{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the template for the submission. You can develop your algorithm in a regular Python script and copy the code here for submission.\n",
    "\n",
    "# TEAM NAME ON KAGGLE\n",
    "# \"EXAMPLE_GROUP\"\n",
    "\n",
    "# GROUP NUMBER\n",
    "# \"group_32\"\n",
    "\n",
    "# TEAM MEMBERS (E-MAIL, LEGI, KAGGLE USERNAME):\n",
    "# dbekatli@student.ethz.ch, 19-946-037, dbekatli\n",
    "# obasinska@student.ethz.ch 19-934-199, Oliwia\n",
    "# chbucher@student.ethz.ch 19-924-240, Christoph Bucher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import re\n",
    "import joblib\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy import signal\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import peak_prominences\n",
    "from scipy.fft import fft, fftfreq\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "# You may change the mhealth_activity module but your algorithm must support the original version\n",
    "from mhealth_activity import Recording\n",
    "\n",
    "# For interactive graphs\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the path for all test traces\n",
    "dir_traces = '/kaggle/input/24-exercise2/data/test'\n",
    "dir_traces = 'data/test'\n",
    "filenames = [join(dir_traces, f) for f in listdir(dir_traces) if isfile(join(dir_traces, f))]\n",
    "filenames.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define feature extraction related functions for watch position classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extraction_watchpos(df, prefix): \n",
    "    FEATURES = ['Median', 'Numneg', 'Numpos', 'Numabovmed', 'Mean', 'STD', 'MAD', 'Var', 'Min', 'Max', 'SMA', 'Energy', 'IQR', 'Entropy', 'Npeaks', 'avgprom', 'avgpeakdist', 'Sum_f', 'Max_f', 'NPeak_f', 'Avgprom_f','avgpeakdist_f', 'Mean_f', 'Skew_f', 'Kurtosis_f']\n",
    "\n",
    "    for idx, feature in enumerate(FEATURES):\n",
    "        FEATURES[idx] = FEATURES[idx] + '_' + prefix\n",
    "    \n",
    "    Median=[];Numneg=[];Numpos=[];Numabovmed=[];\n",
    "    Min=[];Max=[];Mean=[];Mad=[];Sma=[];Eng=[];Iqr=[];Entr=[];Std=[];Var=[];Kurt=[];Skew=[];Npeaks=[];Avgprom=[]\n",
    "    Min_d=[];Max_d=[];Mean_d=[];Mad_d=[];Sma_d=[];Eng_d=[];Iqr_d=[];Entr_d=[];Std_d=[];Var_d=[];\n",
    "    Max_f=[];NPeak_f=[];Avgprom_f=[];Mean_f=[];Skew_f=[];Kurtosis_f=[];Sum_f=[]; Avgpeakdist=[]; Avgpeakdist_f=[];\n",
    "    \n",
    "    ## TIME DOMAIN ##\n",
    "    Median.append(np.median(df))\n",
    "    Numneg.append(np.sum(np.array(df) < 0, axis=0))\n",
    "    Numpos.append(np.sum(np.array(df) > 0, axis=0))\n",
    "    Numabovmed.append(np.sum(np.array(df) > np.median(df), axis=0))\n",
    "\n",
    "    Mean.append(np.mean(df))\n",
    "    Std.append(np.std(df))\n",
    "    #median absolute deviation\n",
    "    Mad.append(stats.median_abs_deviation(df, scale=1))\n",
    "    Var.append(np.var(df))\n",
    "    Min.append(np.min(df))\n",
    "    Max.append(np.max(df))\n",
    "    #Signal Magnitude Area\n",
    "    Sma.append(np.sum(df))\n",
    "    #energy measure\n",
    "    Eng.append(np.sum(df**2)/len(df))\n",
    "    Iqr.append(stats.iqr(df))\n",
    "    Entr.append(stats.entropy(df))\n",
    "\n",
    "    npeaks, _ = find_peaks(df, distance=5)\n",
    "    Npeaks.append(len(npeaks))\n",
    "    prom = peak_prominences(df, npeaks)\n",
    "    Avgprom.append(np.mean(prom))\n",
    "\n",
    "    Apeakdist = 0\n",
    "    for i in range(len(npeaks)-1):\n",
    "        Apeakdist += abs(npeaks[i] - npeaks[i+1])\n",
    "    Avgpeakdist.append(Apeakdist/(len(npeaks)-1))\n",
    "\n",
    "    ## FREQ DOMAIN ##\n",
    "    ft = np.abs(fft(df))\n",
    "    Sum_f.append(np.sum(ft))\n",
    "    Max_f.append(np.max(ft))\n",
    "\n",
    "    npeaks, _ = find_peaks(ft, distance=5)\n",
    "    NPeak_f.append(len(npeaks))\n",
    "    prom = peak_prominences(ft, npeaks)\n",
    "    Avgprom_f.append(np.mean(prom))\n",
    "\n",
    "    Apeakdist = 0\n",
    "    for i in range(len(npeaks)-1):\n",
    "        Apeakdist += abs(npeaks[i] - npeaks[i+1])\n",
    "    Avgpeakdist_f.append(Apeakdist/(len(npeaks)-1))\n",
    "\n",
    "    Mean_f.append(np.mean(ft))\n",
    "    Skew_f.append(stats.skew(ft))\n",
    "    Kurtosis_f.append(stats.kurtosis(ft))\n",
    "\n",
    "    #Create dataframe from features\n",
    "    df_features = pd.DataFrame(index = [FEATURES], \n",
    "                               data = [Median, Numneg, Numpos, Numabovmed, Mean,Std, Mad, Var, Min, Max, Sma, Eng, Iqr, Entr, Npeaks, Avgprom, Avgpeakdist, Sum_f, Max_f, NPeak_f, Avgprom_f, Avgpeakdist_f, Mean_f, Skew_f, Kurtosis_f]) \n",
    "    df_features = pd.DataFrame.transpose(df_features)\n",
    "    df_features.columns = df_features.columns.map(''.join)\n",
    "    # get rid of multiindex\n",
    "    return df_features\n",
    "\n",
    "def calc_norm(xarr, yarr, zarr, label):\n",
    "    norm = []\n",
    "    for i, x in enumerate(xarr):\n",
    "        norm.append(np.sqrt(xarr[i]**2 + yarr[i]**2 + zarr[i]**2))\n",
    "    return np.array(norm)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define feature extraction related functions for path classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extraction_altitude_pathid(df):\n",
    "    FEATURES = ['min', 'max', 'amp', 'len', 'gain']\n",
    "    for idx, feature in enumerate(FEATURES):\n",
    "        FEATURES[idx] = FEATURES[idx] + '_alt' \n",
    "    \n",
    "    Min=[]; Max=[]; amp=[];leng=[];gain=[]; segs =[]\n",
    "\n",
    "    segfeats = []\n",
    "    numsegs = 15\n",
    "    for i in range(numsegs):\n",
    "            segfeats.append(f\"alt_seg{i}\")\n",
    "            segs.append([])\n",
    "    \n",
    "    sos = signal.cheby2(1, 20, 0.5, 'lowpass', fs=12.5, output='sos')\n",
    "    alt = signal.sosfiltfilt(sos,df)\n",
    "\n",
    "    Min.append(min(alt))\n",
    "    Max.append(max(alt))\n",
    "    #fit altitude data to a linear function to determine whether we are climbing or descending\n",
    "    x = np.arange(0,len(alt),1)\n",
    "    m,b = np.polyfit(x, alt, 1)\n",
    "    amp.append(m*1000)\n",
    "    leng.append(len(alt))\n",
    "    gain.append(m*len(alt))\n",
    "    df_features = pd.DataFrame(index = [FEATURES],  data = [Min, Max, amp, leng, gain])\n",
    "\n",
    "    #split altitude data into segments and return average altitude for each segment\n",
    "    seglen = int(len(alt)/numsegs)\n",
    "    for i in range(numsegs):\n",
    "        segs[i].append(np.mean(alt[i*seglen : (i+1)*seglen]))\n",
    "\n",
    "    \n",
    "\n",
    "    segs = pd.DataFrame(index = [segfeats],  data = segs)\n",
    "    segs = pd.DataFrame.transpose(segs)\n",
    "    segs.columns = segs.columns.map(''.join)   \n",
    "\n",
    "    df_features = pd.DataFrame.transpose(df_features)\n",
    "    df_features.columns = df_features.columns.map(''.join)   \n",
    "    df_features = pd.concat([df_features,  segs], axis=1)\n",
    "    return df_features\n",
    "\n",
    "#Madgwick filter, used to generate quaternions from fused accelerometer, gyroscope and magnetometer data\n",
    "class Madgwick:\n",
    "    def __init__(self, gyr: np.ndarray = None, acc: np.ndarray = None, mag: np.ndarray = None, **kwargs):\n",
    "        self.gyr: np.ndarray = gyr\n",
    "        self.acc: np.ndarray = acc\n",
    "        self.mag: np.ndarray = mag\n",
    "        self.frequency: float = kwargs.get('frequency', 100.0)\n",
    "        self.Dt: float = kwargs.get('Dt', (1.0/self.frequency) if self.frequency else 0.01)\n",
    "        self.q0: np.ndarray = kwargs.get('q0')\n",
    "        self._set_gain(**kwargs)\n",
    "        self._assert_validity_of_inputs()\n",
    "        if self.acc is not None and self.gyr is not None:\n",
    "            self.Q: np.ndarray = self._compute_all()\n",
    "\n",
    "    def _set_gain(self, **kwargs) -> None:\n",
    "        \"\"\"Set the gain parameter.\"\"\"\n",
    "        self.gain_imu: float = kwargs.get('gain_imu', 0.033)\n",
    "        self.gain_marg: float = kwargs.get('gain_marg', 0.041)\n",
    "        self.gain: float = kwargs.get('beta')  # Setting gain with `beta` will be removed in the future.\n",
    "        if self.gain is None:\n",
    "            self.gain: float = kwargs.get('gain', self.gain_imu if self.mag is None else self.gain_marg)\n",
    "\n",
    "    def _assert_validity_of_inputs(self):\n",
    "        \"\"\"Asserts the validity of the inputs.\"\"\"\n",
    "        for item in [\"frequency\", \"Dt\", \"gain\", \"gain_imu\", \"gain_marg\"]:\n",
    "            if isinstance(self.__getattribute__(item), bool):\n",
    "                raise TypeError(f\"Parameter '{item}' must be numeric.\")\n",
    "            if not isinstance(self.__getattribute__(item), (int, float)):\n",
    "                raise TypeError(f\"Parameter '{item}' is not a non-zero number.\")\n",
    "            if self.__getattribute__(item) <= 0.0:\n",
    "                raise ValueError(f\"Parameter '{item}' must be a non-zero number.\")\n",
    "        if self.q0 is not None:\n",
    "            if not isinstance(self.q0, (list, tuple, np.ndarray)):\n",
    "                raise TypeError(f\"Parameter 'q0' must be an array. Got {type(self.q0)}.\")\n",
    "            self.q0 = np.copy(self.q0)\n",
    "            if self.q0.shape != (4,):\n",
    "                raise ValueError(f\"Parameter 'q0' must be an array of shape (4,). It is {self.q0.shape}.\")\n",
    "            if not np.allclose(np.linalg.norm(self.q0), 1.0):\n",
    "                raise ValueError(f\"Parameter 'q0' must be a versor (norm equal to 1.0). Its norm is equal to {np.linalg.norm(self.q0)}.\")\n",
    "\n",
    "\n",
    "    def _compute_all(self) -> np.ndarray:\n",
    "\n",
    "        self.gyr = np.copy(self.gyr)\n",
    "        self.acc = np.copy(self.acc)\n",
    "        if self.acc.shape != self.gyr.shape:\n",
    "            raise ValueError(\"acc and gyr are not the same size\")\n",
    "        num_samples = len(self.acc)\n",
    "        Q = np.zeros((num_samples, 4))\n",
    "        # Compute with IMU architecture\n",
    "        if self.mag is None:\n",
    "            Q[0] = acc2q(self.acc[0]) if self.q0 is None else self.q0/np.linalg.norm(self.q0)\n",
    "            for t in range(1, num_samples):\n",
    "                Q[t] = self.updateIMU(Q[t-1], self.gyr[t], self.acc[t])\n",
    "            return Q\n",
    "        # Compute with MARG architecture\n",
    "        self.mag = np.copy(self.mag)\n",
    "        if self.mag.shape != self.gyr.shape:\n",
    "            raise ValueError(\"mag and gyr are not the same size\")\n",
    "        Q[0] = ecompass(self.acc[0], self.mag[0], frame='NED', representation='quaternion')\n",
    "        for t in range(1, num_samples):\n",
    "            Q[t] = self.updateMARG(Q[t-1], self.gyr[t], self.acc[t], self.mag[t])\n",
    "        return Q\n",
    "        \n",
    "    def updateMARG(self, q: np.ndarray, gyr: np.ndarray, acc: np.ndarray, mag: np.ndarray, dt: float = None) -> np.ndarray:\n",
    "        dt = self.Dt if dt is None else dt\n",
    "        if gyr is None or not np.linalg.norm(gyr) > 0:\n",
    "            return q\n",
    "        if mag is None or not np.linalg.norm(mag) > 0:\n",
    "            return self.updateIMU(q, gyr, acc)\n",
    "        qDot = 0.5 * q_prod(q, [0, *gyr])                           # (eq. 12)\n",
    "        a_norm = np.linalg.norm(acc)\n",
    "        if a_norm > 0:\n",
    "            a = acc/a_norm\n",
    "            m = mag/np.linalg.norm(mag)\n",
    "            # Rotate normalized magnetometer measurements\n",
    "            h = q_prod(q, q_prod([0, *m], q_conj(q)))               # (eq. 45)\n",
    "            bx = np.linalg.norm([h[1], h[2]])                       # (eq. 46)\n",
    "            bz = h[3]\n",
    "            qw, qx, qy, qz = q/np.linalg.norm(q)\n",
    "            # Objective function (eq. 31)\n",
    "            f = np.array([2.0*(qx*qz - qw*qy)   - a[0],\n",
    "                            2.0*(qw*qx + qy*qz)   - a[1],\n",
    "                            2.0*(0.5-qx**2-qy**2) - a[2],\n",
    "                            2.0*bx*(0.5 - qy**2 - qz**2) + 2.0*bz*(qx*qz - qw*qy)       - m[0],\n",
    "                            2.0*bx*(qx*qy - qw*qz)       + 2.0*bz*(qw*qx + qy*qz)       - m[1],\n",
    "                            2.0*bx*(qw*qy + qx*qz)       + 2.0*bz*(0.5 - qx**2 - qy**2) - m[2]])\n",
    "            # Jacobian (eq. 32)\n",
    "            J = np.array([[-2.0*qy,               2.0*qz,              -2.0*qw,               2.0*qx             ],\n",
    "                            [ 2.0*qx,               2.0*qw,               2.0*qz,               2.0*qy             ],\n",
    "                            [ 0.0,                 -4.0*qx,              -4.0*qy,               0.0                ],\n",
    "                            [-2.0*bz*qy,            2.0*bz*qz,           -4.0*bx*qy-2.0*bz*qw, -4.0*bx*qz+2.0*bz*qx],\n",
    "                            [-2.0*bx*qz+2.0*bz*qx,  2.0*bx*qy+2.0*bz*qw,  2.0*bx*qx+2.0*bz*qz, -2.0*bx*qw+2.0*bz*qy],\n",
    "                            [ 2.0*bx*qy,            2.0*bx*qz-4.0*bz*qx,  2.0*bx*qw-4.0*bz*qy,  2.0*bx*qx          ]])\n",
    "            gradient = J.T@f                                        # (eq. 34)\n",
    "            gradient /= np.linalg.norm(gradient)\n",
    "            qDot -= self.gain*gradient                              # (eq. 33)\n",
    "        q_new = q + qDot*dt                                         # (eq. 13)\n",
    "        q_new /= np.linalg.norm(q_new)\n",
    "        return q_new\n",
    "    \n",
    "    def updateIMU(self, q: np.ndarray, gyr: np.ndarray, acc: np.ndarray, dt: float = None) -> np.ndarray:\n",
    "        dt = self.Dt if dt is None else dt\n",
    "        if gyr is None or not np.linalg.norm(gyr) > 0:\n",
    "            return q\n",
    "        qDot = 0.5 * q_prod(q, [0, *gyr])                           # (eq. 12)\n",
    "        a_norm = np.linalg.norm(acc)\n",
    "        if a_norm > 0:\n",
    "            a = acc/a_norm\n",
    "            qw, qx, qy, qz = q/np.linalg.norm(q)\n",
    "            # Objective function (eq. 25)\n",
    "            f = np.array([2.0*(qx*qz - qw*qy)   - a[0],\n",
    "                          2.0*(qw*qx + qy*qz)   - a[1],\n",
    "                          2.0*(0.5-qx**2-qy**2) - a[2]])\n",
    "            if np.linalg.norm(f) > 0:\n",
    "                # Jacobian (eq. 26)\n",
    "                J = np.array([[-2.0*qy,  2.0*qz, -2.0*qw, 2.0*qx],\n",
    "                              [ 2.0*qx,  2.0*qw,  2.0*qz, 2.0*qy],\n",
    "                              [ 0.0,    -4.0*qx, -4.0*qy, 0.0   ]])\n",
    "                # Objective Function Gradient\n",
    "                gradient = J.T@f                                    # (eq. 34)\n",
    "                gradient /= np.linalg.norm(gradient)\n",
    "                qDot -= self.gain*gradient                          # (eq. 33)\n",
    "        q_new = q + qDot*dt                                         # (eq. 13)\n",
    "        q_new /= np.linalg.norm(q_new)\n",
    "        return q_new\n",
    "\n",
    "def ecompass(a: np.ndarray, m: np.ndarray, frame: str = 'ENU', representation: str = 'rotmat') -> np.ndarray:\n",
    "    if frame.upper() not in ['ENU', 'NED']:\n",
    "        raise ValueError(\"Wrong local tangent plane coordinate frame. Try 'ENU' or 'NED'\")\n",
    "    if representation.lower() not in ['rotmat', 'quaternion', 'rpy', 'axisangle']:\n",
    "        raise ValueError(\"Wrong representation type. Try 'rotmat', 'quaternion', 'rpy', or 'axisangle'\")\n",
    "    a = np.copy(a)\n",
    "    m = np.copy(m)\n",
    "    if a.shape[-1] != 3 or m.shape[-1] != 3:\n",
    "        raise ValueError(\"Input vectors must have exactly 3 elements.\")\n",
    "    m /= np.linalg.norm(m)\n",
    "    Rz = a/np.linalg.norm(a)\n",
    "    if frame.upper() == 'NED':\n",
    "        Ry = np.cross(Rz, m)\n",
    "        Rx = np.cross(Ry, Rz)\n",
    "    else:\n",
    "        Rx = np.cross(m, Rz)\n",
    "        Ry = np.cross(Rz, Rx)\n",
    "    Rx /= np.linalg.norm(Rx)\n",
    "    Ry /= np.linalg.norm(Ry)\n",
    "    R = np.c_[Rx, Ry, Rz].T\n",
    "    if representation.lower() == 'quaternion':\n",
    "        return chiaverini(R)\n",
    "    if representation.lower() == 'rpy':\n",
    "        phi = np.arctan2(R[1, 2], R[2, 2])    # Roll Angle\n",
    "        theta = -np.arcsin(R[0, 2])           # Pitch Angle\n",
    "        psi = np.arctan2(R[0, 1], R[0, 0])    # Yaw Angle\n",
    "        return np.array([phi, theta, psi])\n",
    "    if representation.lower() == 'axisangle':\n",
    "        angle = np.arccos((R.trace()-1)/2)\n",
    "        axis = np.zeros(3)\n",
    "        if angle != 0:\n",
    "            S = np.array([R[2, 1]-R[1, 2], R[0, 2]-R[2, 0], R[1, 0]-R[0, 1]])\n",
    "            axis = S/(2*np.sin(angle))\n",
    "        return (axis, angle)\n",
    "    return R\n",
    "\n",
    "def chiaverini(dcm: np.ndarray) -> np.ndarray:\n",
    "    dcm = np.copy(dcm)\n",
    "    if dcm.ndim not in [2, 3]:\n",
    "        raise ValueError('dcm must be a 2- or 3-dimensional array.')\n",
    "    if dcm.shape[-2:] != (3, 3):\n",
    "        raise ValueError(f\"dcm must be an array of shape 3-by-3 or N-by-3-by-3. Got {dcm.shape}\")\n",
    "    if dcm.ndim < 3:\n",
    "        q = np.zeros(4)\n",
    "        q[0] = 0.5*np.sqrt(np.clip(dcm.trace(), -1.0, 3.0) + 1.0)\n",
    "        q[1] = 0.5*np.sign(dcm[2, 1]-dcm[1, 2])*np.sqrt(np.clip(dcm[0, 0]-dcm[1, 1]-dcm[2, 2], -1.0, 1.0)+1.0)\n",
    "        q[2] = 0.5*np.sign(dcm[0, 2]-dcm[2, 0])*np.sqrt(np.clip(dcm[1, 1]-dcm[2, 2]-dcm[0, 0], -1.0, 1.0)+1.0)\n",
    "        q[3] = 0.5*np.sign(dcm[1, 0]-dcm[0, 1])*np.sqrt(np.clip(dcm[2, 2]-dcm[0, 0]-dcm[1, 1], -1.0, 1.0)+1.0)\n",
    "        if not any(q):\n",
    "            q[0] = 1.0\n",
    "        q /= np.linalg.norm(q)\n",
    "        return q\n",
    "    Q = np.zeros((dcm.shape[0], 4))\n",
    "    Q[:, 0] = 0.5*np.sqrt(np.clip(dcm.trace(axis1=1, axis2=2), -1.0, 3.0) + 1.0)\n",
    "    Q[:, 1] = 0.5*np.sign(dcm[:, 2, 1] - dcm[:, 1, 2])*np.sqrt(np.clip(dcm[:, 0, 0]-dcm[:, 1, 1]-dcm[:, 2, 2], -1.0, 1.0) + 1.0)\n",
    "    Q[:, 2] = 0.5*np.sign(dcm[:, 0, 2] - dcm[:, 2, 0])*np.sqrt(np.clip(dcm[:, 1, 1]-dcm[:, 2, 2]-dcm[:, 0, 0], -1.0, 1.0) + 1.0)\n",
    "    Q[:, 3] = 0.5*np.sign(dcm[:, 1, 0] - dcm[:, 0, 1])*np.sqrt(np.clip(dcm[:, 2, 2]-dcm[:, 0, 0]-dcm[:, 1, 1], -1.0, 1.0) + 1.0)\n",
    "    Q /= np.linalg.norm(Q, axis=1)[:, None]\n",
    "    return Q\n",
    "\n",
    "def q_prod(p: np.ndarray, q: np.ndarray) -> np.ndarray:\n",
    "    pq = np.zeros(4)\n",
    "    pq[0] = p[0]*q[0] - p[1]*q[1] - p[2]*q[2] - p[3]*q[3]\n",
    "    pq[1] = p[0]*q[1] + p[1]*q[0] + p[2]*q[3] - p[3]*q[2]\n",
    "    pq[2] = p[0]*q[2] - p[1]*q[3] + p[2]*q[0] + p[3]*q[1]\n",
    "    pq[3] = p[0]*q[3] + p[1]*q[2] - p[2]*q[1] + p[3]*q[0]\n",
    "    return pq\n",
    "\n",
    "def q_conj(q: np.ndarray) -> np.ndarray:\n",
    "    q = np.copy(q)\n",
    "    if q.ndim > 2 or q.shape[-1] != 4:\n",
    "        raise ValueError(f\"Quaternion must be of shape (4,) or (N, 4), but has shape {q.shape}\")\n",
    "    return np.array([1., -1., -1., -1.])*np.array(q)\n",
    "\n",
    "def q2euler(q: np.ndarray) -> np.ndarray:\n",
    "    if sum(np.array([1., 0., 0., 0.])-q) == 0.0:\n",
    "        return np.zeros(3)\n",
    "    if len(q) != 4:\n",
    "        return None\n",
    "    R_00 = 2.0*q[0]**2 - 1.0 + 2.0*q[1]**2\n",
    "    R_10 = 2.0*(q[1]*q[2] - q[0]*q[3])\n",
    "    R_20 = 2.0*(q[1]*q[3] + q[0]*q[2])\n",
    "    R_21 = 2.0*(q[2]*q[3] - q[0]*q[1])\n",
    "    R_22 = 2.0*q[0]**2 - 1.0 + 2.0*q[3]**2\n",
    "    #rotation around x, roll\n",
    "    phi = np.arctan2( R_21, R_22)\n",
    "    #rotation around y, pitch\n",
    "    theta = -np.arctan( R_20/np.sqrt(1.0-R_20**2))\n",
    "    #rotation around z, yaw\n",
    "    psi = np.arctan2( R_10, R_00)\n",
    "    return np.array([phi, theta, psi])\n",
    "\n",
    "def acc2q(a: np.ndarray, return_euler: bool = False) -> np.ndarray:\n",
    "    q = np.array([1.0, 0.0, 0.0, 0.0])\n",
    "    ex, ey, ez = 0.0, 0.0, 0.0\n",
    "    if np.linalg.norm(a) > 0 and len(a) == 3:\n",
    "        ax, ay, az = a\n",
    "        # Normalize accelerometer measurements\n",
    "        a_norm = np.linalg.norm(a)\n",
    "        ax /= a_norm\n",
    "        ay /= a_norm\n",
    "        az /= a_norm\n",
    "        # Euler Angles from Gravity vector\n",
    "        ex = np.arctan2(ay, az)\n",
    "        ey = np.arctan2(-ax, np.sqrt(ay**2 + az**2))\n",
    "        ez = 0.0\n",
    "        if return_euler:\n",
    "            return np.array([ex, ey, ez])*RAD2DEG\n",
    "        # Euler to Quaternion\n",
    "        cx2 = np.cos(ex/2.0)\n",
    "        sx2 = np.sin(ex/2.0)\n",
    "        cy2 = np.cos(ey/2.0)\n",
    "        sy2 = np.sin(ey/2.0)\n",
    "        q = np.array([cx2*cy2, sx2*cy2, cx2*sy2, -sx2*sy2])\n",
    "        q /= np.linalg.norm(q)\n",
    "    return q\n",
    "\n",
    "#drop extra samples since phone measurements don't always have the same lengths(length differs by 2 at most)\n",
    "def equalize_lengths(ax,ay,az,gx,gy,gz,mx,my,mz):\n",
    "    mini = min(len(ax), len(ay))\n",
    "    mini = min(mini, len(az))\n",
    "    mini = min(mini, len(gx))\n",
    "    mini = min(mini, len(gy))\n",
    "    mini = min(mini, len(gz))\n",
    "    mini = min(mini, len(mx))\n",
    "    mini = min(mini, len(my))\n",
    "    mini = min(mini, len(mz))\n",
    "\n",
    "    if len(ax) > mini:\n",
    "        ax = ax[:-(len(ax)-mini)]\n",
    "    if len(ay) > mini:\n",
    "        ay = ay[:-(len(ay)-mini)]\n",
    "    if len(az) > mini:\n",
    "        az = az[:-(len(az)-mini)]\n",
    "\n",
    "\n",
    "    if len(gx) > mini:\n",
    "        gx = gx[:-(len(gx)-mini)]\n",
    "    if len(gy) > mini:\n",
    "        gy = gy[:-(len(gy)-mini)]\n",
    "    if len(gz) > mini:\n",
    "        gz = gz[:-(len(gz)-mini)]\n",
    "\n",
    "\n",
    "    if len(mx) > mini:\n",
    "        mx = mx[:-(len(mx)-mini)]\n",
    "    if len(my) > mini:\n",
    "        my = my[:-(len(my)-mini)]\n",
    "    if len(mz) > mini:\n",
    "        mz = mz[:-(len(mz)-mini)]\n",
    "\n",
    "    return (ax, ay, az, gx, gy, gz, mx, my, mz)\n",
    "\n",
    "def madgwick_headings(ax,ay,az,gx,gy,gz,mx,my,mz):\n",
    "    ax, ay, az, gx, gy, gz, mx, my, mz = equalize_lengths(ax,ay,az,gx,gy,gz,mx,my,mz)\n",
    "\n",
    "    acc_data  = np.concatenate([np.array(az).reshape(-1,1),np.array(ay).reshape(-1,1),np.array(ax).reshape(-1,1)], axis=1)\n",
    "    gyro_data = np.concatenate([np.array(gz).reshape(-1,1),np.array(gy).reshape(-1,1),np.array(gx).reshape(-1,1)], axis=1)\n",
    "    mag_data  = np.concatenate([np.array(mz).reshape(-1,1),np.array(my).reshape(-1,1),np.array(mx).reshape(-1,1)], axis=1)\n",
    "    #get quaternions\n",
    "    madgwick = Madgwick(gyr=gyro_data, acc=acc_data, mag=mag_data, frequency=samplerate, gain=0.038)\n",
    "\n",
    "    current = [0, 0, 0]\n",
    "    x = []\n",
    "    y = [] \n",
    "    z = []\n",
    "\n",
    "    limit = len(madgwick.Q)\n",
    "    # limit=100\n",
    "    for i in (range(limit)):\n",
    "        #convert quaternions to rotation matrices\n",
    "        euler = q2euler(madgwick.Q[i]) *180/math.pi\n",
    "        rot = Rotation.from_euler('xyz', euler)\n",
    "        #rotate unit vector to get cartesian headings, x=0\n",
    "        vector = np.array(rot.as_matrix()).dot(np.array([0,0,1]))\n",
    "        #sum heading vectors to get a kind of heading array\n",
    "        current += vector\n",
    "        x.append(current[0])\n",
    "        y.append(current[1])\n",
    "        z.append(current[2])\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    z = np.array(z)\n",
    "\n",
    "    return x, y, z\n",
    "\n",
    "def features_extraction_marg_pathid(ax,ay,az,gx,gy,gz,mx,my,mz):\n",
    "    FEATURES = ['avgdist2d', 'avgdist3d', \"dist1\", \"dist2\", \"dist3\", \"dist4\", \"dist5\"]\n",
    "    for idx, feature in enumerate(FEATURES):\n",
    "        FEATURES[idx] = FEATURES[idx] + '_phone' \n",
    "\n",
    "    avgdist2d=0; avgdist3d=0;\n",
    "    try: \n",
    "        x, y, z = madgwick_headings(ax,ay,az,gx,gy,gz,mx,my,mz)\n",
    "\n",
    "             \n",
    "        avgdist2d=math.sqrt((x[-1]+x[0])**2 + (y[-1]+y[0])**2 )\n",
    "        avgdist3d=math.sqrt((x[-1]+x[0])**2 + (y[-1]+y[0])**2 + (z[-1]+z[0])**2)\n",
    "\n",
    "        seglen = int(len(x)/5)\n",
    "        dist1 = math.sqrt((x[seglen-1]   - x[0]       )**2   +   (y[seglen-1]   - y[0]       )**2)\n",
    "        dist2 = math.sqrt((x[seglen*2-1] - x[seglen]  )**2   +   (y[seglen*2-1] - y[seglen]  )**2)\n",
    "        dist3 = math.sqrt((x[seglen*3-1] - x[seglen*2])**2   +   (y[seglen*3-1] - y[seglen*2])**2)\n",
    "        dist4 = math.sqrt((x[seglen*4-1] - x[seglen*3])**2   +   (y[seglen*4-1] - y[seglen*3])**2)\n",
    "        dist5 = math.sqrt((x[seglen*5-1] - x[seglen*4])**2   +   (y[seglen*5-1] - y[seglen*4])**2)\n",
    "    except:\n",
    "        #return zeros if filter fails for some reason\n",
    "        DistanceFeatures = ['north', \"east\", 'south',  'west']\n",
    "        for idx, feature in enumerate(DistanceFeatures):\n",
    "            FEATURES.append(DistanceFeatures[idx])\n",
    "        #7 common features + 8 per segment features * 5 segments = 47 zeros\n",
    "        df_features = pd.DataFrame(index = [FEATURES], data = np.zeros(11))\n",
    "        df_features = pd.DataFrame.transpose(df_features)\n",
    "        df_features.columns = df_features.columns.map(''.join)\n",
    "        return df_features \n",
    "\n",
    "\n",
    "    df_features = pd.DataFrame(index = [FEATURES], data = [avgdist2d,avgdist3d, dist1, dist2, dist3, dist4, dist5])\n",
    "    df_features = pd.DataFrame.transpose(df_features)\n",
    "    df_features.columns = df_features.columns.map(''.join)\n",
    "\n",
    "    #divide data into 5 parts and classify headings separately\n",
    "    # print(f\"total length {len(x)}\")\n",
    "    north = 0; northeast  = 0; east = 0; southeast = 0; south = 0; southwest = 0; west = 0; northwest = 0;\n",
    "    DistanceFeatures = ['north', \"east\", 'south',  'west']\n",
    "    for i in range(len(x)):\n",
    "        bearing = (math.atan2(x[i], z[i]) * 180.0 / math.pi ) + 180.0\n",
    "\n",
    "        if bearing <= 90:\n",
    "            north += 1\n",
    "        elif bearing <= 180:\n",
    "            east += 1\n",
    "        elif bearing <= 270:\n",
    "            south += 1\n",
    "        else:\n",
    "            west += 1\n",
    "\n",
    "        # seg_features = pd.DataFrame(index = [DistanceFeatures], data = [north, northeast, east, southeast, south, southwest, west, northwest])\n",
    "    seg_features = pd.DataFrame(index = [DistanceFeatures], data = [north, east,  south,  west])\n",
    "    seg_features = pd.DataFrame.transpose(seg_features)\n",
    "    seg_features.columns = seg_features.columns.map(''.join)\n",
    "    df_features = pd.concat([df_features, seg_features],axis=1)\n",
    "\n",
    "    return df_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load all the models\n",
    "watchpos_rf = joblib.load(\"group32_model_watchpos_acc97.5.pkl\")\n",
    "pathid_rf   = joblib.load(\"group32_model_path_id_acc0.775.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [03:18<00:00,  1.41it/s]\n"
     ]
    }
   ],
   "source": [
    "# Loop through all filenames to process recordings\n",
    "submission = []\n",
    "for filename in tqdm(filenames):\n",
    "    recording = Recording(filename)\n",
    "    \n",
    "    # Assumes filename format ends with a three-digit ID before \".pkl\"\n",
    "    match = re.search(r'(\\d{3})\\.pkl$', filename)\n",
    "    if match:\n",
    "        id = int(match.group(1))\n",
    "    else:\n",
    "        raise ValueError(f'Filename {filename} does not match expected format')\n",
    "\n",
    "    # Placeholder for the algorithm to process the recording\n",
    "    # Implement the logic to infer watch location, path index, step count,\n",
    "    # and activities (standing, walking, running, cycling) here.\n",
    "    # Ensure your algorithm is tolerant to missing data and does not crash\n",
    "    # when optional smartphone data traces are missing.\n",
    "    #calculate watch position features\n",
    "    watchpos_acc_norm = calc_norm(recording.data['ax'].values, recording.data['ay'].values, recording.data['az'].values, \"acc_norm\")\n",
    "    watchpos_acc_features = features_extraction_watchpos(watchpos_acc_norm, \"acc\")\n",
    "\n",
    "    watchpos_gyro_norm = calc_norm(recording.data['gx'].values, recording.data['gy'].values, recording.data['gz'].values, \"gyro_norm\")\n",
    "    watchpos_gyro_features = features_extraction_watchpos(watchpos_gyro_norm, \"gyro\")\n",
    "\n",
    "    watchpos_features = pd.concat([watchpos_acc_features, watchpos_gyro_features], axis=1)\n",
    "\n",
    "    #calculate path classification features\n",
    "    pathid_altitude_features = features_extraction_altitude_pathid(recording.data['altitude'].values)\n",
    "    \n",
    "    pathid_bearing_features  = features_extraction_marg_pathid(recording.data['phone_ax'].values, recording.data['phone_ay'].values, recording.data['phone_az'].values,recording.data['phone_gx'].values, recording.data['phone_gy'].values, recording.data['phone_gz'].values,recording.data['phone_mx'].values, recording.data['phone_my'].values, recording.data['phone_mz'].values)\n",
    "    \n",
    "    pathid_features = pd.concat([pathid_altitude_features, pathid_bearing_features],axis=1)\n",
    "\n",
    "    path_idx = int(np.rint(pathid_rf.predict(pathid_features))[0])  # Integer, path in {0, 1, 2, 3, 4}\n",
    "    watch_loc = int(np.rint(watchpos_rf.predict(watchpos_features))[0])  # Integer, 0: left wrist, 1: belt, 2: right ankle\n",
    "    standing = False  # Boolean, True if participant was standing still throughout the recording\n",
    "    walking = False  # Boolean, True if participant was walking throughout the recording\n",
    "    running = False  # Boolean, True if participant was running throughout the recording\n",
    "    cycling = False  # Boolean, True if participant was cycling throughout the recording\n",
    "    step_count = 0  # Integer, number of steps, must be provided for each recording\n",
    "\n",
    "    predictions = {\n",
    "        'Id': id, \n",
    "        'watch_loc': watch_loc, \n",
    "        'path_idx': path_idx,\n",
    "        'standing': standing,\n",
    "        'walking': walking,\n",
    "        'running': running,\n",
    "        'cycling': cycling,\n",
    "        'step_count': step_count\n",
    "        }\n",
    "\n",
    "    submission.append(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the predicted values into a .csv file to then upload the .csv file to Kaggle\n",
    "# When cross-checking the .csv file on your computer, we recommend using a text editor and NOT excel so that the results are displayed correctly\n",
    "# IMPORTANT: Do NOT change the name of the columns of the .csv file (\"Id\", \"watch_loc\", \"path_idx\", \"standing\", \"walking\", \"running\", \"cycling\", \"step_count\")\n",
    "submission_df = pd.DataFrame(submission, columns=['Id', 'watch_loc', 'path_idx', 'standing', 'walking', 'running', 'cycling', 'step_count'])\n",
    "# submission_df.to_csv('/kaggle/working/submission.csv', index=False)\n",
    "submission_df.to_csv('group32_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhealth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

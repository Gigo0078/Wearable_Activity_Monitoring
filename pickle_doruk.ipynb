{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "# You may change the mhealth_activity module but your algorithm must support the original version\n",
    "from mhealth_activity import Recording, Trace, Activity, WatchLocation, Path\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "# For interactive plots, uncomment the following line\n",
    "# %matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train_trace_000.pkl', 'train_trace_001.pkl', 'train_trace_002.pkl', 'train_trace_003.pkl', 'train_trace_004.pkl', 'train_trace_005.pkl', 'train_trace_006.pkl', 'train_trace_007.pkl', 'train_trace_008.pkl', 'train_trace_009.pkl', 'train_trace_010.pkl', 'train_trace_011.pkl', 'train_trace_012.pkl', 'train_trace_013.pkl', 'train_trace_014.pkl', 'train_trace_015.pkl', 'train_trace_016.pkl', 'train_trace_017.pkl', 'train_trace_018.pkl', 'train_trace_019.pkl', 'train_trace_020.pkl', 'train_trace_021.pkl', 'train_trace_022.pkl', 'train_trace_023.pkl', 'train_trace_024.pkl', 'train_trace_025.pkl', 'train_trace_026.pkl', 'train_trace_027.pkl', 'train_trace_028.pkl', 'train_trace_029.pkl', 'train_trace_030.pkl', 'train_trace_031.pkl', 'train_trace_032.pkl', 'train_trace_033.pkl', 'train_trace_034.pkl', 'train_trace_035.pkl', 'train_trace_036.pkl', 'train_trace_037.pkl', 'train_trace_038.pkl', 'train_trace_039.pkl', 'train_trace_040.pkl', 'train_trace_041.pkl', 'train_trace_042.pkl', 'train_trace_043.pkl', 'train_trace_044.pkl', 'train_trace_045.pkl', 'train_trace_046.pkl', 'train_trace_047.pkl', 'train_trace_048.pkl', 'train_trace_049.pkl', 'train_trace_050.pkl', 'train_trace_051.pkl', 'train_trace_052.pkl', 'train_trace_053.pkl', 'train_trace_054.pkl', 'train_trace_055.pkl', 'train_trace_056.pkl', 'train_trace_057.pkl', 'train_trace_058.pkl', 'train_trace_059.pkl', 'train_trace_060.pkl', 'train_trace_061.pkl', 'train_trace_062.pkl', 'train_trace_063.pkl', 'train_trace_064.pkl', 'train_trace_065.pkl', 'train_trace_066.pkl', 'train_trace_067.pkl', 'train_trace_068.pkl', 'train_trace_069.pkl', 'train_trace_070.pkl', 'train_trace_071.pkl', 'train_trace_072.pkl', 'train_trace_073.pkl', 'train_trace_074.pkl', 'train_trace_075.pkl', 'train_trace_076.pkl', 'train_trace_077.pkl', 'train_trace_078.pkl', 'train_trace_079.pkl', 'train_trace_080.pkl', 'train_trace_081.pkl', 'train_trace_082.pkl', 'train_trace_083.pkl', 'train_trace_084.pkl', 'train_trace_085.pkl', 'train_trace_086.pkl', 'train_trace_087.pkl', 'train_trace_088.pkl', 'train_trace_089.pkl', 'train_trace_090.pkl', 'train_trace_091.pkl', 'train_trace_092.pkl', 'train_trace_093.pkl', 'train_trace_094.pkl', 'train_trace_095.pkl', 'train_trace_096.pkl', 'train_trace_097.pkl', 'train_trace_098.pkl', 'train_trace_099.pkl', 'train_trace_100.pkl', 'train_trace_101.pkl', 'train_trace_102.pkl', 'train_trace_103.pkl', 'train_trace_104.pkl', 'train_trace_105.pkl', 'train_trace_106.pkl', 'train_trace_107.pkl', 'train_trace_108.pkl', 'train_trace_109.pkl', 'train_trace_110.pkl', 'train_trace_111.pkl', 'train_trace_112.pkl', 'train_trace_113.pkl', 'train_trace_114.pkl', 'train_trace_115.pkl', 'train_trace_116.pkl', 'train_trace_117.pkl', 'train_trace_118.pkl', 'train_trace_119.pkl', 'train_trace_120.pkl', 'train_trace_121.pkl', 'train_trace_122.pkl', 'train_trace_123.pkl', 'train_trace_124.pkl', 'train_trace_125.pkl', 'train_trace_126.pkl', 'train_trace_127.pkl', 'train_trace_128.pkl', 'train_trace_129.pkl', 'train_trace_130.pkl', 'train_trace_131.pkl', 'train_trace_132.pkl', 'train_trace_133.pkl', 'train_trace_134.pkl', 'train_trace_135.pkl', 'train_trace_136.pkl', 'train_trace_137.pkl', 'train_trace_138.pkl', 'train_trace_139.pkl', 'train_trace_140.pkl', 'train_trace_141.pkl', 'train_trace_142.pkl', 'train_trace_143.pkl', 'train_trace_144.pkl', 'train_trace_145.pkl', 'train_trace_146.pkl', 'train_trace_147.pkl', 'train_trace_148.pkl', 'train_trace_149.pkl', 'train_trace_150.pkl', 'train_trace_151.pkl', 'train_trace_152.pkl', 'train_trace_153.pkl', 'train_trace_154.pkl', 'train_trace_155.pkl', 'train_trace_156.pkl', 'train_trace_157.pkl', 'train_trace_158.pkl', 'train_trace_159.pkl', 'train_trace_160.pkl', 'train_trace_161.pkl', 'train_trace_162.pkl', 'train_trace_163.pkl', 'train_trace_164.pkl', 'train_trace_165.pkl', 'train_trace_166.pkl', 'train_trace_167.pkl', 'train_trace_168.pkl', 'train_trace_169.pkl', 'train_trace_170.pkl', 'train_trace_171.pkl', 'train_trace_172.pkl', 'train_trace_173.pkl', 'train_trace_174.pkl', 'train_trace_175.pkl', 'train_trace_176.pkl', 'train_trace_177.pkl', 'train_trace_178.pkl', 'train_trace_179.pkl', 'train_trace_180.pkl', 'train_trace_181.pkl', 'train_trace_182.pkl', 'train_trace_183.pkl', 'train_trace_184.pkl', 'train_trace_185.pkl', 'train_trace_186.pkl', 'train_trace_187.pkl', 'train_trace_188.pkl', 'train_trace_189.pkl', 'train_trace_190.pkl', 'train_trace_191.pkl', 'train_trace_192.pkl', 'train_trace_193.pkl', 'train_trace_194.pkl', 'train_trace_195.pkl', 'train_trace_196.pkl', 'train_trace_197.pkl', 'train_trace_198.pkl', 'train_trace_199.pkl', 'train_trace_200.pkl', 'train_trace_201.pkl', 'train_trace_202.pkl', 'train_trace_203.pkl', 'train_trace_204.pkl', 'train_trace_205.pkl', 'train_trace_206.pkl', 'train_trace_207.pkl', 'train_trace_208.pkl', 'train_trace_209.pkl', 'train_trace_210.pkl', 'train_trace_211.pkl', 'train_trace_212.pkl', 'train_trace_213.pkl', 'train_trace_214.pkl', 'train_trace_215.pkl', 'train_trace_216.pkl', 'train_trace_217.pkl', 'train_trace_218.pkl', 'train_trace_219.pkl', 'train_trace_220.pkl', 'train_trace_221.pkl', 'train_trace_222.pkl', 'train_trace_223.pkl', 'train_trace_224.pkl', 'train_trace_225.pkl', 'train_trace_226.pkl', 'train_trace_227.pkl', 'train_trace_228.pkl', 'train_trace_229.pkl', 'train_trace_230.pkl', 'train_trace_231.pkl', 'train_trace_232.pkl', 'train_trace_233.pkl', 'train_trace_234.pkl', 'train_trace_235.pkl', 'train_trace_236.pkl', 'train_trace_237.pkl', 'train_trace_238.pkl', 'train_trace_239.pkl', 'train_trace_240.pkl', 'train_trace_241.pkl', 'train_trace_242.pkl', 'train_trace_243.pkl', 'train_trace_244.pkl', 'train_trace_245.pkl', 'train_trace_246.pkl', 'train_trace_247.pkl', 'train_trace_248.pkl', 'train_trace_249.pkl', 'train_trace_250.pkl', 'train_trace_251.pkl', 'train_trace_252.pkl', 'train_trace_253.pkl', 'train_trace_254.pkl', 'train_trace_255.pkl', 'train_trace_256.pkl', 'train_trace_257.pkl', 'train_trace_258.pkl', 'train_trace_259.pkl', 'train_trace_260.pkl', 'train_trace_261.pkl', 'train_trace_262.pkl', 'train_trace_263.pkl', 'train_trace_264.pkl', 'train_trace_265.pkl', 'train_trace_266.pkl', 'train_trace_267.pkl', 'train_trace_268.pkl', 'train_trace_269.pkl', 'train_trace_270.pkl', 'train_trace_271.pkl', 'train_trace_272.pkl', 'train_trace_273.pkl', 'train_trace_274.pkl', 'train_trace_275.pkl', 'train_trace_276.pkl', 'train_trace_277.pkl', 'train_trace_278.pkl', 'train_trace_279.pkl', 'train_trace_280.pkl', 'train_trace_281.pkl', 'train_trace_282.pkl', 'train_trace_283.pkl', 'train_trace_284.pkl', 'train_trace_285.pkl', 'train_trace_286.pkl', 'train_trace_287.pkl', 'train_trace_288.pkl', 'train_trace_289.pkl', 'train_trace_290.pkl', 'train_trace_291.pkl', 'train_trace_292.pkl', 'train_trace_293.pkl', 'train_trace_294.pkl', 'train_trace_295.pkl', 'train_trace_296.pkl', 'train_trace_297.pkl', 'train_trace_298.pkl', 'train_trace_299.pkl', 'train_trace_300.pkl', 'train_trace_301.pkl', 'train_trace_302.pkl', 'train_trace_303.pkl', 'train_trace_304.pkl', 'train_trace_305.pkl', 'train_trace_306.pkl', 'train_trace_307.pkl', 'train_trace_308.pkl', 'train_trace_309.pkl', 'train_trace_310.pkl', 'train_trace_311.pkl', 'train_trace_312.pkl', 'train_trace_313.pkl', 'train_trace_314.pkl', 'train_trace_315.pkl', 'train_trace_316.pkl', 'train_trace_317.pkl', 'train_trace_318.pkl', 'train_trace_319.pkl', 'train_trace_320.pkl', 'train_trace_321.pkl', 'train_trace_322.pkl', 'train_trace_323.pkl', 'train_trace_324.pkl', 'train_trace_325.pkl', 'train_trace_326.pkl', 'train_trace_327.pkl', 'train_trace_328.pkl', 'train_trace_329.pkl', 'train_trace_330.pkl', 'train_trace_331.pkl', 'train_trace_332.pkl', 'train_trace_333.pkl', 'train_trace_334.pkl', 'train_trace_335.pkl', 'train_trace_336.pkl', 'train_trace_337.pkl', 'train_trace_338.pkl', 'train_trace_339.pkl', 'train_trace_340.pkl', 'train_trace_341.pkl', 'train_trace_342.pkl', 'train_trace_343.pkl', 'train_trace_344.pkl', 'train_trace_345.pkl', 'train_trace_346.pkl', 'train_trace_347.pkl', 'train_trace_348.pkl', 'train_trace_349.pkl', 'train_trace_350.pkl', 'train_trace_351.pkl', 'train_trace_352.pkl', 'train_trace_353.pkl', 'train_trace_354.pkl', 'train_trace_355.pkl', 'train_trace_356.pkl', 'train_trace_357.pkl', 'train_trace_358.pkl', 'train_trace_359.pkl', 'train_trace_360.pkl', 'train_trace_361.pkl', 'train_trace_362.pkl', 'train_trace_363.pkl', 'train_trace_364.pkl', 'train_trace_365.pkl', 'train_trace_366.pkl', 'train_trace_367.pkl', 'train_trace_368.pkl', 'train_trace_369.pkl', 'train_trace_370.pkl', 'train_trace_371.pkl', 'train_trace_372.pkl', 'train_trace_373.pkl', 'train_trace_374.pkl', 'train_trace_375.pkl', 'train_trace_376.pkl', 'train_trace_377.pkl', 'train_trace_378.pkl', 'train_trace_379.pkl', 'train_trace_380.pkl', 'train_trace_381.pkl', 'train_trace_382.pkl', 'train_trace_383.pkl', 'train_trace_384.pkl', 'train_trace_385.pkl', 'train_trace_386.pkl', 'train_trace_387.pkl', 'train_trace_388.pkl', 'train_trace_389.pkl', 'train_trace_390.pkl', 'train_trace_391.pkl', 'train_trace_392.pkl', 'train_trace_393.pkl', 'train_trace_394.pkl', 'train_trace_395.pkl']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 396/396 [01:41<00:00,  3.89it/s]\n"
     ]
    }
   ],
   "source": [
    "create_data_pickle = True\n",
    "if create_data_pickle:\n",
    "    files = os.listdir('data/train')\n",
    "    files.sort()\n",
    "    print(files)\n",
    "    list_of_dicts = []\n",
    "    types_to_include = ['ax', 'ay', 'az','gx', 'gy', 'gz', 'mx', 'my', 'mz', 'speed', 'longitude', 'latitude', 'altitude', 'phone_steps', 'temperature']\n",
    "    # types_to_include = ['ax', 'ay', 'az','gx', 'gy', 'gz','mx', 'my', 'mz',  'speed', 'altitude', 'phone_steps', 'temperature']\n",
    "\n",
    "    for file in tqdm(files):\n",
    "        Dict = {}\n",
    "        d = Recording(os.path.join('data/train',file))\n",
    "\n",
    "        Dict['labels'] = d.labels\n",
    "        for data_type in types_to_include:\n",
    "            if data_type in d.data.keys():\n",
    "                Dict[data_type] = d.data[data_type]\n",
    "        list_of_dicts.append(Dict)\n",
    "\n",
    "    data = pd.DataFrame(list_of_dicts)\n",
    "    data.to_pickle(path='data/pickled_and_sorted_training_data.pkl.zst', compression={'method': 'zstd'})\n",
    "else:\n",
    "    data = pd.read_pickle('data/pickled_and_sorted_training_data.pkl.zst')\n",
    "    data = data.drop(columns=['labels', 'ax', 'ay', 'az', 'mx', 'my', 'mz', 'speed', 'altitude',\n",
    "       'phone_steps', 'temperature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mag_norm(input):\n",
    "    return (np.sqrt(input[1]['mx'].values**2 + input[1]['my'].values**2 + input[1]['mz'].values**2))\n",
    "\n",
    "def calc_magneto_mag(input):\n",
    "\n",
    "    mag = []\n",
    "    with Pool(4) as p:\n",
    "        mag = p.map(mag_norm, input.iterrows())        \n",
    "    # print(mag)\n",
    "    return mag\n",
    "\n",
    "def accel_norm(input):\n",
    "    return (np.sqrt(input[1]['ax'].values**2 + input[1]['ay'].values**2 + input[1]['az'].values**2))\n",
    "\n",
    "def calc_accel_mag(input):\n",
    "\n",
    "    mag = []\n",
    "    with Pool(4) as p:\n",
    "        mag = p.map(accel_norm, input.iterrows())        \n",
    "    # print(mag)\n",
    "    return mag\n",
    "\n",
    "def gyro_norm(input):\n",
    "    return (np.sqrt(input[1]['gx'].values**2 + input[1]['gy'].values**2 + input[1]['gz'].values**2))\n",
    "\n",
    "def calc_gyro_mag(input):\n",
    "\n",
    "    mag = []\n",
    "    with Pool(4) as p:\n",
    "        mag = p.map(gyro_norm, input.iterrows())        \n",
    "    # print(mag)\n",
    "    return mag\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calced\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "calc_watch_vals = True\n",
    "if calc_watch_vals:\n",
    "\n",
    "    accel_mag   = calc_accel_mag(data)\n",
    "    print(\"calced\")\n",
    "    with open('data/accel_mag_train.pkl', 'wb') as f:\n",
    "        pickle.dump(accel_mag, f)\n",
    "        f.close()\n",
    "\n",
    "    # magneto_mag = calc_magneto_mag(data)\n",
    "    # print(\"calced\")\n",
    "\n",
    "    # with open('data/magneto_mag_train.pkl', 'wb') as f:\n",
    "    #     pickle.dump(magneto_mag, f)\n",
    "    #     f.close()\n",
    "        \n",
    "    # gyro_mag    = calc_gyro_mag(data)\n",
    "    # with open('data/gyro_mag_train.pkl', 'wb') as f:\n",
    "    #     pickle.dump(gyro_mag, f)\n",
    "    #     f.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handle phone data too, doesnt really work now\n",
    "def phone_mag_norm(input):\n",
    "    return (np.sqrt(input[1]['phone_mx'].values**2 + input[1]['phone_my'].values**2 + input[1]['phone_mz'].values**2))\n",
    "\n",
    "def calc_phone_magneto_mag(input):\n",
    "\n",
    "    mag = []\n",
    "    with Pool(8) as p:\n",
    "        mag = p.map(phone_mag_norm, data.iterrows())        \n",
    "    # print(mag)\n",
    "    return mag\n",
    "\n",
    "def phone_accel_norm(input):\n",
    "    if(len(input[1]['phone_ax'].values) != len(input[1]['phone_ay'].values**2) or len (input[1]['phone_ay'].values**2 ) != len(input[1]['phone_az'].values**2) or len (input[1]['phone_ax'].values**2 ) != len(input[1]['phone_az'].values**2)):\n",
    "        print(f\"{len(input[1]['phone_ax'].values)} {len(input[1]['phone_ay'].values**2)} {len(input[1]['phone_az'].values**2)}\" )\n",
    "\n",
    "    return (np.sqrt(input[1]['phone_ax'].values**2 + input[1]['phone_ay'].values**2 + input[1]['phone_az'].values**2))\n",
    "\n",
    "def calc_phone_accel_mag(input):\n",
    "\n",
    "    mag = []\n",
    "    with Pool(4) as p:\n",
    "        mag = p.map(phone_accel_norm, data.iterrows())        \n",
    "    print(mag)\n",
    "    return mag\n",
    "\n",
    "calc_phone_mags = False\n",
    "if calc_phone_mags:\n",
    "    phone_accel_mag = calc_phone_accel_mag(data)\n",
    "    phone_magneto_mag = calc_phone_magneto_mag(data)\n",
    "    with open('data/phone_accel_mag_train.pkl', 'wb') as f:\n",
    "        pickle.dump(phone_accel_mag, f)\n",
    "        f.close()\n",
    "\n",
    "    with open('data/phone_magneto_mag_train.pkl', 'wb') as f:\n",
    "        pickle.dump(phone_magneto_mag, f)\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/280 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 280/280 [00:19<00:00, 14.64it/s]\n"
     ]
    }
   ],
   "source": [
    "#rinse and repeat for test data\n",
    "create_data_pickle = True\n",
    "if create_data_pickle:\n",
    "    files = os.listdir('data/test')\n",
    "    files.sort()\n",
    "    list_of_dicts = []\n",
    "    types_to_include = ['ax', 'ay', 'az', 'gx', 'gy', 'gz', 'mx', 'my', 'mz']\n",
    "\n",
    "    for file in tqdm(files):\n",
    "        Dict = {}\n",
    "        d = Recording(os.path.join('data/test',file))\n",
    "\n",
    "        Dict['labels'] = d.labels\n",
    "        for data_type in types_to_include:\n",
    "            if data_type in d.data.keys():\n",
    "                Dict[data_type] = d.data[data_type]\n",
    "        list_of_dicts.append(Dict)\n",
    "\n",
    "    data_test = pd.DataFrame(list_of_dicts)\n",
    "    data_test.to_pickle(path='data/pickled_and_sorted_test_data.pkl.zst', compression={'method': 'zstd'})\n",
    "else:\n",
    "    data_test = pd.read_pickle('data/pickled_and_sorted_test_data.pkl.zst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calced\n"
     ]
    }
   ],
   "source": [
    "calc_watch_vals = True\n",
    "if calc_watch_vals:\n",
    "\n",
    "    accel_mag   = calc_accel_mag(data_test)\n",
    "\n",
    "    with open('data/accel_mag_test.pkl', 'wb') as f:\n",
    "        pickle.dump(accel_mag, f)\n",
    "        f.close()\n",
    "\n",
    "    magneto_mag = calc_magneto_mag(data_test)\n",
    "    print(\"calced\")\n",
    "\n",
    "    with open('data/magneto_mag_test.pkl', 'wb') as f:\n",
    "        pickle.dump(magneto_mag, f)\n",
    "        f.close()\n",
    "        \n",
    "    gyro_mag    = calc_gyro_mag(data_test)\n",
    "    with open('data/gyro_mag_test.pkl', 'wb') as f:\n",
    "        pickle.dump(gyro_mag, f)\n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['phone_mx', 'gx', 'altitude', 'phone_rotx', 'phone_steps', 'longitude', 'phone_gravy', 'lostPackets', 'phone_gz', 'latitude', 'phone_my', 'timestamp', 'gz', 'ax', 'my', 'phone_pressure', 'phone_gravx', 'phone_gy', 'phone_orientationx', 'temperature', 'phone_az', 'mz', 'az', 'gy', 'phone_mz', 'phone_rotm', 'phone_ax', 'packetNumber', 'phone_orientationz', 'phone_gravz', 'speed', 'bearing', 'phone_gx', 'phone_lax', 'phone_laz', 'phone_rotz', 'ay', 'phone_roty', 'phone_lay', 'mx', 'phone_ay', 'phone_orientationy'])\n"
     ]
    }
   ],
   "source": [
    "d = Recording('data/train/train_trace_000.pkl')\n",
    "print(d.data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 17/396 [00:06<02:32,  2.48it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/doruk/Documents/ders/mhealth/Wearable_Activity_Monitoring/pickle_doruk.ipynb Cell 9\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/doruk/Documents/ders/mhealth/Wearable_Activity_Monitoring/pickle_doruk.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mfor\u001b[39;00m file \u001b[39min\u001b[39;00m tqdm(files):\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/doruk/Documents/ders/mhealth/Wearable_Activity_Monitoring/pickle_doruk.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     Dict \u001b[39m=\u001b[39m {}\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/doruk/Documents/ders/mhealth/Wearable_Activity_Monitoring/pickle_doruk.ipynb#X11sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     d \u001b[39m=\u001b[39m Recording(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(\u001b[39m'\u001b[39;49m\u001b[39mdata/train\u001b[39;49m\u001b[39m'\u001b[39;49m,file))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/doruk/Documents/ders/mhealth/Wearable_Activity_Monitoring/pickle_doruk.ipynb#X11sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     Dict[\u001b[39m\"\u001b[39m\u001b[39maccel_time\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m d\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39max\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtimestamps\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/doruk/Documents/ders/mhealth/Wearable_Activity_Monitoring/pickle_doruk.ipynb#X11sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     Dict[\u001b[39m\"\u001b[39m\u001b[39mgyro_time\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m d\u001b[39m.\u001b[39mdata[\u001b[39m'\u001b[39m\u001b[39mgx\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtimestamps\n",
      "File \u001b[0;32m~/Documents/ders/mhealth/Wearable_Activity_Monitoring/mhealth_activity/recording.py:47\u001b[0m, in \u001b[0;36mRecording.__init__\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilename \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mbasename(path)\n\u001b[1;32m     46\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m---> 47\u001b[0m     data_dict \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(f)\n\u001b[1;32m     48\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlabels \u001b[39m=\u001b[39m data_dict[\u001b[39m\"\u001b[39m\u001b[39mlabels\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m     49\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m {key: Trace\u001b[39m.\u001b[39mfrom_dict(trace_dict) \u001b[39mfor\u001b[39;00m key, trace_dict \u001b[39min\u001b[39;00m data_dict[\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mitems()}\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "files = os.listdir('data/train')\n",
    "files.sort()\n",
    "list_of_dicts = []\n",
    "# types_to_include = ['ax', 'ay', 'az','gx', 'gy', 'gz', 'phone_ax', 'phone_ay', 'phone_az', 'mx', 'my', 'mz', 'phone_mx', 'phone_my', 'phone_mz', 'speed', 'longitude', 'latitude', 'altitude', 'phone_steps', 'temperature']\n",
    "types_to_include = ['ax', 'gx', 'gy', 'gz','mx', 'my', 'mz',  'speed', 'altitude', 'phone_steps', 'temperature']\n",
    "\n",
    "for file in tqdm(files):\n",
    "    Dict = {}\n",
    "    d = Recording(os.path.join('data/train',file))\n",
    "\n",
    "    Dict[\"accel_time\"] = d.data['ax'].timestamps\n",
    "    Dict[\"gyro_time\"] = d.data['gx'].timestamps\n",
    "    Dict[\"magneto_time\"] = d.data['mx'].timestamps\n",
    "\n",
    "    list_of_dicts.append(Dict)\n",
    "    \n",
    "data = pd.DataFrame(list_of_dicts)\n",
    "data.to_pickle(path='data/pickled_and_sorted_training_data.pkl.zst', compression={'method': 'zstd'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You may change the mhealth_activity module but your algorithm must support the original version\n",
    "from mhealth_activity import Recording, Trace, Activity, WatchLocation, Path\n",
    "\n",
    "# For interactive plots, uncomment the following line\n",
    "# %matplotlib widget\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.fft import fft, fftfreq\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error,accuracy_score,precision_score,recall_score,confusion_matrix,classification_report,f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "create_data_pickle = False\n",
    "if create_data_pickle:\n",
    "    files = os.listdir('data/train')\n",
    "    list_of_dicts = []\n",
    "    types_to_include = ['ax', 'ay', 'az', 'phone_ax', 'phone_ay', 'phone_az', 'speed', 'longitude', 'latitude', 'altitude', 'phone_steps']\n",
    "\n",
    "    for file in tqdm(files):\n",
    "        Dict = {}\n",
    "        d = Recording(os.path.join('data/train',file))\n",
    "\n",
    "        Dict['labels'] = d.labels\n",
    "        for data_type in types_to_include:\n",
    "            if data_type in d.data.keys():\n",
    "                Dict[data_type] = d.data[data_type]\n",
    "        list_of_dicts.append(Dict)\n",
    "\n",
    "    data = pd.DataFrame(list_of_dicts)\n",
    "    data.to_pickle(path='data/pickled_and_sorted_training_data.pkl.zst', compression={'method': 'zstd'})\n",
    "else:\n",
    "    data = pd.read_pickle('data/pickled_and_sorted_training_data.pkl.zst')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_idx</th>\n",
       "      <th>smartwatch_location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     path_idx  smartwatch_location\n",
       "0           2                    1\n",
       "1           0                    0\n",
       "2           0                    0\n",
       "3           2                    1\n",
       "4           1                    1\n",
       "..        ...                  ...\n",
       "391         3                    2\n",
       "392         4                    0\n",
       "393         2                    1\n",
       "394         3                    0\n",
       "395         0                    1\n",
       "\n",
       "[396 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load pickled training 3d norm accelerometer data\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "file = open('accel_mag_train.pkl', 'rb')\n",
    "pickled = pickle.load(file)\n",
    "accel_mag_train =  pd.DataFrame(((x,) for x in pickled), columns=['lists'])\n",
    "print(accel_mag_train.shape)\n",
    "file.close()\n",
    "\n",
    "labels = []\n",
    "for label in data[\"labels\"]:\n",
    "    labels.extend([[label[\"path_idx\"],label[\"watch_loc\"]]])\n",
    "labels = pd.DataFrame(labels, columns =['path_idx', \"smartwatch_location\"])\n",
    "labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "altitude_data = [x.values[::15] for x in data[\"altitude\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe_altitude = pd.DataFrame(altitude_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extraction(df): \n",
    "    \n",
    "    FEATURES = ['MIN','MAX','MEAN','RMS','VAR','STD','POWER','PEAK','P2P','CREST FACTOR','SKEW','KURTOSIS',\n",
    "            'MAX_f','SUM_f','MEAN_f','VAR_f','PEAK_f','SKEW_f','KURTOSIS_f']\n",
    "    \n",
    "    Min=[];Max=[];Mean=[];Rms=[];Var=[];Std=[];Power=[];Peak=[];Skew=[];Kurtosis=[];P2p=[];CrestFactor=[];\n",
    "    FormFactor=[]; PulseIndicator=[];\n",
    "    Max_f=[];Sum_f=[];Mean_f=[];Var_f=[];Peak_f=[];Skew_f=[];Kurtosis_f=[]\n",
    "    \n",
    "    X = df.values\n",
    "    ## TIME DOMAIN ##\n",
    "    #list of lists of lists, ugly as fuck but it works \n",
    "    for recording in X:\n",
    "        Min.append(np.min(recording[0]))\n",
    "        Max.append(np.max(recording[0]))\n",
    "        Mean.append(np.mean(recording[0]))\n",
    "        Rms.append(np.sqrt(np.mean(recording[0]**2)))\n",
    "        Var.append(np.var(recording[0]))\n",
    "        Std.append(np.std(recording[0]))\n",
    "        Power.append(np.mean(recording[0]**2))\n",
    "        Peak.append(np.max(np.abs(recording[0])))\n",
    "        P2p.append(np.ptp(recording[0]))\n",
    "        CrestFactor.append(np.max(np.abs(recording[0]))/np.sqrt(np.mean(recording[0]**2)))\n",
    "        Skew.append(stats.skew(recording[0]))\n",
    "        Kurtosis.append(stats.kurtosis(recording[0]))\n",
    "        FormFactor.append(np.sqrt(np.mean(recording[0]**2))/np.mean(recording[0]))\n",
    "        PulseIndicator.append(np.max(np.abs(recording[0]))/np.mean(recording[0]))\n",
    "        ## FREQ DOMAIN ##\n",
    "        ft = fft(recording[0])\n",
    "        S = np.abs(ft**2)/len(df)\n",
    "        Max_f.append(np.max(S))\n",
    "        Sum_f.append(np.sum(S))\n",
    "        Mean_f.append(np.mean(S))\n",
    "        Var_f.append(np.var(S))\n",
    "        \n",
    "        Peak_f.append(np.max(np.abs(S)))\n",
    "        Skew_f.append(stats.skew(recording[0]))\n",
    "        Kurtosis_f.append(stats.kurtosis(recording[0]))\n",
    "\n",
    "    \n",
    "    #Create dataframe from features\n",
    "    df_features = pd.DataFrame(index = [FEATURES], \n",
    "                               data = [Min,Max,Mean,Rms,Var,Std,Power,Peak,P2p,CrestFactor,Skew,Kurtosis,\n",
    "                                       Max_f,Sum_f,Mean_f,Var_f,Peak_f,Skew_f,Kurtosis_f])\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MIN</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MEAN</th>\n",
       "      <th>RMS</th>\n",
       "      <th>VAR</th>\n",
       "      <th>STD</th>\n",
       "      <th>POWER</th>\n",
       "      <th>PEAK</th>\n",
       "      <th>P2P</th>\n",
       "      <th>CREST FACTOR</th>\n",
       "      <th>SKEW</th>\n",
       "      <th>KURTOSIS</th>\n",
       "      <th>MAX_f</th>\n",
       "      <th>SUM_f</th>\n",
       "      <th>MEAN_f</th>\n",
       "      <th>VAR_f</th>\n",
       "      <th>PEAK_f</th>\n",
       "      <th>SKEW_f</th>\n",
       "      <th>KURTOSIS_f</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.153406</td>\n",
       "      <td>2.597480</td>\n",
       "      <td>1.202418</td>\n",
       "      <td>1.221131</td>\n",
       "      <td>0.045352</td>\n",
       "      <td>0.212961</td>\n",
       "      <td>1.491161</td>\n",
       "      <td>2.597480</td>\n",
       "      <td>2.444074</td>\n",
       "      <td>2.127110</td>\n",
       "      <td>0.176443</td>\n",
       "      <td>0.543339</td>\n",
       "      <td>5.469889e+07</td>\n",
       "      <td>5.641470e+07</td>\n",
       "      <td>460.904406</td>\n",
       "      <td>2.444401e+10</td>\n",
       "      <td>5.469889e+07</td>\n",
       "      <td>0.176443</td>\n",
       "      <td>0.543339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.046882</td>\n",
       "      <td>2.826338</td>\n",
       "      <td>1.092686</td>\n",
       "      <td>1.149698</td>\n",
       "      <td>0.127844</td>\n",
       "      <td>0.357553</td>\n",
       "      <td>1.321806</td>\n",
       "      <td>2.826338</td>\n",
       "      <td>2.779456</td>\n",
       "      <td>2.458331</td>\n",
       "      <td>0.346138</td>\n",
       "      <td>-0.193552</td>\n",
       "      <td>4.173153e+07</td>\n",
       "      <td>4.619995e+07</td>\n",
       "      <td>392.696408</td>\n",
       "      <td>1.480367e+10</td>\n",
       "      <td>4.173153e+07</td>\n",
       "      <td>0.346138</td>\n",
       "      <td>-0.193552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.083755</td>\n",
       "      <td>3.057903</td>\n",
       "      <td>1.093724</td>\n",
       "      <td>1.135764</td>\n",
       "      <td>0.093728</td>\n",
       "      <td>0.306151</td>\n",
       "      <td>1.289960</td>\n",
       "      <td>3.057903</td>\n",
       "      <td>2.974148</td>\n",
       "      <td>2.692375</td>\n",
       "      <td>1.456056</td>\n",
       "      <td>3.479315</td>\n",
       "      <td>4.175404e+07</td>\n",
       "      <td>4.502559e+07</td>\n",
       "      <td>382.974880</td>\n",
       "      <td>1.482894e+10</td>\n",
       "      <td>4.175404e+07</td>\n",
       "      <td>1.456056</td>\n",
       "      <td>3.479315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.276498</td>\n",
       "      <td>2.088655</td>\n",
       "      <td>1.026057</td>\n",
       "      <td>1.083954</td>\n",
       "      <td>0.122162</td>\n",
       "      <td>0.349516</td>\n",
       "      <td>1.174955</td>\n",
       "      <td>2.088655</td>\n",
       "      <td>1.812157</td>\n",
       "      <td>1.926886</td>\n",
       "      <td>0.348455</td>\n",
       "      <td>-0.611317</td>\n",
       "      <td>3.086272e+07</td>\n",
       "      <td>3.444390e+07</td>\n",
       "      <td>319.682780</td>\n",
       "      <td>8.841351e+09</td>\n",
       "      <td>3.086272e+07</td>\n",
       "      <td>0.348455</td>\n",
       "      <td>-0.611317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.080601</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>1.078819</td>\n",
       "      <td>1.119106</td>\n",
       "      <td>0.088548</td>\n",
       "      <td>0.297570</td>\n",
       "      <td>1.252399</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>3.383500</td>\n",
       "      <td>3.095418</td>\n",
       "      <td>2.066954</td>\n",
       "      <td>9.037060</td>\n",
       "      <td>1.734226e+07</td>\n",
       "      <td>1.866169e+07</td>\n",
       "      <td>242.940102</td>\n",
       "      <td>3.915198e+09</td>\n",
       "      <td>1.734226e+07</td>\n",
       "      <td>2.066954</td>\n",
       "      <td>9.037060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0.093611</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>1.551828</td>\n",
       "      <td>1.678641</td>\n",
       "      <td>0.409665</td>\n",
       "      <td>0.640051</td>\n",
       "      <td>2.817836</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>3.370491</td>\n",
       "      <td>2.063635</td>\n",
       "      <td>0.761946</td>\n",
       "      <td>-0.359174</td>\n",
       "      <td>8.212287e+07</td>\n",
       "      <td>9.609317e+07</td>\n",
       "      <td>826.906681</td>\n",
       "      <td>5.804152e+10</td>\n",
       "      <td>8.212287e+07</td>\n",
       "      <td>0.761946</td>\n",
       "      <td>-0.359174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>0.025811</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>1.468600</td>\n",
       "      <td>1.625606</td>\n",
       "      <td>0.485809</td>\n",
       "      <td>0.697000</td>\n",
       "      <td>2.642595</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>3.438291</td>\n",
       "      <td>2.130960</td>\n",
       "      <td>0.905103</td>\n",
       "      <td>-0.054596</td>\n",
       "      <td>7.030573e+07</td>\n",
       "      <td>8.614188e+07</td>\n",
       "      <td>758.184439</td>\n",
       "      <td>4.351259e+10</td>\n",
       "      <td>7.030573e+07</td>\n",
       "      <td>0.905103</td>\n",
       "      <td>-0.054596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>0.034486</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>1.294628</td>\n",
       "      <td>1.425602</td>\n",
       "      <td>0.356279</td>\n",
       "      <td>0.596891</td>\n",
       "      <td>2.032342</td>\n",
       "      <td>3.464102</td>\n",
       "      <td>3.429616</td>\n",
       "      <td>2.429922</td>\n",
       "      <td>1.162461</td>\n",
       "      <td>0.824875</td>\n",
       "      <td>1.761473e+07</td>\n",
       "      <td>2.135908e+07</td>\n",
       "      <td>331.086919</td>\n",
       "      <td>4.811941e+09</td>\n",
       "      <td>1.761473e+07</td>\n",
       "      <td>1.162461</td>\n",
       "      <td>0.824875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0.032321</td>\n",
       "      <td>3.464066</td>\n",
       "      <td>0.996864</td>\n",
       "      <td>1.078101</td>\n",
       "      <td>0.168563</td>\n",
       "      <td>0.410565</td>\n",
       "      <td>1.162301</td>\n",
       "      <td>3.464066</td>\n",
       "      <td>3.431746</td>\n",
       "      <td>3.213119</td>\n",
       "      <td>0.854506</td>\n",
       "      <td>1.884827</td>\n",
       "      <td>4.478016e+07</td>\n",
       "      <td>5.237601e+07</td>\n",
       "      <td>392.082963</td>\n",
       "      <td>1.501348e+10</td>\n",
       "      <td>4.478016e+07</td>\n",
       "      <td>0.854506</td>\n",
       "      <td>1.884827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>0.218100</td>\n",
       "      <td>2.383891</td>\n",
       "      <td>1.020193</td>\n",
       "      <td>1.059278</td>\n",
       "      <td>0.081276</td>\n",
       "      <td>0.285089</td>\n",
       "      <td>1.122070</td>\n",
       "      <td>2.383891</td>\n",
       "      <td>2.165791</td>\n",
       "      <td>2.250487</td>\n",
       "      <td>0.685253</td>\n",
       "      <td>0.171590</td>\n",
       "      <td>5.498526e+07</td>\n",
       "      <td>5.927908e+07</td>\n",
       "      <td>409.838763</td>\n",
       "      <td>2.090276e+10</td>\n",
       "      <td>5.498526e+07</td>\n",
       "      <td>0.685253</td>\n",
       "      <td>0.171590</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          MIN       MAX      MEAN       RMS       VAR       STD     POWER  \\\n",
       "0    0.153406  2.597480  1.202418  1.221131  0.045352  0.212961  1.491161   \n",
       "1    0.046882  2.826338  1.092686  1.149698  0.127844  0.357553  1.321806   \n",
       "2    0.083755  3.057903  1.093724  1.135764  0.093728  0.306151  1.289960   \n",
       "3    0.276498  2.088655  1.026057  1.083954  0.122162  0.349516  1.174955   \n",
       "4    0.080601  3.464102  1.078819  1.119106  0.088548  0.297570  1.252399   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "391  0.093611  3.464102  1.551828  1.678641  0.409665  0.640051  2.817836   \n",
       "392  0.025811  3.464102  1.468600  1.625606  0.485809  0.697000  2.642595   \n",
       "393  0.034486  3.464102  1.294628  1.425602  0.356279  0.596891  2.032342   \n",
       "394  0.032321  3.464066  0.996864  1.078101  0.168563  0.410565  1.162301   \n",
       "395  0.218100  2.383891  1.020193  1.059278  0.081276  0.285089  1.122070   \n",
       "\n",
       "         PEAK       P2P  CREST FACTOR      SKEW  KURTOSIS         MAX_f  \\\n",
       "0    2.597480  2.444074      2.127110  0.176443  0.543339  5.469889e+07   \n",
       "1    2.826338  2.779456      2.458331  0.346138 -0.193552  4.173153e+07   \n",
       "2    3.057903  2.974148      2.692375  1.456056  3.479315  4.175404e+07   \n",
       "3    2.088655  1.812157      1.926886  0.348455 -0.611317  3.086272e+07   \n",
       "4    3.464102  3.383500      3.095418  2.066954  9.037060  1.734226e+07   \n",
       "..        ...       ...           ...       ...       ...           ...   \n",
       "391  3.464102  3.370491      2.063635  0.761946 -0.359174  8.212287e+07   \n",
       "392  3.464102  3.438291      2.130960  0.905103 -0.054596  7.030573e+07   \n",
       "393  3.464102  3.429616      2.429922  1.162461  0.824875  1.761473e+07   \n",
       "394  3.464066  3.431746      3.213119  0.854506  1.884827  4.478016e+07   \n",
       "395  2.383891  2.165791      2.250487  0.685253  0.171590  5.498526e+07   \n",
       "\n",
       "            SUM_f      MEAN_f         VAR_f        PEAK_f    SKEW_f  \\\n",
       "0    5.641470e+07  460.904406  2.444401e+10  5.469889e+07  0.176443   \n",
       "1    4.619995e+07  392.696408  1.480367e+10  4.173153e+07  0.346138   \n",
       "2    4.502559e+07  382.974880  1.482894e+10  4.175404e+07  1.456056   \n",
       "3    3.444390e+07  319.682780  8.841351e+09  3.086272e+07  0.348455   \n",
       "4    1.866169e+07  242.940102  3.915198e+09  1.734226e+07  2.066954   \n",
       "..            ...         ...           ...           ...       ...   \n",
       "391  9.609317e+07  826.906681  5.804152e+10  8.212287e+07  0.761946   \n",
       "392  8.614188e+07  758.184439  4.351259e+10  7.030573e+07  0.905103   \n",
       "393  2.135908e+07  331.086919  4.811941e+09  1.761473e+07  1.162461   \n",
       "394  5.237601e+07  392.082963  1.501348e+10  4.478016e+07  0.854506   \n",
       "395  5.927908e+07  409.838763  2.090276e+10  5.498526e+07  0.685253   \n",
       "\n",
       "     KURTOSIS_f  \n",
       "0      0.543339  \n",
       "1     -0.193552  \n",
       "2      3.479315  \n",
       "3     -0.611317  \n",
       "4      9.037060  \n",
       "..          ...  \n",
       "391   -0.359174  \n",
       "392   -0.054596  \n",
       "393    0.824875  \n",
       "394    1.884827  \n",
       "395    0.171590  \n",
       "\n",
       "[396 rows x 19 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#extract features from accelerometer norm and get rid of multiindex\n",
    "features = pd.DataFrame.transpose(features_extraction(accel_mag_train))\n",
    "features.columns = features.columns.map(''.join)\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import find_peaks\n",
    "\n",
    "altitude_gradients = []\n",
    "for sample in altitude_data:\n",
    "    altitude_gradients.append(np.gradient(sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Try to make slopes based on not every signal but on every 20th signal or so"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "altitude_gradients = pd.DataFrame(altitude_gradients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "452.98732080776244"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "altitude_data[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = []\n",
    "for i in range(len(altitude_data)):\n",
    "    first.append(altitude_data[i][0])\n",
    "\n",
    "last = []\n",
    "for i in range(len(altitude_data)):\n",
    "    last.append(altitude_data[i][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>407.332413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>407.676311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>456.399994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>471.688363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>457.399994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>451.697559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>436.882629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>456.395513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>501.199982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>408.384979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0\n",
       "0    407.332413\n",
       "1    407.676311\n",
       "2    456.399994\n",
       "3    471.688363\n",
       "4    457.399994\n",
       "..          ...\n",
       "391  451.697559\n",
       "392  436.882629\n",
       "393  456.395513\n",
       "394  501.199982\n",
       "395  408.384979\n",
       "\n",
       "[396 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.concat([features,altitude_gradients,pd.DataFrame(first),pd.DataFrame(last)],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 2 2 2 3 4 4 2 0 2 4 3 3 4 4 1 2 4 2 4 2 4 3 3 2 2 3 4 2 3 2 2 4 1 3 2 2\n",
      " 2 4 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import randint\n",
    "\n",
    "def split_and_train(X_train,y_train):\n",
    "\n",
    "    X_train.columns = [''] * len(X_train.columns)\n",
    "    X_train.fillna(0, inplace=True)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train.to_numpy(), y_train.to_numpy(), test_size=0.1, random_state=10)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train) \n",
    "    X_test = scaler.fit_transform(X_test) \n",
    "\n",
    "    param_dist = {'n_estimators': randint(50,500),\n",
    "              'max_depth': randint(1,20)}\n",
    "\n",
    "    # Instantiate model with 1000 decision trees, use all cores\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    # Use random search to find the best hyperparameters\n",
    "    rand_search = RandomizedSearchCV(rf, \n",
    "                                 param_distributions = param_dist, \n",
    "                                 n_iter=10, \n",
    "                                 cv=5)\n",
    "\n",
    "    # Fit the random search object to the data\n",
    "    rand_search.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = np.round(rand_search.predict(X_test),0)\n",
    "\n",
    "    print(y_pred)\n",
    "    return rand_search,y_pred,y_test,X_train,X_test\n",
    "\n",
    "rf_model,y_pred,y_test,X_train,X_test = split_and_train(total,labels[\"path_idx\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhavenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

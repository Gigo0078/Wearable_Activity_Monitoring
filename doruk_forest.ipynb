{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You may change the mhealth_activity module but your algorithm must support the original version\n",
    "from mhealth_activity import Recording, Trace, Activity, WatchLocation, Path\n",
    "\n",
    "# For interactive plots, uncomment the following line\n",
    "# %matplotlib widget\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tqdm\n",
    "from scipy.fft import fft, fftfreq\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "create_data_pickle = False\n",
    "if create_data_pickle:\n",
    "    files = os.listdir('data/train')\n",
    "    list_of_dicts = []\n",
    "    types_to_include = ['ax', 'ay', 'az', 'phone_ax', 'phone_ay', 'phone_az', 'speed', 'longitude', 'latitude', 'altitude', 'phone_steps']\n",
    "\n",
    "    for file in tqdm(files):\n",
    "        Dict = {}\n",
    "        d = Recording(os.path.join('data/train',file))\n",
    "\n",
    "        Dict['labels'] = d.labels\n",
    "        for data_type in types_to_include:\n",
    "            if data_type in d.data.keys():\n",
    "                Dict[data_type] = d.data[data_type]\n",
    "        list_of_dicts.append(Dict)\n",
    "\n",
    "    data = pd.DataFrame(list_of_dicts)\n",
    "    data.to_pickle(path='data/pickled_and_sorted_training_data.pkl.zst', compression={'method': 'zstd'})\n",
    "else:\n",
    "    data = pd.read_pickle('data/pickled_and_sorted_training_data.pkl.zst')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extraction(df): \n",
    "    \n",
    "    FEATURES = ['MIN','MAX','MEAN','RMS','VAR','STD','POWER','PEAK','P2P','CREST FACTOR','SKEW','KURTOSIS',\n",
    "            'MAX_f','SUM_f','MEAN_f','VAR_f','PEAK_f','SKEW_f','KURTOSIS_f']\n",
    "    \n",
    "    Min=[];Max=[];Mean=[];Rms=[];Var=[];Std=[];Power=[];Peak=[];Skew=[];Kurtosis=[];P2p=[];CrestFactor=[];\n",
    "    FormFactor=[]; PulseIndicator=[];\n",
    "    Max_f=[];Sum_f=[];Mean_f=[];Var_f=[];Peak_f=[];Skew_f=[];Kurtosis_f=[]\n",
    "    \n",
    "    X = df.values\n",
    "    ## TIME DOMAIN ##\n",
    "    #list of lists of lists, ugly as fuck but it works \n",
    "    for recording in X:\n",
    "        Min.append(np.min(recording[0]))\n",
    "        Max.append(np.max(recording[0]))\n",
    "        Mean.append(np.mean(recording[0]))\n",
    "        Rms.append(np.sqrt(np.mean(recording[0]**2)))\n",
    "        Var.append(np.var(recording[0]))\n",
    "        Std.append(np.std(recording[0]))\n",
    "        Power.append(np.mean(recording[0]**2))\n",
    "        Peak.append(np.max(np.abs(recording[0])))\n",
    "        P2p.append(np.ptp(recording[0]))\n",
    "        CrestFactor.append(np.max(np.abs(recording[0]))/np.sqrt(np.mean(recording[0]**2)))\n",
    "        Skew.append(stats.skew(recording[0]))\n",
    "        Kurtosis.append(stats.kurtosis(recording[0]))\n",
    "        FormFactor.append(np.sqrt(np.mean(recording[0]**2))/np.mean(recording[0]))\n",
    "        PulseIndicator.append(np.max(np.abs(recording[0]))/np.mean(recording[0]))\n",
    "        ## FREQ DOMAIN ##\n",
    "        ft = fft(recording[0])\n",
    "        S = np.abs(ft**2)/len(df)\n",
    "        Max_f.append(np.max(S))\n",
    "        Sum_f.append(np.sum(S))\n",
    "        Mean_f.append(np.mean(S))\n",
    "        Var_f.append(np.var(S))\n",
    "        \n",
    "        Peak_f.append(np.max(np.abs(S)))\n",
    "        Skew_f.append(stats.skew(recording[0]))\n",
    "        Kurtosis_f.append(stats.kurtosis(recording[0]))\n",
    "    #Create dataframe from features\n",
    "    df_features = pd.DataFrame(index = [FEATURES], \n",
    "                               data = [Min,Max,Mean,Rms,Var,Std,Power,Peak,P2p,CrestFactor,Skew,Kurtosis,\n",
    "                                       Max_f,Sum_f,Mean_f,Var_f,Peak_f,Skew_f,Kurtosis_f])\n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396, 1)\n"
     ]
    }
   ],
   "source": [
    "#load pickled training 3d norm accelerometer data\n",
    "file = open('data/accel_mag_train.pkl', 'rb')\n",
    "pickled = pickle.load(file)\n",
    "accel_mag_train =  pd.DataFrame(((x,) for x in pickled), columns=['lists'])\n",
    "print(accel_mag_train.shape)\n",
    "file.close()\n",
    "\n",
    "labels = []\n",
    "for label in data[\"labels\"]:\n",
    "    labels.extend([[label[\"path_idx\"],label[\"activities\"],label[\"step_count\"],label[\"watch_loc\"]]])\n",
    "labels = pd.DataFrame(labels, columns =['path_idx', 'activities', \"step_count\", \"smartwatch_location\"])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0076106  1.00275902 1.00581143 ... 1.1451823  1.15308679 1.1590346 ]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Too many levels: Index has only 1 level, not 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/doruk/Documents/ders/mhealth/Wearable_Activity_Monitoring/doruk_forest.ipynb Cell 5\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/doruk/Documents/ders/mhealth/Wearable_Activity_Monitoring/doruk_forest.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(accel_mag_train\u001b[39m.\u001b[39mvalues[\u001b[39m2\u001b[39m][\u001b[39m0\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/doruk/Documents/ders/mhealth/Wearable_Activity_Monitoring/doruk_forest.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_features \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mtranspose(features_extraction(accel_mag_train))\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/doruk/Documents/ders/mhealth/Wearable_Activity_Monitoring/doruk_forest.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m train_features \u001b[39m=\u001b[39m train_features\u001b[39m.\u001b[39;49mreset_index(level\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/doruk/Documents/ders/mhealth/Wearable_Activity_Monitoring/doruk_forest.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m train_features\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/frame.py:6314\u001b[0m, in \u001b[0;36mDataFrame.reset_index\u001b[0;34m(self, level, drop, inplace, col_level, col_fill, allow_duplicates, names)\u001b[0m\n\u001b[1;32m   6312\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(level, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m)):\n\u001b[1;32m   6313\u001b[0m     level \u001b[39m=\u001b[39m [level]\n\u001b[0;32m-> 6314\u001b[0m level \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49m_get_level_number(lev) \u001b[39mfor\u001b[39;49;00m lev \u001b[39min\u001b[39;49;00m level]\n\u001b[1;32m   6315\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(level) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mnlevels:\n\u001b[1;32m   6316\u001b[0m     new_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mdroplevel(level)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/frame.py:6314\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   6312\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(level, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m)):\n\u001b[1;32m   6313\u001b[0m     level \u001b[39m=\u001b[39m [level]\n\u001b[0;32m-> 6314\u001b[0m level \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49m_get_level_number(lev) \u001b[39mfor\u001b[39;00m lev \u001b[39min\u001b[39;00m level]\n\u001b[1;32m   6315\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(level) \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mnlevels:\n\u001b[1;32m   6316\u001b[0m     new_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mdroplevel(level)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/indexes/base.py:2055\u001b[0m, in \u001b[0;36mIndex._get_level_number\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   2054\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_level_number\u001b[39m(\u001b[39mself\u001b[39m, level) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m-> 2055\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_index_level(level)\n\u001b[1;32m   2056\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/indexes/base.py:2046\u001b[0m, in \u001b[0;36mIndex._validate_index_level\u001b[0;34m(self, level)\u001b[0m\n\u001b[1;32m   2041\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[1;32m   2042\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mToo many levels: Index has only 1 level, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2043\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlevel\u001b[39m}\u001b[39;00m\u001b[39m is not a valid level number\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2044\u001b[0m         )\n\u001b[1;32m   2045\u001b[0m     \u001b[39melif\u001b[39;00m level \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 2046\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\n\u001b[1;32m   2047\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mToo many levels: Index has only 1 level, not \u001b[39m\u001b[39m{\u001b[39;00mlevel\u001b[39m \u001b[39m\u001b[39m+\u001b[39m\u001b[39m \u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2048\u001b[0m         )\n\u001b[1;32m   2049\u001b[0m \u001b[39melif\u001b[39;00m level \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname:\n\u001b[1;32m   2050\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\n\u001b[1;32m   2051\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mRequested level (\u001b[39m\u001b[39m{\u001b[39;00mlevel\u001b[39m}\u001b[39;00m\u001b[39m) does not match index name (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2052\u001b[0m     )\n",
      "\u001b[0;31mIndexError\u001b[0m: Too many levels: Index has only 1 level, not 2"
     ]
    }
   ],
   "source": [
    "print(accel_mag_train.values[2][0])\n",
    "train_features = pd.DataFrame.transpose(features_extraction(accel_mag_train))\n",
    "train_features = train_features.reset_index(level=1)\n",
    "train_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([(         'MIN',),\n",
      "            (         'MAX',),\n",
      "            (        'MEAN',),\n",
      "            (         'RMS',),\n",
      "            (         'VAR',),\n",
      "            (         'STD',),\n",
      "            (       'POWER',),\n",
      "            (        'PEAK',),\n",
      "            (         'P2P',),\n",
      "            ('CREST FACTOR',),\n",
      "            (        'SKEW',),\n",
      "            (    'KURTOSIS',),\n",
      "            (       'MAX_f',),\n",
      "            (       'SUM_f',),\n",
      "            (      'MEAN_f',),\n",
      "            (       'VAR_f',),\n",
      "            (      'PEAK_f',),\n",
      "            (      'SKEW_f',),\n",
      "            (  'KURTOSIS_f',)],\n",
      "           )\n",
      "Index(['path_idx', 'activities', 'step_count', 'smartwatch_location'], dtype='object')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "no types given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/doruk/Documents/ders/mhealth/Wearable_Activity_Monitoring/doruk_forest.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/doruk/Documents/ders/mhealth/Wearable_Activity_Monitoring/doruk_forest.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(train_features\u001b[39m.\u001b[39mcolumns)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/doruk/Documents/ders/mhealth/Wearable_Activity_Monitoring/doruk_forest.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(labels\u001b[39m.\u001b[39mcolumns)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/doruk/Documents/ders/mhealth/Wearable_Activity_Monitoring/doruk_forest.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m random_forest_data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mconcat([train_features,labels],axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/reshape/concat.py:381\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[39mConcatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[39m1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    368\u001b[0m op \u001b[39m=\u001b[39m _Concatenator(\n\u001b[1;32m    369\u001b[0m     objs,\n\u001b[1;32m    370\u001b[0m     axis\u001b[39m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    378\u001b[0m     sort\u001b[39m=\u001b[39msort,\n\u001b[1;32m    379\u001b[0m )\n\u001b[0;32m--> 381\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mget_result()\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/reshape/concat.py:616\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m             indexers[ax] \u001b[39m=\u001b[39m obj_labels\u001b[39m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    614\u001b[0m     mgrs_indexers\u001b[39m.\u001b[39mappend((obj\u001b[39m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 616\u001b[0m new_data \u001b[39m=\u001b[39m concatenate_managers(\n\u001b[1;32m    617\u001b[0m     mgrs_indexers, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnew_axes, concat_axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbm_axis, copy\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcopy\n\u001b[1;32m    618\u001b[0m )\n\u001b[1;32m    619\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcopy:\n\u001b[1;32m    620\u001b[0m     new_data\u001b[39m.\u001b[39m_consolidate_inplace()\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/internals/concat.py:233\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    231\u001b[0m     fastpath \u001b[39m=\u001b[39m blk\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m values\u001b[39m.\u001b[39mdtype\n\u001b[1;32m    232\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 233\u001b[0m     values \u001b[39m=\u001b[39m _concatenate_join_units(join_units, concat_axis, copy\u001b[39m=\u001b[39;49mcopy)\n\u001b[1;32m    234\u001b[0m     fastpath \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m fastpath:\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/internals/concat.py:537\u001b[0m, in \u001b[0;36m_concatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[39mif\u001b[39;00m concat_axis \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(join_units) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    534\u001b[0m     \u001b[39m# Concatenating join units along ax0 is handled in _merge_blocks.\u001b[39;00m\n\u001b[1;32m    535\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mConcatenating join units along axis0\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 537\u001b[0m empty_dtype \u001b[39m=\u001b[39m _get_empty_dtype(join_units)\n\u001b[1;32m    539\u001b[0m has_none_blocks \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(unit\u001b[39m.\u001b[39mblock\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mV\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m join_units)\n\u001b[1;32m    540\u001b[0m upcasted_na \u001b[39m=\u001b[39m _dtype_to_na_value(empty_dtype, has_none_blocks)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/internals/concat.py:629\u001b[0m, in \u001b[0;36m_get_empty_dtype\u001b[0;34m(join_units)\u001b[0m\n\u001b[1;32m    626\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mlen\u001b[39m(dtypes):\n\u001b[1;32m    627\u001b[0m     dtypes \u001b[39m=\u001b[39m [unit\u001b[39m.\u001b[39mdtype \u001b[39mfor\u001b[39;00m unit \u001b[39min\u001b[39;00m join_units \u001b[39mif\u001b[39;00m unit\u001b[39m.\u001b[39mblock\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mV\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m--> 629\u001b[0m dtype \u001b[39m=\u001b[39m find_common_type(dtypes)\n\u001b[1;32m    630\u001b[0m \u001b[39mif\u001b[39;00m has_none_blocks:\n\u001b[1;32m    631\u001b[0m     dtype \u001b[39m=\u001b[39m ensure_dtype_can_hold_na(dtype)\n",
      "File \u001b[0;32m/usr/lib/python3.11/site-packages/pandas/core/dtypes/cast.py:1607\u001b[0m, in \u001b[0;36mfind_common_type\u001b[0;34m(types)\u001b[0m\n\u001b[1;32m   1590\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1591\u001b[0m \u001b[39mFind a common data type among the given dtypes.\u001b[39;00m\n\u001b[1;32m   1592\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1604\u001b[0m \n\u001b[1;32m   1605\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1606\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m types:\n\u001b[0;32m-> 1607\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mno types given\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1609\u001b[0m first \u001b[39m=\u001b[39m types[\u001b[39m0\u001b[39m]\n\u001b[1;32m   1611\u001b[0m \u001b[39m# workaround for find_common_type([np.dtype('datetime64[ns]')] * 2)\u001b[39;00m\n\u001b[1;32m   1612\u001b[0m \u001b[39m# => object\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: no types given"
     ]
    }
   ],
   "source": [
    "print(train_features.columns)\n",
    "print(labels.columns)\n",
    "\n",
    "random_forest_data = pd.concat([train_features,labels],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load pickled test 3d norm accelerometer data\n",
    "file = open('data/accel_mag_test.pkl', 'rb')\n",
    "pickled = pickle.load(file)\n",
    "accel_mag =  pd.DataFrame(((x,) for x in pickled), columns=['lists'])\n",
    "\n",
    "features_signal = features_extraction(accel_mag)\n",
    "\n",
    "features_test_accel_mag = pd.DataFrame.transpose(features_signal)\n",
    "\n",
    "for sample in acceleration[1:,1]:\n",
    "    new = []\n",
    "    for x, t in list(zip(sample.timestamps, sample.values)):\n",
    "        new.append([x,t])\n",
    "    new = pd.DataFrame(new)\n",
    "    features_inside = features_extraction(new)\n",
    "    features_test_y = pd.concat([features_test_x,pd.DataFrame.transpose(features_inside)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

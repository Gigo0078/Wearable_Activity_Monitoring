{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You may change the mhealth_activity module but your algorithm must support the original version\n",
    "from mhealth_activity import Recording, Trace, Activity, WatchLocation, Path\n",
    "\n",
    "# For interactive plots, uncomment the following line\n",
    "# %matplotlib widget\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from scipy.fft import fft, fftfreq\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.signal import find_peaks, peak_prominences, resample_poly\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_absolute_error,accuracy_score,precision_score,recall_score,confusion_matrix,classification_report,f1_score\n",
    "from multiprocessing import Pool\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from numpy.linalg import norm\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/pickled_and_sorted_training_data.pkl.zst')\n",
    "\n",
    "# data = data[['ax','ay', 'az', 'mx', 'my', 'mz', 'gx', 'gy', 'gz','altitude']]\n",
    "data = data[['ax','ay', 'az', 'mx', 'my', 'mz', 'gx', 'gy', 'gz', 'phone_ax', 'phone_ay', 'phone_az','phone_gx', 'phone_gy', 'phone_gz', 'phone_mx', 'phone_my', 'phone_mz','altitude']]\n",
    "#magneto sampling rate is ~12.5 10 sample averaging\n",
    "#accel gyro sampling rate is 200 100 sample averaging\n",
    "#10 sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Recording(\"data/train/train_trace_000.pkl\")\n",
    "for i in range(1, len(d.data['gx'].timestamps)-1):\n",
    "    print(f\" acc {1/(d.data['phone_ax'].timestamps[i]-d.data['phone_ax'].timestamps[i-1])}\")\n",
    "    print(f\" gyro {1/(d.data['phone_gx'].timestamps[i]-d.data['phone_gx'].timestamps[i-1])}\")\n",
    "    print(f\" mag {1/(d.data['phone_mx'].timestamps[i]-d.data['phone_mx'].timestamps[i-1])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define filtering and vector projection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265.7231512699832\n"
     ]
    }
   ],
   "source": [
    "def window_average(input, winlen: int):\n",
    "#downsample/filter with an average, if the input is 40 elements long and winlen is 10 output will have 4 elements\n",
    "\n",
    "    numwins = int(len(input)/winlen)\n",
    "    remainder = len(input)%winlen\n",
    "    output=[]\n",
    "\n",
    "    for i in range(numwins):\n",
    "        output.append(np.mean(input[winlen*i:winlen*(i+1)]))\n",
    "    \n",
    "    return output\n",
    "\n",
    "#average accelerometer and magnetometer data based on the trace number\n",
    "def get_filtered_data(numtrace = 100, downsample = False, filter=False, source=\"watch\"):\n",
    "    if source == \"watch\":\n",
    "        axl = \"ax\"; ayl = \"ay\"; azl = \"az\"\n",
    "        gxl = \"gx\"; gyl = \"gy\"; gzl = \"gz\"\n",
    "        mxl = \"mx\"; myl = \"my\"; mzl = \"mz\"\n",
    "    elif source == \"phone\":\n",
    "        axl = \"phone_ax\"; ayl = \"phone_ay\"; azl = \"phone_az\"\n",
    "        gxl = \"phone_gx\"; gyl = \"phone_gy\"; gzl = \"phone_gz\"\n",
    "        mxl = \"phone_mx\"; myl = \"phone_my\"; mzl = \"phone_mz\"\n",
    "\n",
    "\n",
    "    ax=[];ay=[];ax=[];gx=[];gy=[];gz=[];mx=[];my=[];mz=[]\n",
    "    if downsample:\n",
    "        down, up = (len(data[axl].loc[numtrace].values)/len(data[mxl].loc[numtrace].values)).as_integer_ratio()\n",
    "        \n",
    "        ax = resample_poly(data[axl].loc[numtrace].values, up, down)\n",
    "        ay = resample_poly(data[ayl].loc[numtrace].values, up, down)\n",
    "        az = resample_poly(data[azl].loc[numtrace].values, up, down)\n",
    "        \n",
    "        gx = resample_poly(data[gxl].loc[numtrace].values, up, down)\n",
    "        gy = resample_poly(data[gyl].loc[numtrace].values, up, down)\n",
    "        gz = resample_poly(data[gzl].loc[numtrace].values, up, down)\n",
    "\n",
    "        if filter:\n",
    "            sos = signal.cheby2(2, 20, [0.5, 3.125], 'bandpass', fs=12.5, output='sos')\n",
    "\n",
    "            ax = signal.sosfiltfilt(sos,ax)\n",
    "            ay = signal.sosfiltfilt(sos,ay)\n",
    "            az = signal.sosfiltfilt(sos,az)\n",
    "\n",
    "            gx = signal.sosfiltfilt(sos,gx)\n",
    "            gy = signal.sosfiltfilt(sos,gy)\n",
    "            gz = signal.sosfiltfilt(sos,gz)\n",
    "\n",
    "            mx = signal.sosfiltfilt(sos,data[mxl].loc[numtrace].values)\n",
    "            my = signal.sosfiltfilt(sos,data[myl].loc[numtrace].values)\n",
    "            mz = signal.sosfiltfilt(sos,data[mzl].loc[numtrace].values)\n",
    "        else:\n",
    "            mx = data[mxl].loc[numtrace].values\n",
    "            my = data[myl].loc[numtrace].values\n",
    "            mz = data[mzl].loc[numtrace].values\n",
    "\n",
    "    else:\n",
    "        #some arrays don't have the same lengths, equalize to the shortest\n",
    "        \n",
    "        ax = data[axl].loc[numtrace].values\n",
    "        ay = data[ayl].loc[numtrace].values\n",
    "        az = data[azl].loc[numtrace].values\n",
    "\n",
    "        gx = data[gxl].loc[numtrace].values\n",
    "        gy = data[gyl].loc[numtrace].values\n",
    "        gz = data[gzl].loc[numtrace].values\n",
    "\n",
    "        mx = data[mxl].loc[numtrace].values\n",
    "        my = data[myl].loc[numtrace].values\n",
    "        mz = data[mzl].loc[numtrace].values\n",
    "\n",
    "        mini = min(len(ax), len(ay))\n",
    "        mini = min(mini, len(az))\n",
    "        mini = min(mini, len(gx))\n",
    "        mini = min(mini, len(gy))\n",
    "        mini = min(mini, len(gz))\n",
    "        mini = min(mini, len(mx))\n",
    "        mini = min(mini, len(my))\n",
    "        mini = min(mini, len(mz))\n",
    "\n",
    "        if len(ax) > mini:\n",
    "            ax = ax[:-(len(ax)-mini)]\n",
    "        if len(ay) > mini:\n",
    "            ay = ay[:-(len(ay)-mini)]\n",
    "        if len(az) > mini:\n",
    "            az = az[:-(len(az)-mini)]\n",
    "\n",
    "\n",
    "        if len(gx) > mini:\n",
    "            gx = gx[:-(len(gx)-mini)]\n",
    "        if len(gy) > mini:\n",
    "            gy = gy[:-(len(gy)-mini)]\n",
    "        if len(gz) > mini:\n",
    "            gz = gz[:-(len(gz)-mini)]\n",
    "\n",
    "\n",
    "        if len(mx) > mini:\n",
    "            mx = mx[:-(len(mx)-mini)]\n",
    "        if len(my) > mini:\n",
    "            my = my[:-(len(my)-mini)]\n",
    "        if len(mz) > mini:\n",
    "            mz = mz[:-(len(mz)-mini)]\n",
    "\n",
    "    # print(f\"{len(ax)} {len(ay)} {len(az)} {len(gx)} {len(gy)} {len(gz)} {len(mx)} {len(my)} {len(mz)}\")\n",
    "\n",
    "    return (ax, ay, az, gx, gy, gz, mx, my, mz)\n",
    "\n",
    "def getproj(a,b):\n",
    "    return a - ((np.dot(a, b) / np.dot(b, b)) * b)\n",
    "\n",
    "def getbearing(accelvec, magvec):\n",
    "    proj = getproj(magvec, accelvec)\n",
    "    return (math.atan2(proj[1], proj[0]) * 180.0 / math.pi ) + 180.0\n",
    "\n",
    "def get_trace_bearings(numtrace):\n",
    "    bearings = []\n",
    "    ax, ay, az, gx, gy, gz, mx, my, mz = get_filtered_data(numtrace)\n",
    "    limit = min(len(ax), len(mx))\n",
    "    for i in range(limit):\n",
    "        accelvec = np.array([az[i], ay[i], ax[i]])\n",
    "        magvec   = np.array([mz[i], my[i], mx[i]])\n",
    "        bearings.append(getbearing(accelvec, magvec))\n",
    "    return bearings\n",
    "\n",
    "#test the bearing function\n",
    "ax, ay, az, gx, gy, gz, mx, my, mz = get_filtered_data(100, True, True)\n",
    "\n",
    "accelvec = np.array([az[0], ay[0], ax[0]])\n",
    "magvec   = np.array([mz[0], my[0], mx[0]])\n",
    "\n",
    "print(getbearing(accelvec, magvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Madgwick:\n",
    "    def __init__(self, gyr: np.ndarray = None, acc: np.ndarray = None, mag: np.ndarray = None, **kwargs):\n",
    "        self.gyr: np.ndarray = gyr\n",
    "        self.acc: np.ndarray = acc\n",
    "        self.mag: np.ndarray = mag\n",
    "        self.frequency: float = kwargs.get('frequency', 100.0)\n",
    "        self.Dt: float = kwargs.get('Dt', (1.0/self.frequency) if self.frequency else 0.01)\n",
    "        self.q0: np.ndarray = kwargs.get('q0')\n",
    "        self._set_gain(**kwargs)\n",
    "        self._assert_validity_of_inputs()\n",
    "        if self.acc is not None and self.gyr is not None:\n",
    "            self.Q: np.ndarray = self._compute_all()\n",
    "\n",
    "    def _set_gain(self, **kwargs) -> None:\n",
    "        \"\"\"Set the gain parameter.\"\"\"\n",
    "        self.gain_imu: float = kwargs.get('gain_imu', 0.033)\n",
    "        self.gain_marg: float = kwargs.get('gain_marg', 0.041)\n",
    "        self.gain: float = kwargs.get('beta')  # Setting gain with `beta` will be removed in the future.\n",
    "        if self.gain is None:\n",
    "            self.gain: float = kwargs.get('gain', self.gain_imu if self.mag is None else self.gain_marg)\n",
    "\n",
    "    def _assert_validity_of_inputs(self):\n",
    "        \"\"\"Asserts the validity of the inputs.\"\"\"\n",
    "        for item in [\"frequency\", \"Dt\", \"gain\", \"gain_imu\", \"gain_marg\"]:\n",
    "            if isinstance(self.__getattribute__(item), bool):\n",
    "                raise TypeError(f\"Parameter '{item}' must be numeric.\")\n",
    "            if not isinstance(self.__getattribute__(item), (int, float)):\n",
    "                raise TypeError(f\"Parameter '{item}' is not a non-zero number.\")\n",
    "            if self.__getattribute__(item) <= 0.0:\n",
    "                raise ValueError(f\"Parameter '{item}' must be a non-zero number.\")\n",
    "        if self.q0 is not None:\n",
    "            if not isinstance(self.q0, (list, tuple, np.ndarray)):\n",
    "                raise TypeError(f\"Parameter 'q0' must be an array. Got {type(self.q0)}.\")\n",
    "            self.q0 = np.copy(self.q0)\n",
    "            if self.q0.shape != (4,):\n",
    "                raise ValueError(f\"Parameter 'q0' must be an array of shape (4,). It is {self.q0.shape}.\")\n",
    "            if not np.allclose(np.linalg.norm(self.q0), 1.0):\n",
    "                raise ValueError(f\"Parameter 'q0' must be a versor (norm equal to 1.0). Its norm is equal to {np.linalg.norm(self.q0)}.\")\n",
    "\n",
    "\n",
    "    def _compute_all(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Estimate the quaternions given all data.\n",
    "\n",
    "        Attributes ``gyr`` and ``acc`` must contain data. If ``mag`` contains\n",
    "        data, the updateMARG() method is used.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Q : numpy.ndarray\n",
    "            M-by-4 Array with all estimated quaternions, where M is the number\n",
    "            of samples.\n",
    "\n",
    "        \"\"\"\n",
    "        self.gyr = np.copy(self.gyr)\n",
    "        self.acc = np.copy(self.acc)\n",
    "        if self.acc.shape != self.gyr.shape:\n",
    "            raise ValueError(\"acc and gyr are not the same size\")\n",
    "        num_samples = len(self.acc)\n",
    "        Q = np.zeros((num_samples, 4))\n",
    "        # Compute with IMU architecture\n",
    "        if self.mag is None:\n",
    "            Q[0] = acc2q(self.acc[0]) if self.q0 is None else self.q0/np.linalg.norm(self.q0)\n",
    "            for t in range(1, num_samples):\n",
    "                Q[t] = self.updateIMU(Q[t-1], self.gyr[t], self.acc[t])\n",
    "            return Q\n",
    "        # Compute with MARG architecture\n",
    "        self.mag = np.copy(self.mag)\n",
    "        if self.mag.shape != self.gyr.shape:\n",
    "            raise ValueError(\"mag and gyr are not the same size\")\n",
    "        Q[0] = ecompass(self.acc[0], self.mag[0], frame='NED', representation='quaternion')\n",
    "        for t in range(1, num_samples):\n",
    "            Q[t] = self.updateMARG(Q[t-1], self.gyr[t], self.acc[t], self.mag[t])\n",
    "        return Q\n",
    "        \n",
    "    def updateMARG(self, q: np.ndarray, gyr: np.ndarray, acc: np.ndarray, mag: np.ndarray, dt: float = None) -> np.ndarray:\n",
    "\n",
    "        # q : numpy.ndarray\n",
    "        #     A-priori quaternion.\n",
    "        # gyr : numpy.ndarray\n",
    "        #     Sample of tri-axial Gyroscope in rad/s\n",
    "        # acc : numpy.ndarray\n",
    "        #     Sample of tri-axial Accelerometer in m/s^2\n",
    "        # mag : numpy.ndarray\n",
    "        #     Sample of tri-axial Magnetometer in nT\n",
    "        # dt : float, default: None\n",
    "        #     Time step, in seconds, between consecutive Quaternions.\n",
    "\n",
    "        dt = self.Dt if dt is None else dt\n",
    "        if gyr is None or not np.linalg.norm(gyr) > 0:\n",
    "            return q\n",
    "        if mag is None or not np.linalg.norm(mag) > 0:\n",
    "            return self.updateIMU(q, gyr, acc)\n",
    "        qDot = 0.5 * q_prod(q, [0, *gyr])                           # (eq. 12)\n",
    "        a_norm = np.linalg.norm(acc)\n",
    "        if a_norm > 0:\n",
    "            a = acc/a_norm\n",
    "            m = mag/np.linalg.norm(mag)\n",
    "            # Rotate normalized magnetometer measurements\n",
    "            h = q_prod(q, q_prod([0, *m], q_conj(q)))               # (eq. 45)\n",
    "            bx = np.linalg.norm([h[1], h[2]])                       # (eq. 46)\n",
    "            bz = h[3]\n",
    "            qw, qx, qy, qz = q/np.linalg.norm(q)\n",
    "            # Objective function (eq. 31)\n",
    "            f = np.array([2.0*(qx*qz - qw*qy)   - a[0],\n",
    "                            2.0*(qw*qx + qy*qz)   - a[1],\n",
    "                            2.0*(0.5-qx**2-qy**2) - a[2],\n",
    "                            2.0*bx*(0.5 - qy**2 - qz**2) + 2.0*bz*(qx*qz - qw*qy)       - m[0],\n",
    "                            2.0*bx*(qx*qy - qw*qz)       + 2.0*bz*(qw*qx + qy*qz)       - m[1],\n",
    "                            2.0*bx*(qw*qy + qx*qz)       + 2.0*bz*(0.5 - qx**2 - qy**2) - m[2]])\n",
    "            # Jacobian (eq. 32)\n",
    "            J = np.array([[-2.0*qy,               2.0*qz,              -2.0*qw,               2.0*qx             ],\n",
    "                            [ 2.0*qx,               2.0*qw,               2.0*qz,               2.0*qy             ],\n",
    "                            [ 0.0,                 -4.0*qx,              -4.0*qy,               0.0                ],\n",
    "                            [-2.0*bz*qy,            2.0*bz*qz,           -4.0*bx*qy-2.0*bz*qw, -4.0*bx*qz+2.0*bz*qx],\n",
    "                            [-2.0*bx*qz+2.0*bz*qx,  2.0*bx*qy+2.0*bz*qw,  2.0*bx*qx+2.0*bz*qz, -2.0*bx*qw+2.0*bz*qy],\n",
    "                            [ 2.0*bx*qy,            2.0*bx*qz-4.0*bz*qx,  2.0*bx*qw-4.0*bz*qy,  2.0*bx*qx          ]])\n",
    "            gradient = J.T@f                                        # (eq. 34)\n",
    "            gradient /= np.linalg.norm(gradient)\n",
    "            qDot -= self.gain*gradient                              # (eq. 33)\n",
    "        q_new = q + qDot*dt                                         # (eq. 13)\n",
    "        q_new /= np.linalg.norm(q_new)\n",
    "        return q_new\n",
    "    \n",
    "    def updateIMU(self, q: np.ndarray, gyr: np.ndarray, acc: np.ndarray, dt: float = None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Quaternion Estimation with IMU architecture.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        q : numpy.ndarray\n",
    "            A-priori quaternion.\n",
    "        gyr : numpy.ndarray\n",
    "            Sample of tri-axial Gyroscope in rad/s\n",
    "        acc : numpy.ndarray\n",
    "            Sample of tri-axial Accelerometer in m/s^2\n",
    "        dt : float, default: None\n",
    "            Time step, in seconds, between consecutive Quaternions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        q : numpy.ndarray\n",
    "            Estimated quaternion.\n",
    "        \"\"\"\n",
    "        dt = self.Dt if dt is None else dt\n",
    "        if gyr is None or not np.linalg.norm(gyr) > 0:\n",
    "            return q\n",
    "        qDot = 0.5 * q_prod(q, [0, *gyr])                           # (eq. 12)\n",
    "        a_norm = np.linalg.norm(acc)\n",
    "        if a_norm > 0:\n",
    "            a = acc/a_norm\n",
    "            qw, qx, qy, qz = q/np.linalg.norm(q)\n",
    "            # Objective function (eq. 25)\n",
    "            f = np.array([2.0*(qx*qz - qw*qy)   - a[0],\n",
    "                          2.0*(qw*qx + qy*qz)   - a[1],\n",
    "                          2.0*(0.5-qx**2-qy**2) - a[2]])\n",
    "            if np.linalg.norm(f) > 0:\n",
    "                # Jacobian (eq. 26)\n",
    "                J = np.array([[-2.0*qy,  2.0*qz, -2.0*qw, 2.0*qx],\n",
    "                              [ 2.0*qx,  2.0*qw,  2.0*qz, 2.0*qy],\n",
    "                              [ 0.0,    -4.0*qx, -4.0*qy, 0.0   ]])\n",
    "                # Objective Function Gradient\n",
    "                gradient = J.T@f                                    # (eq. 34)\n",
    "                gradient /= np.linalg.norm(gradient)\n",
    "                qDot -= self.gain*gradient                          # (eq. 33)\n",
    "        q_new = q + qDot*dt                                         # (eq. 13)\n",
    "        q_new /= np.linalg.norm(q_new)\n",
    "        return q_new\n",
    "\n",
    "def ecompass(a: np.ndarray, m: np.ndarray, frame: str = 'ENU', representation: str = 'rotmat') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Orientation from accelerometer and magnetometer readings\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : numpy.ndarray\n",
    "        Sample of tri-axial accelerometer, in m/s^2.\n",
    "    m : numpy.ndarray\n",
    "        Sample of tri-axial magnetometer, in uT.\n",
    "    frame : str, default: ``'ENU'``\n",
    "        Local tangent plane coordinate frame.\n",
    "    representation : str, default: ``'rotmat'``\n",
    "        Orientation representation. Options are: ``'rotmat'``, ``'quaternion'``,\n",
    "        ``'rpy'``, ``'axisangle'``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Estimated orientation.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        When wrong local tangent plane coordinates, or invalid representation,\n",
    "        is given.\n",
    "    \"\"\"\n",
    "    if frame.upper() not in ['ENU', 'NED']:\n",
    "        raise ValueError(\"Wrong local tangent plane coordinate frame. Try 'ENU' or 'NED'\")\n",
    "    if representation.lower() not in ['rotmat', 'quaternion', 'rpy', 'axisangle']:\n",
    "        raise ValueError(\"Wrong representation type. Try 'rotmat', 'quaternion', 'rpy', or 'axisangle'\")\n",
    "    a = np.copy(a)\n",
    "    m = np.copy(m)\n",
    "    if a.shape[-1] != 3 or m.shape[-1] != 3:\n",
    "        raise ValueError(\"Input vectors must have exactly 3 elements.\")\n",
    "    m /= np.linalg.norm(m)\n",
    "    Rz = a/np.linalg.norm(a)\n",
    "    if frame.upper() == 'NED':\n",
    "        Ry = np.cross(Rz, m)\n",
    "        Rx = np.cross(Ry, Rz)\n",
    "    else:\n",
    "        Rx = np.cross(m, Rz)\n",
    "        Ry = np.cross(Rz, Rx)\n",
    "    Rx /= np.linalg.norm(Rx)\n",
    "    Ry /= np.linalg.norm(Ry)\n",
    "    R = np.c_[Rx, Ry, Rz].T\n",
    "    if representation.lower() == 'quaternion':\n",
    "        return chiaverini(R)\n",
    "    if representation.lower() == 'rpy':\n",
    "        phi = np.arctan2(R[1, 2], R[2, 2])    # Roll Angle\n",
    "        theta = -np.arcsin(R[0, 2])           # Pitch Angle\n",
    "        psi = np.arctan2(R[0, 1], R[0, 0])    # Yaw Angle\n",
    "        return np.array([phi, theta, psi])\n",
    "    if representation.lower() == 'axisangle':\n",
    "        angle = np.arccos((R.trace()-1)/2)\n",
    "        axis = np.zeros(3)\n",
    "        if angle != 0:\n",
    "            S = np.array([R[2, 1]-R[1, 2], R[0, 2]-R[2, 0], R[1, 0]-R[0, 1]])\n",
    "            axis = S/(2*np.sin(angle))\n",
    "        return (axis, angle)\n",
    "    return R\n",
    "\n",
    "def chiaverini(dcm: np.ndarray) -> np.ndarray:\n",
    "    dcm = np.copy(dcm)\n",
    "    if dcm.ndim not in [2, 3]:\n",
    "        raise ValueError('dcm must be a 2- or 3-dimensional array.')\n",
    "    if dcm.shape[-2:] != (3, 3):\n",
    "        raise ValueError(f\"dcm must be an array of shape 3-by-3 or N-by-3-by-3. Got {dcm.shape}\")\n",
    "    if dcm.ndim < 3:\n",
    "        q = np.zeros(4)\n",
    "        q[0] = 0.5*np.sqrt(np.clip(dcm.trace(), -1.0, 3.0) + 1.0)\n",
    "        q[1] = 0.5*np.sign(dcm[2, 1]-dcm[1, 2])*np.sqrt(np.clip(dcm[0, 0]-dcm[1, 1]-dcm[2, 2], -1.0, 1.0)+1.0)\n",
    "        q[2] = 0.5*np.sign(dcm[0, 2]-dcm[2, 0])*np.sqrt(np.clip(dcm[1, 1]-dcm[2, 2]-dcm[0, 0], -1.0, 1.0)+1.0)\n",
    "        q[3] = 0.5*np.sign(dcm[1, 0]-dcm[0, 1])*np.sqrt(np.clip(dcm[2, 2]-dcm[0, 0]-dcm[1, 1], -1.0, 1.0)+1.0)\n",
    "        if not any(q):\n",
    "            q[0] = 1.0\n",
    "        q /= np.linalg.norm(q)\n",
    "        return q\n",
    "    Q = np.zeros((dcm.shape[0], 4))\n",
    "    Q[:, 0] = 0.5*np.sqrt(np.clip(dcm.trace(axis1=1, axis2=2), -1.0, 3.0) + 1.0)\n",
    "    Q[:, 1] = 0.5*np.sign(dcm[:, 2, 1] - dcm[:, 1, 2])*np.sqrt(np.clip(dcm[:, 0, 0]-dcm[:, 1, 1]-dcm[:, 2, 2], -1.0, 1.0) + 1.0)\n",
    "    Q[:, 2] = 0.5*np.sign(dcm[:, 0, 2] - dcm[:, 2, 0])*np.sqrt(np.clip(dcm[:, 1, 1]-dcm[:, 2, 2]-dcm[:, 0, 0], -1.0, 1.0) + 1.0)\n",
    "    Q[:, 3] = 0.5*np.sign(dcm[:, 1, 0] - dcm[:, 0, 1])*np.sqrt(np.clip(dcm[:, 2, 2]-dcm[:, 0, 0]-dcm[:, 1, 1], -1.0, 1.0) + 1.0)\n",
    "    Q /= np.linalg.norm(Q, axis=1)[:, None]\n",
    "    return Q\n",
    "\n",
    "def q_prod(p: np.ndarray, q: np.ndarray) -> np.ndarray:\n",
    "    pq = np.zeros(4)\n",
    "    pq[0] = p[0]*q[0] - p[1]*q[1] - p[2]*q[2] - p[3]*q[3]\n",
    "    pq[1] = p[0]*q[1] + p[1]*q[0] + p[2]*q[3] - p[3]*q[2]\n",
    "    pq[2] = p[0]*q[2] - p[1]*q[3] + p[2]*q[0] + p[3]*q[1]\n",
    "    pq[3] = p[0]*q[3] + p[1]*q[2] - p[2]*q[1] + p[3]*q[0]\n",
    "    return pq\n",
    "\n",
    "def q_conj(q: np.ndarray) -> np.ndarray:\n",
    "    q = np.copy(q)\n",
    "    if q.ndim > 2 or q.shape[-1] != 4:\n",
    "        raise ValueError(f\"Quaternion must be of shape (4,) or (N, 4), but has shape {q.shape}\")\n",
    "    return np.array([1., -1., -1., -1.])*np.array(q)\n",
    "\n",
    "def q2euler(q: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Euler Angles from unit Quaternion.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    q : numpy.ndarray\n",
    "        Quaternion\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    angles : numpy.ndarray\n",
    "        Euler Angles around X-, Y- and Z-axis.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] https://en.wikipedia.org/wiki/Conversion_between_quaternions_and_Euler_angles#Quaternion_to_Euler_Angles_Conversion\n",
    "\n",
    "    \"\"\"\n",
    "    if sum(np.array([1., 0., 0., 0.])-q) == 0.0:\n",
    "        return np.zeros(3)\n",
    "    if len(q) != 4:\n",
    "        return None\n",
    "    R_00 = 2.0*q[0]**2 - 1.0 + 2.0*q[1]**2\n",
    "    R_10 = 2.0*(q[1]*q[2] - q[0]*q[3])\n",
    "    R_20 = 2.0*(q[1]*q[3] + q[0]*q[2])\n",
    "    R_21 = 2.0*(q[2]*q[3] - q[0]*q[1])\n",
    "    R_22 = 2.0*q[0]**2 - 1.0 + 2.0*q[3]**2\n",
    "    #rotation around x, roll\n",
    "    phi = np.arctan2( R_21, R_22)\n",
    "    #rotation around y, pitch\n",
    "    theta = -np.arctan( R_20/np.sqrt(1.0-R_20**2))\n",
    "    #rotation around z, yaw\n",
    "    psi = np.arctan2( R_10, R_00)\n",
    "    return np.array([phi, theta, psi])\n",
    "\n",
    "def acc2q(a: np.ndarray, return_euler: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Quaternion from given acceleration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : numpy.ndarray\n",
    "        A sample of 3 orthogonal accelerometers.\n",
    "    return_euler : bool, default: False\n",
    "        Return pose as Euler angles\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pose : numpy.ndarray\n",
    "        Quaternion or Euler Angles.\n",
    "    \"\"\"\n",
    "    q = np.array([1.0, 0.0, 0.0, 0.0])\n",
    "    ex, ey, ez = 0.0, 0.0, 0.0\n",
    "    if np.linalg.norm(a) > 0 and len(a) == 3:\n",
    "        ax, ay, az = a\n",
    "        # Normalize accelerometer measurements\n",
    "        a_norm = np.linalg.norm(a)\n",
    "        ax /= a_norm\n",
    "        ay /= a_norm\n",
    "        az /= a_norm\n",
    "        # Euler Angles from Gravity vector\n",
    "        ex = np.arctan2(ay, az)\n",
    "        ey = np.arctan2(-ax, np.sqrt(ay**2 + az**2))\n",
    "        ez = 0.0\n",
    "        if return_euler:\n",
    "            return np.array([ex, ey, ez])*RAD2DEG\n",
    "        # Euler to Quaternion\n",
    "        cx2 = np.cos(ex/2.0)\n",
    "        sx2 = np.sin(ex/2.0)\n",
    "        cy2 = np.cos(ey/2.0)\n",
    "        sy2 = np.sin(ey/2.0)\n",
    "        q = np.array([cx2*cy2, sx2*cy2, cx2*sy2, -sx2*sy2])\n",
    "        q /= np.linalg.norm(q)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path_idx': 2, 'activities': [1], 'step_count': None, 'watch_loc': 0} 103\n",
      "{'path_idx': 2, 'activities': [1], 'step_count': None, 'watch_loc': 0} 106\n",
      "{'path_idx': 4, 'activities': [1], 'step_count': None, 'watch_loc': 1} 107\n",
      "{'path_idx': 4, 'activities': [1], 'step_count': None, 'watch_loc': 2} 109\n",
      "{'path_idx': 0, 'activities': [1], 'step_count': None, 'watch_loc': 0} 112\n",
      "{'path_idx': 4, 'activities': [1], 'step_count': None, 'watch_loc': 0} 115\n",
      "{'path_idx': 3, 'activities': [1], 'step_count': None, 'watch_loc': 2} 116\n",
      "{'path_idx': 1, 'activities': [1], 'step_count': None, 'watch_loc': 0} 117\n",
      "{'path_idx': 2, 'activities': [1], 'step_count': None, 'watch_loc': 2} 120\n",
      "{'path_idx': 1, 'activities': [1], 'step_count': None, 'watch_loc': 2} 121\n",
      "{'path_idx': 0, 'activities': [1], 'step_count': None, 'watch_loc': 2} 122\n",
      "{'path_idx': 3, 'activities': [1], 'step_count': None, 'watch_loc': 0} 123\n",
      "{'path_idx': 0, 'activities': [1], 'step_count': None, 'watch_loc': 0} 125\n",
      "{'path_idx': 1, 'activities': [1], 'step_count': None, 'watch_loc': 2} 126\n",
      "{'path_idx': 4, 'activities': [1], 'step_count': None, 'watch_loc': 0} 128\n",
      "{'path_idx': 0, 'activities': [1], 'step_count': None, 'watch_loc': 2} 129\n"
     ]
    }
   ],
   "source": [
    "#116, path 3, walking only\n",
    "# {'path_idx': 4, 'activities': [1], 'step_count': None, 'watch_loc': 0} 115\n",
    "# {'path_idx': 3, 'activities': [1], 'step_count': None, 'watch_loc': 2} 116\n",
    "# {'path_idx': 1, 'activities': [1], 'step_count': None, 'watch_loc': 0} 117\n",
    "# {'path_idx': 2, 'activities': [1], 'step_count': None, 'watch_loc': 2} 120\n",
    "# {'path_idx': 1, 'activities': [1], 'step_count': None, 'watch_loc': 2} 121\n",
    "# {'path_idx': 0, 'activities': [1], 'step_count': None, 'watch_loc': 2} 122\n",
    "# {'path_idx': 3, 'activities': [1], 'step_count': None, 'watch_loc': 0} 123\n",
    "# {'path_idx': 0, 'activities': [1], 'step_count': None, 'watch_loc': 0} 125\n",
    "for i in range(100, 130):\n",
    "    d = Recording(f\"data/train/train_trace_{i}.pkl\")\n",
    "    if(d.labels['activities']==[1]):\n",
    "        print(f\"{d.labels} {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ntrace = 116\n",
    "include_mag = True\n",
    "\n",
    "def madgwick_headings(num_trace, source=\"watch\"):\n",
    "    if(source==\"watch\"):\n",
    "        ax, ay, az, gx, gy, gz, mx, my, mz = get_filtered_data(num_trace, downsample=True, filter=False, source=source)\n",
    "        #magnetometer has lower fs and everything downsampled to that\n",
    "        samplerate = 12.5\n",
    "    else:\n",
    "        ax, ay, az, gx, gy, gz, mx, my, mz = get_filtered_data(num_trace, downsample=False, filter=False, source=source)\n",
    "        #everything has the same sample rate\n",
    "        samplerate = 100\n",
    "        \n",
    "    # if len(ax) != len(ay) or len(ax) != len(az) or len(az) != len(ay):\n",
    "    #     print(f\"{num_trace} orospu cocugu array\")\n",
    "\n",
    "    # if len(gx) != len(gy) or len(gx) != len(gz) or len(gz) != len(gy):\n",
    "    #     print(f\"{num_trace} orospu cocugu array\")\n",
    "    \n",
    "    # if len(mx) != len(my) or len(mx) != len(mz) or len(mz) != len(my):\n",
    "    #     print(f\"{num_trace} orospu cocugu array\")\n",
    "\n",
    "    acc_data  = np.concatenate([np.array(az).reshape(-1,1),np.array(ay).reshape(-1,1),np.array(ax).reshape(-1,1)], axis=1)\n",
    "    gyro_data = np.concatenate([np.array(gz).reshape(-1,1),np.array(gy).reshape(-1,1),np.array(gx).reshape(-1,1)], axis=1)\n",
    "    mag_data  = np.concatenate([np.array(mz).reshape(-1,1),np.array(my).reshape(-1,1),np.array(mx).reshape(-1,1)], axis=1)\n",
    "\n",
    "    \n",
    "    madgwick = Madgwick(gyr=gyro_data, acc=acc_data, mag=mag_data, frequency=samplerate, gain=0.038)\n",
    "\n",
    "    # \n",
    "\n",
    "    # fig = plt.figure()\n",
    "    # ax = plt.axes(projection=\"3d\")\n",
    "\n",
    "\n",
    "    current = [0, 0, 0]\n",
    "    x = []\n",
    "    y = [] \n",
    "    z = []\n",
    "\n",
    "    from scipy.spatial.transform import Rotation\n",
    "    limit = len(madgwick.Q)\n",
    "    # limit=100\n",
    "    for i in (range(limit)):\n",
    "        euler = q2euler(madgwick.Q[i]) *180/math.pi\n",
    "        rot = Rotation.from_euler('xyz', euler)\n",
    "        #rotate unit vector to get cartesian headings, x=0\n",
    "        vector = np.array(rot.as_matrix()).dot(np.array([0,0,1]))\n",
    "\n",
    "        # plt.arrow(current[0], current[1], vector[0], vector[1])\n",
    "        current += vector\n",
    "        x.append(current[0])\n",
    "        y.append(current[1])\n",
    "        z.append(current[2])\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    z = np.array(z)\n",
    "\n",
    "    return x, y, z\n",
    "\n",
    "def plot_trajectory(x, y, title):\n",
    "    avg = 2000\n",
    "\n",
    "    u = np.diff(window_average(x,avg))\n",
    "    v = np.diff(window_average(y,avg))\n",
    "    print(len(u))\n",
    "    print(len(v))\n",
    "\n",
    "    pos_x = window_average(x,avg)[:-1] + u/2\n",
    "    pos_y = window_average(y,avg)[:-1] + v/2\n",
    "    norm = np.sqrt(u**2+v**2) \n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(window_average(x,avg),window_average(y,avg), marker=\"o\")\n",
    "    ax.quiver(pos_x, pos_y, u/norm, v/norm, angles=\"xy\", zorder=5, pivot=\"mid\")\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "x, y, z = madgwick_headings(ntrace, source=\"phone\")\n",
    "plt.scatter(x,y,z)\n",
    "plt.show()\n",
    "# plot_trajectory(x, z, \"xz\")\n",
    "# plot_trajectory(x, y, \"xy\")\n",
    "# plot_trajectory(z, y, \"zy\")\n",
    "\n",
    "# x, y, z = madgwick_headings(ntrace, source=\"watch\")\n",
    "\n",
    "# plot_trajectory(x, z, \"xz\")\n",
    "# plot_trajectory(x, y, \"xy\")\n",
    "# plot_trajectory(z, y, \"zy\")\n",
    "\n",
    "\n",
    "# x = np.arange(0, len(data['altitude'].loc[ntrace].values), 1)\n",
    "\n",
    "# m,b = np.polyfit(x, data['altitude'].loc[ntrace].values, 1)\n",
    "# poly1d_fn = np.poly1d((m,b))\n",
    "# plt.plot(x,data['altitude'].loc[ntrace].values, 'yo', x, poly1d_fn(x), '--k')\n",
    "\n",
    "# plt.title(f'altitude {np.mean(data['altitude'].loc[ntrace].values[-100:]) - np.mean(data['altitude'].loc[ntrace].values[:100])} {m*1000} ')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot bearings as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot bearings extracted from a plot\n",
    "# z,y,x\n",
    "\n",
    "for trace in range(5):\n",
    "    ax, ay, az, gx, gy, gz, mx, my, mz = get_filtered_data(trace, downsample=True)\n",
    "    current = [0,0,0]\n",
    "    limit = min(len(ax), len(mx))\n",
    "    # limit=20\n",
    "    bearings = []\n",
    "    for point in range(limit):\n",
    "        accelvec = np.array([az[point], ay[point], ax[point]])\n",
    "        magvec   = np.array([mz[point], my[point], mx[point]])\n",
    "\n",
    "        proj = getproj(magvec, accelvec)\n",
    "        bearings.append(getbearing(accelvec, magvec))\n",
    "        # length = math.sqrt(proj[0]**2 + proj[1]**2)\n",
    "        length =3\n",
    "        plt.arrow(current[0], current[1], proj[0]/length, proj[1]/length)\n",
    "        current += proj\n",
    "    print(bearings)\n",
    "    plt.title(f\"trace {trace}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classify the number of bearings per direction based on the trace number\n",
    "def classify_bearings(source = \"phone\", numtrace=0):\n",
    "    FEATURES = ['avgdist2d', 'avgdist3d', \"dist1\", \"dist2\", \"dist3\", \"dist4\", \"dist5\"]\n",
    "    for idx, feature in enumerate(FEATURES):\n",
    "        FEATURES[idx] = FEATURES[idx] + f'_{source}' \n",
    "\n",
    "    avgdist2d=0; avgdist3d=0;\n",
    "    try: \n",
    "        x, y, z = madgwick_headings(numtrace, source=source)\n",
    "        # if source == \"phone\":\n",
    "        #     x = window_average(x,50)\n",
    "        #     y = window_average(y,50)\n",
    "        #     z = window_average(z,50)\n",
    "\n",
    "        # else:\n",
    "        #     x = window_average(x,5)\n",
    "        #     y = window_average(y,5)\n",
    "        #     z = window_average(z,5) \n",
    "             \n",
    "        avgdist2d=math.sqrt((x[-1]+x[0])**2 + (y[-1]+y[0])**2 )\n",
    "        avgdist3d=math.sqrt((x[-1]+x[0])**2 + (y[-1]+y[0])**2 + (z[-1]+z[0])**2)\n",
    "\n",
    "        seglen = int(len(x)/5)\n",
    "        dist1 = math.sqrt((x[seglen-1]   - x[0]       )**2   +   (y[seglen-1]   - y[0]       )**2)\n",
    "        dist2 = math.sqrt((x[seglen*2-1] - x[seglen]  )**2   +   (y[seglen*2-1] - y[seglen]  )**2)\n",
    "        dist3 = math.sqrt((x[seglen*3-1] - x[seglen*2])**2   +   (y[seglen*3-1] - y[seglen*2])**2)\n",
    "        dist4 = math.sqrt((x[seglen*4-1] - x[seglen*3])**2   +   (y[seglen*4-1] - y[seglen*3])**2)\n",
    "        dist5 = math.sqrt((x[seglen*5-1] - x[seglen*4])**2   +   (y[seglen*5-1] - y[seglen*4])**2)\n",
    "    except:\n",
    "        print(f\"except {numtrace}\")\n",
    "        # DistanceFeatures = ['north', 'northeast', \"east\", 'southeast', 'south', 'southwest', 'west', 'northwest']\n",
    "        DistanceFeatures = ['north', \"east\", 'south',  'west']\n",
    "        for idx, feature in enumerate(DistanceFeatures):\n",
    "            FEATURES.append(DistanceFeatures[idx])\n",
    "        #7 common features + 8 per segment features * 5 segments = 47 zeros\n",
    "        df_features = pd.DataFrame(index = [FEATURES], data = np.zeros(11))\n",
    "        df_features = pd.DataFrame.transpose(df_features)\n",
    "        df_features.columns = df_features.columns.map(''.join)\n",
    "        return df_features \n",
    "\n",
    "\n",
    "    df_features = pd.DataFrame(index = [FEATURES], data = [avgdist2d,avgdist3d, dist1, dist2, dist3, dist4, dist5])\n",
    "    df_features = pd.DataFrame.transpose(df_features)\n",
    "    df_features.columns = df_features.columns.map(''.join)\n",
    "\n",
    "    #divide data into 5 parts and classify headings separately\n",
    "    # print(f\"total length {len(x)}\")\n",
    "    north = 0; northeast  = 0; east = 0; southeast = 0; south = 0; southwest = 0; west = 0; northwest = 0;\n",
    "    DistanceFeatures = ['north', \"east\", 'south',  'west']\n",
    "    for i in range(len(x)):\n",
    "        bearing = (math.atan2(x[i], z[i]) * 180.0 / math.pi ) + 180.0\n",
    "\n",
    "        if bearing <= 90:\n",
    "            north += 1\n",
    "        elif bearing <= 180:\n",
    "            east += 1\n",
    "        elif bearing <= 270:\n",
    "            south += 1\n",
    "        else:\n",
    "            west += 1\n",
    "\n",
    "        # seg_features = pd.DataFrame(index = [DistanceFeatures], data = [north, northeast, east, southeast, south, southwest, west, northwest])\n",
    "    seg_features = pd.DataFrame(index = [DistanceFeatures], data = [north, east,  south,  west])\n",
    "    seg_features = pd.DataFrame.transpose(seg_features)\n",
    "    seg_features.columns = seg_features.columns.map(''.join)\n",
    "    df_features = pd.concat([df_features, seg_features],axis=1)\n",
    "\n",
    "    return df_features\n",
    "\n",
    "\n",
    "#wrapper functions because to make using map easier\n",
    "def classify_bearings_watch(numtrace):\n",
    "    return classify_bearings(source = \"watch\", numtrace=numtrace)\n",
    "\n",
    "\n",
    "def classify_bearings_phone(numtrace):\n",
    "    return classify_bearings(source = \"phone\", numtrace=numtrace)\n",
    "\n",
    "def classify_all_watch_recordings():\n",
    "    nums = np.arange(0,len(data['ax']), 1)\n",
    "    with Pool() as p:\n",
    "        directions = p.map(classify_bearings_watch, nums)\n",
    "    directions = pd.concat(directions, ignore_index=True)    \n",
    "    \n",
    "    return directions\n",
    "\n",
    "def classify_all_phone_recordings():\n",
    "    nums = np.arange(0,len(data['phone_ax']), 1)\n",
    "    with Pool() as p:\n",
    "        directions = p.map(classify_bearings_phone, nums)\n",
    "    directions = pd.concat(directions, ignore_index=True)    \n",
    "    \n",
    "    return directions\n",
    "\n",
    "watch_bearing_directions = classify_all_watch_recordings()\n",
    "watch_bearing_directions.to_pickle(path='data/watch_bearing_directions.pkl.zst', compression={'method': 'zstd'})\n",
    "watch_bearing_directions\n",
    "\n",
    "phone_bearing_directions = classify_all_phone_recordings()\n",
    "phone_bearing_directions.to_pickle(path='data/phone_bearing_directions.pkl.zst', compression={'method': 'zstd'})\n",
    "phone_bearing_directions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(147, 200):\n",
    "    d = Recording(f\"data/train/train_trace_{i}.pkl\")\n",
    "    sos = signal.cheby2(1, 20, 0.5, 'lowpass', fs=12.5, output='sos')\n",
    "    alt = signal.sosfiltfilt(sos,d.data[\"altitude\"].values)\n",
    "    plt.plot(alt)\n",
    "    plt.title(f\"{i} {np.var(alt)}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

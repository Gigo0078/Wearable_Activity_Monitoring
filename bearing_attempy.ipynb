{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You may change the mhealth_activity module but your algorithm must support the original version\n",
    "from mhealth_activity import Recording, Trace, Activity, WatchLocation, Path\n",
    "\n",
    "# For interactive plots, uncomment the following line\n",
    "# %matplotlib widget\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "from scipy.fft import fft, fftfreq\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy.signal import find_peaks, peak_prominences, resample_poly\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_absolute_error,accuracy_score,precision_score,recall_score,confusion_matrix,classification_report,f1_score\n",
    "from multiprocessing import Pool\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from numpy.linalg import norm\n",
    "from scipy import signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/pickled_and_sorted_training_data.pkl.zst')\n",
    "\n",
    "# data = data[['ax','ay', 'az', 'mx', 'my', 'mz', 'gx', 'gy', 'gz','altitude']]\n",
    "data = data[['ax','ay', 'az', 'mx', 'my', 'mz', 'gx', 'gy', 'gz', 'phone_ax', 'phone_ay', 'phone_az','phone_gx', 'phone_gy', 'phone_gz', 'phone_mx', 'phone_my', 'phone_mz','altitude']]\n",
    "#magneto sampling rate is ~12.5 10 sample averaging\n",
    "#accel gyro sampling rate is 200 100 sample averaging\n",
    "#10 sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = Recording(\"data/train/train_trace_000.pkl\")\n",
    "for i in range(1, len(d.data['gx'].timestamps)-1):\n",
    "    print(f\" acc {1/(d.data['phone_ax'].timestamps[i]-d.data['phone_ax'].timestamps[i-1])}\")\n",
    "    print(f\" gyro {1/(d.data['phone_gx'].timestamps[i]-d.data['phone_gx'].timestamps[i-1])}\")\n",
    "    print(f\" mag {1/(d.data['phone_mx'].timestamps[i]-d.data['phone_mx'].timestamps[i-1])}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define filtering and vector projection functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "265.7231512699832\n"
     ]
    }
   ],
   "source": [
    "def window_average(input, winlen: int):\n",
    "#downsample/filter with an average, if the input is 40 elements long and winlen is 10 output will have 4 elements\n",
    "\n",
    "    numwins = int(len(input)/winlen)\n",
    "    remainder = len(input)%winlen\n",
    "    output=[]\n",
    "\n",
    "    for i in range(numwins):\n",
    "        output.append(np.mean(input[winlen*i:winlen*(i+1)]))\n",
    "    \n",
    "    return output\n",
    "\n",
    "#average accelerometer and magnetometer data based on the trace number\n",
    "def get_filtered_data(numtrace = 100, downsample = False, filter=False, source=\"watch\"):\n",
    "    if source == \"watch\":\n",
    "        axl = \"ax\"; ayl = \"ay\"; azl = \"az\"\n",
    "        gxl = \"gx\"; gyl = \"gy\"; gzl = \"gz\"\n",
    "        mxl = \"mx\"; myl = \"my\"; mzl = \"mz\"\n",
    "    elif source == \"phone\":\n",
    "        axl = \"phone_ax\"; ayl = \"phone_ay\"; azl = \"phone_az\"\n",
    "        gxl = \"phone_gx\"; gyl = \"phone_gy\"; gzl = \"phone_gz\"\n",
    "        mxl = \"phone_mx\"; myl = \"phone_my\"; mzl = \"phone_mz\"\n",
    "\n",
    "\n",
    "    ax=[];ay=[];ax=[];gx=[];gy=[];gz=[];mx=[];my=[];mz=[]\n",
    "    if downsample:\n",
    "        down, up = (len(data[axl].loc[numtrace].values)/len(data[mxl].loc[numtrace].values)).as_integer_ratio()\n",
    "        \n",
    "        ax = resample_poly(data[axl].loc[numtrace].values, up, down)\n",
    "        ay = resample_poly(data[ayl].loc[numtrace].values, up, down)\n",
    "        az = resample_poly(data[azl].loc[numtrace].values, up, down)\n",
    "        \n",
    "        gx = resample_poly(data[gxl].loc[numtrace].values, up, down)\n",
    "        gy = resample_poly(data[gyl].loc[numtrace].values, up, down)\n",
    "        gz = resample_poly(data[gzl].loc[numtrace].values, up, down)\n",
    "\n",
    "        if filter:\n",
    "            sos = signal.cheby2(2, 20, [0.5, 3.125], 'bandpass', fs=12.5, output='sos')\n",
    "\n",
    "            ax = signal.sosfiltfilt(sos,ax)\n",
    "            ay = signal.sosfiltfilt(sos,ay)\n",
    "            az = signal.sosfiltfilt(sos,az)\n",
    "\n",
    "            gx = signal.sosfiltfilt(sos,gx)\n",
    "            gy = signal.sosfiltfilt(sos,gy)\n",
    "            gz = signal.sosfiltfilt(sos,gz)\n",
    "\n",
    "            mx = signal.sosfiltfilt(sos,data[mxl].loc[numtrace].values)\n",
    "            my = signal.sosfiltfilt(sos,data[myl].loc[numtrace].values)\n",
    "            mz = signal.sosfiltfilt(sos,data[mzl].loc[numtrace].values)\n",
    "        else:\n",
    "            mx = data[mxl].loc[numtrace].values\n",
    "            my = data[myl].loc[numtrace].values\n",
    "            mz = data[mzl].loc[numtrace].values\n",
    "\n",
    "    else:\n",
    "        #some arrays don't have the same lengths, equalize to the shortest\n",
    "        \n",
    "        ax = data[axl].loc[numtrace].values\n",
    "        ay = data[ayl].loc[numtrace].values\n",
    "        az = data[azl].loc[numtrace].values\n",
    "\n",
    "        gx = data[gxl].loc[numtrace].values\n",
    "        gy = data[gyl].loc[numtrace].values\n",
    "        gz = data[gzl].loc[numtrace].values\n",
    "\n",
    "        mx = data[mxl].loc[numtrace].values\n",
    "        my = data[myl].loc[numtrace].values\n",
    "        mz = data[mzl].loc[numtrace].values\n",
    "\n",
    "        mini = min(len(ax), len(ay))\n",
    "        mini = min(mini, len(az))\n",
    "        mini = min(mini, len(gx))\n",
    "        mini = min(mini, len(gy))\n",
    "        mini = min(mini, len(gz))\n",
    "        mini = min(mini, len(mx))\n",
    "        mini = min(mini, len(my))\n",
    "        mini = min(mini, len(mz))\n",
    "\n",
    "        if len(ax) > mini:\n",
    "            ax = ax[:-(len(ax)-mini)]\n",
    "        if len(ay) > mini:\n",
    "            ay = ay[:-(len(ay)-mini)]\n",
    "        if len(az) > mini:\n",
    "            az = az[:-(len(az)-mini)]\n",
    "\n",
    "\n",
    "        if len(gx) > mini:\n",
    "            gx = gx[:-(len(gx)-mini)]\n",
    "        if len(gy) > mini:\n",
    "            gy = gy[:-(len(gy)-mini)]\n",
    "        if len(gz) > mini:\n",
    "            gz = gz[:-(len(gz)-mini)]\n",
    "\n",
    "\n",
    "        if len(mx) > mini:\n",
    "            mx = mx[:-(len(mx)-mini)]\n",
    "        if len(my) > mini:\n",
    "            my = my[:-(len(my)-mini)]\n",
    "        if len(mz) > mini:\n",
    "            mz = mz[:-(len(mz)-mini)]\n",
    "\n",
    "    # print(f\"{len(ax)} {len(ay)} {len(az)} {len(gx)} {len(gy)} {len(gz)} {len(mx)} {len(my)} {len(mz)}\")\n",
    "\n",
    "    return (ax, ay, az, gx, gy, gz, mx, my, mz)\n",
    "\n",
    "def getproj(a,b):\n",
    "    return a - ((np.dot(a, b) / np.dot(b, b)) * b)\n",
    "\n",
    "def getbearing(accelvec, magvec):\n",
    "    proj = getproj(magvec, accelvec)\n",
    "    return (math.atan2(proj[1], proj[0]) * 180.0 / math.pi ) + 180.0\n",
    "\n",
    "def get_trace_bearings(numtrace):\n",
    "    bearings = []\n",
    "    ax, ay, az, gx, gy, gz, mx, my, mz = get_filtered_data(numtrace)\n",
    "    limit = min(len(ax), len(mx))\n",
    "    for i in range(limit):\n",
    "        accelvec = np.array([az[i], ay[i], ax[i]])\n",
    "        magvec   = np.array([mz[i], my[i], mx[i]])\n",
    "        bearings.append(getbearing(accelvec, magvec))\n",
    "    return bearings\n",
    "\n",
    "#test the bearing function\n",
    "ax, ay, az, gx, gy, gz, mx, my, mz = get_filtered_data(100, True, True)\n",
    "\n",
    "accelvec = np.array([az[0], ay[0], ax[0]])\n",
    "magvec   = np.array([mz[0], my[0], mx[0]])\n",
    "\n",
    "print(getbearing(accelvec, magvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Madgwick:\n",
    "    def __init__(self, gyr: np.ndarray = None, acc: np.ndarray = None, mag: np.ndarray = None, **kwargs):\n",
    "        self.gyr: np.ndarray = gyr\n",
    "        self.acc: np.ndarray = acc\n",
    "        self.mag: np.ndarray = mag\n",
    "        self.frequency: float = kwargs.get('frequency', 100.0)\n",
    "        self.Dt: float = kwargs.get('Dt', (1.0/self.frequency) if self.frequency else 0.01)\n",
    "        self.q0: np.ndarray = kwargs.get('q0')\n",
    "        self._set_gain(**kwargs)\n",
    "        self._assert_validity_of_inputs()\n",
    "        if self.acc is not None and self.gyr is not None:\n",
    "            self.Q: np.ndarray = self._compute_all()\n",
    "\n",
    "    def _set_gain(self, **kwargs) -> None:\n",
    "        \"\"\"Set the gain parameter.\"\"\"\n",
    "        self.gain_imu: float = kwargs.get('gain_imu', 0.033)\n",
    "        self.gain_marg: float = kwargs.get('gain_marg', 0.041)\n",
    "        self.gain: float = kwargs.get('beta')  # Setting gain with `beta` will be removed in the future.\n",
    "        if self.gain is None:\n",
    "            self.gain: float = kwargs.get('gain', self.gain_imu if self.mag is None else self.gain_marg)\n",
    "\n",
    "    def _assert_validity_of_inputs(self):\n",
    "        \"\"\"Asserts the validity of the inputs.\"\"\"\n",
    "        for item in [\"frequency\", \"Dt\", \"gain\", \"gain_imu\", \"gain_marg\"]:\n",
    "            if isinstance(self.__getattribute__(item), bool):\n",
    "                raise TypeError(f\"Parameter '{item}' must be numeric.\")\n",
    "            if not isinstance(self.__getattribute__(item), (int, float)):\n",
    "                raise TypeError(f\"Parameter '{item}' is not a non-zero number.\")\n",
    "            if self.__getattribute__(item) <= 0.0:\n",
    "                raise ValueError(f\"Parameter '{item}' must be a non-zero number.\")\n",
    "        if self.q0 is not None:\n",
    "            if not isinstance(self.q0, (list, tuple, np.ndarray)):\n",
    "                raise TypeError(f\"Parameter 'q0' must be an array. Got {type(self.q0)}.\")\n",
    "            self.q0 = np.copy(self.q0)\n",
    "            if self.q0.shape != (4,):\n",
    "                raise ValueError(f\"Parameter 'q0' must be an array of shape (4,). It is {self.q0.shape}.\")\n",
    "            if not np.allclose(np.linalg.norm(self.q0), 1.0):\n",
    "                raise ValueError(f\"Parameter 'q0' must be a versor (norm equal to 1.0). Its norm is equal to {np.linalg.norm(self.q0)}.\")\n",
    "\n",
    "\n",
    "    def _compute_all(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Estimate the quaternions given all data.\n",
    "\n",
    "        Attributes ``gyr`` and ``acc`` must contain data. If ``mag`` contains\n",
    "        data, the updateMARG() method is used.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Q : numpy.ndarray\n",
    "            M-by-4 Array with all estimated quaternions, where M is the number\n",
    "            of samples.\n",
    "\n",
    "        \"\"\"\n",
    "        self.gyr = np.copy(self.gyr)\n",
    "        self.acc = np.copy(self.acc)\n",
    "        if self.acc.shape != self.gyr.shape:\n",
    "            raise ValueError(\"acc and gyr are not the same size\")\n",
    "        num_samples = len(self.acc)\n",
    "        Q = np.zeros((num_samples, 4))\n",
    "        # Compute with IMU architecture\n",
    "        if self.mag is None:\n",
    "            Q[0] = acc2q(self.acc[0]) if self.q0 is None else self.q0/np.linalg.norm(self.q0)\n",
    "            for t in range(1, num_samples):\n",
    "                Q[t] = self.updateIMU(Q[t-1], self.gyr[t], self.acc[t])\n",
    "            return Q\n",
    "        # Compute with MARG architecture\n",
    "        self.mag = np.copy(self.mag)\n",
    "        if self.mag.shape != self.gyr.shape:\n",
    "            raise ValueError(\"mag and gyr are not the same size\")\n",
    "        Q[0] = ecompass(self.acc[0], self.mag[0], frame='NED', representation='quaternion')\n",
    "        for t in range(1, num_samples):\n",
    "            Q[t] = self.updateMARG(Q[t-1], self.gyr[t], self.acc[t], self.mag[t])\n",
    "        return Q\n",
    "        \n",
    "    def updateMARG(self, q: np.ndarray, gyr: np.ndarray, acc: np.ndarray, mag: np.ndarray, dt: float = None) -> np.ndarray:\n",
    "\n",
    "        # q : numpy.ndarray\n",
    "        #     A-priori quaternion.\n",
    "        # gyr : numpy.ndarray\n",
    "        #     Sample of tri-axial Gyroscope in rad/s\n",
    "        # acc : numpy.ndarray\n",
    "        #     Sample of tri-axial Accelerometer in m/s^2\n",
    "        # mag : numpy.ndarray\n",
    "        #     Sample of tri-axial Magnetometer in nT\n",
    "        # dt : float, default: None\n",
    "        #     Time step, in seconds, between consecutive Quaternions.\n",
    "\n",
    "        dt = self.Dt if dt is None else dt\n",
    "        if gyr is None or not np.linalg.norm(gyr) > 0:\n",
    "            return q\n",
    "        if mag is None or not np.linalg.norm(mag) > 0:\n",
    "            return self.updateIMU(q, gyr, acc)\n",
    "        qDot = 0.5 * q_prod(q, [0, *gyr])                           # (eq. 12)\n",
    "        a_norm = np.linalg.norm(acc)\n",
    "        if a_norm > 0:\n",
    "            a = acc/a_norm\n",
    "            m = mag/np.linalg.norm(mag)\n",
    "            # Rotate normalized magnetometer measurements\n",
    "            h = q_prod(q, q_prod([0, *m], q_conj(q)))               # (eq. 45)\n",
    "            bx = np.linalg.norm([h[1], h[2]])                       # (eq. 46)\n",
    "            bz = h[3]\n",
    "            qw, qx, qy, qz = q/np.linalg.norm(q)\n",
    "            # Objective function (eq. 31)\n",
    "            f = np.array([2.0*(qx*qz - qw*qy)   - a[0],\n",
    "                            2.0*(qw*qx + qy*qz)   - a[1],\n",
    "                            2.0*(0.5-qx**2-qy**2) - a[2],\n",
    "                            2.0*bx*(0.5 - qy**2 - qz**2) + 2.0*bz*(qx*qz - qw*qy)       - m[0],\n",
    "                            2.0*bx*(qx*qy - qw*qz)       + 2.0*bz*(qw*qx + qy*qz)       - m[1],\n",
    "                            2.0*bx*(qw*qy + qx*qz)       + 2.0*bz*(0.5 - qx**2 - qy**2) - m[2]])\n",
    "            # Jacobian (eq. 32)\n",
    "            J = np.array([[-2.0*qy,               2.0*qz,              -2.0*qw,               2.0*qx             ],\n",
    "                            [ 2.0*qx,               2.0*qw,               2.0*qz,               2.0*qy             ],\n",
    "                            [ 0.0,                 -4.0*qx,              -4.0*qy,               0.0                ],\n",
    "                            [-2.0*bz*qy,            2.0*bz*qz,           -4.0*bx*qy-2.0*bz*qw, -4.0*bx*qz+2.0*bz*qx],\n",
    "                            [-2.0*bx*qz+2.0*bz*qx,  2.0*bx*qy+2.0*bz*qw,  2.0*bx*qx+2.0*bz*qz, -2.0*bx*qw+2.0*bz*qy],\n",
    "                            [ 2.0*bx*qy,            2.0*bx*qz-4.0*bz*qx,  2.0*bx*qw-4.0*bz*qy,  2.0*bx*qx          ]])\n",
    "            gradient = J.T@f                                        # (eq. 34)\n",
    "            gradient /= np.linalg.norm(gradient)\n",
    "            qDot -= self.gain*gradient                              # (eq. 33)\n",
    "        q_new = q + qDot*dt                                         # (eq. 13)\n",
    "        q_new /= np.linalg.norm(q_new)\n",
    "        return q_new\n",
    "    \n",
    "    def updateIMU(self, q: np.ndarray, gyr: np.ndarray, acc: np.ndarray, dt: float = None) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Quaternion Estimation with IMU architecture.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        q : numpy.ndarray\n",
    "            A-priori quaternion.\n",
    "        gyr : numpy.ndarray\n",
    "            Sample of tri-axial Gyroscope in rad/s\n",
    "        acc : numpy.ndarray\n",
    "            Sample of tri-axial Accelerometer in m/s^2\n",
    "        dt : float, default: None\n",
    "            Time step, in seconds, between consecutive Quaternions.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        q : numpy.ndarray\n",
    "            Estimated quaternion.\n",
    "        \"\"\"\n",
    "        dt = self.Dt if dt is None else dt\n",
    "        if gyr is None or not np.linalg.norm(gyr) > 0:\n",
    "            return q\n",
    "        qDot = 0.5 * q_prod(q, [0, *gyr])                           # (eq. 12)\n",
    "        a_norm = np.linalg.norm(acc)\n",
    "        if a_norm > 0:\n",
    "            a = acc/a_norm\n",
    "            qw, qx, qy, qz = q/np.linalg.norm(q)\n",
    "            # Objective function (eq. 25)\n",
    "            f = np.array([2.0*(qx*qz - qw*qy)   - a[0],\n",
    "                          2.0*(qw*qx + qy*qz)   - a[1],\n",
    "                          2.0*(0.5-qx**2-qy**2) - a[2]])\n",
    "            if np.linalg.norm(f) > 0:\n",
    "                # Jacobian (eq. 26)\n",
    "                J = np.array([[-2.0*qy,  2.0*qz, -2.0*qw, 2.0*qx],\n",
    "                              [ 2.0*qx,  2.0*qw,  2.0*qz, 2.0*qy],\n",
    "                              [ 0.0,    -4.0*qx, -4.0*qy, 0.0   ]])\n",
    "                # Objective Function Gradient\n",
    "                gradient = J.T@f                                    # (eq. 34)\n",
    "                gradient /= np.linalg.norm(gradient)\n",
    "                qDot -= self.gain*gradient                          # (eq. 33)\n",
    "        q_new = q + qDot*dt                                         # (eq. 13)\n",
    "        q_new /= np.linalg.norm(q_new)\n",
    "        return q_new\n",
    "\n",
    "def ecompass(a: np.ndarray, m: np.ndarray, frame: str = 'ENU', representation: str = 'rotmat') -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Orientation from accelerometer and magnetometer readings\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : numpy.ndarray\n",
    "        Sample of tri-axial accelerometer, in m/s^2.\n",
    "    m : numpy.ndarray\n",
    "        Sample of tri-axial magnetometer, in uT.\n",
    "    frame : str, default: ``'ENU'``\n",
    "        Local tangent plane coordinate frame.\n",
    "    representation : str, default: ``'rotmat'``\n",
    "        Orientation representation. Options are: ``'rotmat'``, ``'quaternion'``,\n",
    "        ``'rpy'``, ``'axisangle'``.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Estimated orientation.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        When wrong local tangent plane coordinates, or invalid representation,\n",
    "        is given.\n",
    "    \"\"\"\n",
    "    if frame.upper() not in ['ENU', 'NED']:\n",
    "        raise ValueError(\"Wrong local tangent plane coordinate frame. Try 'ENU' or 'NED'\")\n",
    "    if representation.lower() not in ['rotmat', 'quaternion', 'rpy', 'axisangle']:\n",
    "        raise ValueError(\"Wrong representation type. Try 'rotmat', 'quaternion', 'rpy', or 'axisangle'\")\n",
    "    a = np.copy(a)\n",
    "    m = np.copy(m)\n",
    "    if a.shape[-1] != 3 or m.shape[-1] != 3:\n",
    "        raise ValueError(\"Input vectors must have exactly 3 elements.\")\n",
    "    m /= np.linalg.norm(m)\n",
    "    Rz = a/np.linalg.norm(a)\n",
    "    if frame.upper() == 'NED':\n",
    "        Ry = np.cross(Rz, m)\n",
    "        Rx = np.cross(Ry, Rz)\n",
    "    else:\n",
    "        Rx = np.cross(m, Rz)\n",
    "        Ry = np.cross(Rz, Rx)\n",
    "    Rx /= np.linalg.norm(Rx)\n",
    "    Ry /= np.linalg.norm(Ry)\n",
    "    R = np.c_[Rx, Ry, Rz].T\n",
    "    if representation.lower() == 'quaternion':\n",
    "        return chiaverini(R)\n",
    "    if representation.lower() == 'rpy':\n",
    "        phi = np.arctan2(R[1, 2], R[2, 2])    # Roll Angle\n",
    "        theta = -np.arcsin(R[0, 2])           # Pitch Angle\n",
    "        psi = np.arctan2(R[0, 1], R[0, 0])    # Yaw Angle\n",
    "        return np.array([phi, theta, psi])\n",
    "    if representation.lower() == 'axisangle':\n",
    "        angle = np.arccos((R.trace()-1)/2)\n",
    "        axis = np.zeros(3)\n",
    "        if angle != 0:\n",
    "            S = np.array([R[2, 1]-R[1, 2], R[0, 2]-R[2, 0], R[1, 0]-R[0, 1]])\n",
    "            axis = S/(2*np.sin(angle))\n",
    "        return (axis, angle)\n",
    "    return R\n",
    "\n",
    "def chiaverini(dcm: np.ndarray) -> np.ndarray:\n",
    "    dcm = np.copy(dcm)\n",
    "    if dcm.ndim not in [2, 3]:\n",
    "        raise ValueError('dcm must be a 2- or 3-dimensional array.')\n",
    "    if dcm.shape[-2:] != (3, 3):\n",
    "        raise ValueError(f\"dcm must be an array of shape 3-by-3 or N-by-3-by-3. Got {dcm.shape}\")\n",
    "    if dcm.ndim < 3:\n",
    "        q = np.zeros(4)\n",
    "        q[0] = 0.5*np.sqrt(np.clip(dcm.trace(), -1.0, 3.0) + 1.0)\n",
    "        q[1] = 0.5*np.sign(dcm[2, 1]-dcm[1, 2])*np.sqrt(np.clip(dcm[0, 0]-dcm[1, 1]-dcm[2, 2], -1.0, 1.0)+1.0)\n",
    "        q[2] = 0.5*np.sign(dcm[0, 2]-dcm[2, 0])*np.sqrt(np.clip(dcm[1, 1]-dcm[2, 2]-dcm[0, 0], -1.0, 1.0)+1.0)\n",
    "        q[3] = 0.5*np.sign(dcm[1, 0]-dcm[0, 1])*np.sqrt(np.clip(dcm[2, 2]-dcm[0, 0]-dcm[1, 1], -1.0, 1.0)+1.0)\n",
    "        if not any(q):\n",
    "            q[0] = 1.0\n",
    "        q /= np.linalg.norm(q)\n",
    "        return q\n",
    "    Q = np.zeros((dcm.shape[0], 4))\n",
    "    Q[:, 0] = 0.5*np.sqrt(np.clip(dcm.trace(axis1=1, axis2=2), -1.0, 3.0) + 1.0)\n",
    "    Q[:, 1] = 0.5*np.sign(dcm[:, 2, 1] - dcm[:, 1, 2])*np.sqrt(np.clip(dcm[:, 0, 0]-dcm[:, 1, 1]-dcm[:, 2, 2], -1.0, 1.0) + 1.0)\n",
    "    Q[:, 2] = 0.5*np.sign(dcm[:, 0, 2] - dcm[:, 2, 0])*np.sqrt(np.clip(dcm[:, 1, 1]-dcm[:, 2, 2]-dcm[:, 0, 0], -1.0, 1.0) + 1.0)\n",
    "    Q[:, 3] = 0.5*np.sign(dcm[:, 1, 0] - dcm[:, 0, 1])*np.sqrt(np.clip(dcm[:, 2, 2]-dcm[:, 0, 0]-dcm[:, 1, 1], -1.0, 1.0) + 1.0)\n",
    "    Q /= np.linalg.norm(Q, axis=1)[:, None]\n",
    "    return Q\n",
    "\n",
    "def q_prod(p: np.ndarray, q: np.ndarray) -> np.ndarray:\n",
    "    pq = np.zeros(4)\n",
    "    pq[0] = p[0]*q[0] - p[1]*q[1] - p[2]*q[2] - p[3]*q[3]\n",
    "    pq[1] = p[0]*q[1] + p[1]*q[0] + p[2]*q[3] - p[3]*q[2]\n",
    "    pq[2] = p[0]*q[2] - p[1]*q[3] + p[2]*q[0] + p[3]*q[1]\n",
    "    pq[3] = p[0]*q[3] + p[1]*q[2] - p[2]*q[1] + p[3]*q[0]\n",
    "    return pq\n",
    "\n",
    "def q_conj(q: np.ndarray) -> np.ndarray:\n",
    "    q = np.copy(q)\n",
    "    if q.ndim > 2 or q.shape[-1] != 4:\n",
    "        raise ValueError(f\"Quaternion must be of shape (4,) or (N, 4), but has shape {q.shape}\")\n",
    "    return np.array([1., -1., -1., -1.])*np.array(q)\n",
    "\n",
    "def q2euler(q: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Euler Angles from unit Quaternion.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    q : numpy.ndarray\n",
    "        Quaternion\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    angles : numpy.ndarray\n",
    "        Euler Angles around X-, Y- and Z-axis.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] https://en.wikipedia.org/wiki/Conversion_between_quaternions_and_Euler_angles#Quaternion_to_Euler_Angles_Conversion\n",
    "\n",
    "    \"\"\"\n",
    "    if sum(np.array([1., 0., 0., 0.])-q) == 0.0:\n",
    "        return np.zeros(3)\n",
    "    if len(q) != 4:\n",
    "        return None\n",
    "    R_00 = 2.0*q[0]**2 - 1.0 + 2.0*q[1]**2\n",
    "    R_10 = 2.0*(q[1]*q[2] - q[0]*q[3])\n",
    "    R_20 = 2.0*(q[1]*q[3] + q[0]*q[2])\n",
    "    R_21 = 2.0*(q[2]*q[3] - q[0]*q[1])\n",
    "    R_22 = 2.0*q[0]**2 - 1.0 + 2.0*q[3]**2\n",
    "    #rotation around x, roll\n",
    "    phi = np.arctan2( R_21, R_22)\n",
    "    #rotation around y, pitch\n",
    "    theta = -np.arctan( R_20/np.sqrt(1.0-R_20**2))\n",
    "    #rotation around z, yaw\n",
    "    psi = np.arctan2( R_10, R_00)\n",
    "    return np.array([phi, theta, psi])\n",
    "\n",
    "def acc2q(a: np.ndarray, return_euler: bool = False) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Quaternion from given acceleration.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    a : numpy.ndarray\n",
    "        A sample of 3 orthogonal accelerometers.\n",
    "    return_euler : bool, default: False\n",
    "        Return pose as Euler angles\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pose : numpy.ndarray\n",
    "        Quaternion or Euler Angles.\n",
    "    \"\"\"\n",
    "    q = np.array([1.0, 0.0, 0.0, 0.0])\n",
    "    ex, ey, ez = 0.0, 0.0, 0.0\n",
    "    if np.linalg.norm(a) > 0 and len(a) == 3:\n",
    "        ax, ay, az = a\n",
    "        # Normalize accelerometer measurements\n",
    "        a_norm = np.linalg.norm(a)\n",
    "        ax /= a_norm\n",
    "        ay /= a_norm\n",
    "        az /= a_norm\n",
    "        # Euler Angles from Gravity vector\n",
    "        ex = np.arctan2(ay, az)\n",
    "        ey = np.arctan2(-ax, np.sqrt(ay**2 + az**2))\n",
    "        ez = 0.0\n",
    "        if return_euler:\n",
    "            return np.array([ex, ey, ez])*RAD2DEG\n",
    "        # Euler to Quaternion\n",
    "        cx2 = np.cos(ex/2.0)\n",
    "        sx2 = np.sin(ex/2.0)\n",
    "        cy2 = np.cos(ey/2.0)\n",
    "        sy2 = np.sin(ey/2.0)\n",
    "        q = np.array([cx2*cy2, sx2*cy2, cx2*sy2, -sx2*sy2])\n",
    "        q /= np.linalg.norm(q)\n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'path_idx': 2, 'activities': [1], 'step_count': None, 'watch_loc': 0} 103\n",
      "{'path_idx': 2, 'activities': [1], 'step_count': None, 'watch_loc': 0} 106\n",
      "{'path_idx': 4, 'activities': [1], 'step_count': None, 'watch_loc': 1} 107\n",
      "{'path_idx': 4, 'activities': [1], 'step_count': None, 'watch_loc': 2} 109\n",
      "{'path_idx': 0, 'activities': [1], 'step_count': None, 'watch_loc': 0} 112\n",
      "{'path_idx': 4, 'activities': [1], 'step_count': None, 'watch_loc': 0} 115\n",
      "{'path_idx': 3, 'activities': [1], 'step_count': None, 'watch_loc': 2} 116\n",
      "{'path_idx': 1, 'activities': [1], 'step_count': None, 'watch_loc': 0} 117\n",
      "{'path_idx': 2, 'activities': [1], 'step_count': None, 'watch_loc': 2} 120\n",
      "{'path_idx': 1, 'activities': [1], 'step_count': None, 'watch_loc': 2} 121\n",
      "{'path_idx': 0, 'activities': [1], 'step_count': None, 'watch_loc': 2} 122\n",
      "{'path_idx': 3, 'activities': [1], 'step_count': None, 'watch_loc': 0} 123\n",
      "{'path_idx': 0, 'activities': [1], 'step_count': None, 'watch_loc': 0} 125\n",
      "{'path_idx': 1, 'activities': [1], 'step_count': None, 'watch_loc': 2} 126\n",
      "{'path_idx': 4, 'activities': [1], 'step_count': None, 'watch_loc': 0} 128\n",
      "{'path_idx': 0, 'activities': [1], 'step_count': None, 'watch_loc': 2} 129\n"
     ]
    }
   ],
   "source": [
    "#116, path 3, walking only\n",
    "# {'path_idx': 4, 'activities': [1], 'step_count': None, 'watch_loc': 0} 115\n",
    "# {'path_idx': 3, 'activities': [1], 'step_count': None, 'watch_loc': 2} 116\n",
    "# {'path_idx': 1, 'activities': [1], 'step_count': None, 'watch_loc': 0} 117\n",
    "# {'path_idx': 2, 'activities': [1], 'step_count': None, 'watch_loc': 2} 120\n",
    "# {'path_idx': 1, 'activities': [1], 'step_count': None, 'watch_loc': 2} 121\n",
    "# {'path_idx': 0, 'activities': [1], 'step_count': None, 'watch_loc': 2} 122\n",
    "# {'path_idx': 3, 'activities': [1], 'step_count': None, 'watch_loc': 0} 123\n",
    "# {'path_idx': 0, 'activities': [1], 'step_count': None, 'watch_loc': 0} 125\n",
    "for i in range(100, 130):\n",
    "    d = Recording(f\"data/train/train_trace_{i}.pkl\")\n",
    "    if(d.labels['activities']==[1]):\n",
    "        print(f\"{d.labels} {i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ntrace = 116\n",
    "include_mag = True\n",
    "\n",
    "def madgwick_headings(num_trace, source=\"watch\"):\n",
    "    if(source==\"watch\"):\n",
    "        ax, ay, az, gx, gy, gz, mx, my, mz = get_filtered_data(num_trace, downsample=True, filter=False, source=source)\n",
    "        #magnetometer has lower fs and everything downsampled to that\n",
    "        samplerate = 12.5\n",
    "    else:\n",
    "        ax, ay, az, gx, gy, gz, mx, my, mz = get_filtered_data(num_trace, downsample=False, filter=False, source=source)\n",
    "        #everything has the same sample rate\n",
    "        samplerate = 100\n",
    "        \n",
    "    # if len(ax) != len(ay) or len(ax) != len(az) or len(az) != len(ay):\n",
    "    #     print(f\"{num_trace} orospu cocugu array\")\n",
    "\n",
    "    # if len(gx) != len(gy) or len(gx) != len(gz) or len(gz) != len(gy):\n",
    "    #     print(f\"{num_trace} orospu cocugu array\")\n",
    "    \n",
    "    # if len(mx) != len(my) or len(mx) != len(mz) or len(mz) != len(my):\n",
    "    #     print(f\"{num_trace} orospu cocugu array\")\n",
    "\n",
    "    acc_data  = np.concatenate([np.array(az).reshape(-1,1),np.array(ay).reshape(-1,1),np.array(ax).reshape(-1,1)], axis=1)\n",
    "    gyro_data = np.concatenate([np.array(gz).reshape(-1,1),np.array(gy).reshape(-1,1),np.array(gx).reshape(-1,1)], axis=1)\n",
    "    mag_data  = np.concatenate([np.array(mz).reshape(-1,1),np.array(my).reshape(-1,1),np.array(mx).reshape(-1,1)], axis=1)\n",
    "\n",
    "    \n",
    "    madgwick = Madgwick(gyr=gyro_data, acc=acc_data, mag=mag_data, frequency=samplerate, gain=0.038)\n",
    "\n",
    "    # \n",
    "\n",
    "    # fig = plt.figure()\n",
    "    # ax = plt.axes(projection=\"3d\")\n",
    "\n",
    "\n",
    "    current = [0, 0, 0]\n",
    "    x = []\n",
    "    y = [] \n",
    "    z = []\n",
    "\n",
    "    from scipy.spatial.transform import Rotation\n",
    "    limit = len(madgwick.Q)\n",
    "    # limit=100\n",
    "    for i in (range(limit)):\n",
    "        euler = q2euler(madgwick.Q[i]) *180/math.pi\n",
    "        rot = Rotation.from_euler('xyz', euler)\n",
    "        #rotate unit vector to get cartesian headings, x=0\n",
    "        vector = np.array(rot.as_matrix()).dot(np.array([0,0,1]))\n",
    "\n",
    "        # plt.arrow(current[0], current[1], vector[0], vector[1])\n",
    "        current += vector\n",
    "        x.append(current[0])\n",
    "        y.append(current[1])\n",
    "        z.append(current[2])\n",
    "\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    z = np.array(z)\n",
    "\n",
    "    return x, y, z\n",
    "\n",
    "def plot_trajectory(x, y, title):\n",
    "    avg = 2000\n",
    "\n",
    "    u = np.diff(window_average(x,avg))\n",
    "    v = np.diff(window_average(y,avg))\n",
    "    print(len(u))\n",
    "    print(len(v))\n",
    "\n",
    "    pos_x = window_average(x,avg)[:-1] + u/2\n",
    "    pos_y = window_average(y,avg)[:-1] + v/2\n",
    "    norm = np.sqrt(u**2+v**2) \n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(window_average(x,avg),window_average(y,avg), marker=\"o\")\n",
    "    ax.quiver(pos_x, pos_y, u/norm, v/norm, angles=\"xy\", zorder=5, pivot=\"mid\")\n",
    "    \n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "x, y, z = madgwick_headings(ntrace, source=\"phone\")\n",
    "plt.scatter(x,y,z)\n",
    "plt.show()\n",
    "# plot_trajectory(x, z, \"xz\")\n",
    "# plot_trajectory(x, y, \"xy\")\n",
    "# plot_trajectory(z, y, \"zy\")\n",
    "\n",
    "# x, y, z = madgwick_headings(ntrace, source=\"watch\")\n",
    "\n",
    "# plot_trajectory(x, z, \"xz\")\n",
    "# plot_trajectory(x, y, \"xy\")\n",
    "# plot_trajectory(z, y, \"zy\")\n",
    "\n",
    "\n",
    "# x = np.arange(0, len(data['altitude'].loc[ntrace].values), 1)\n",
    "\n",
    "# m,b = np.polyfit(x, data['altitude'].loc[ntrace].values, 1)\n",
    "# poly1d_fn = np.poly1d((m,b))\n",
    "# plt.plot(x,data['altitude'].loc[ntrace].values, 'yo', x, poly1d_fn(x), '--k')\n",
    "\n",
    "# plt.title(f'altitude {np.mean(data['altitude'].loc[ntrace].values[-100:]) - np.mean(data['altitude'].loc[ntrace].values[:100])} {m*1000} ')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot bearings as a sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot bearings extracted from a plot\n",
    "# z,y,x\n",
    "\n",
    "for trace in range(5):\n",
    "    ax, ay, az, gx, gy, gz, mx, my, mz = get_filtered_data(trace, downsample=True)\n",
    "    current = [0,0,0]\n",
    "    limit = min(len(ax), len(mx))\n",
    "    # limit=20\n",
    "    bearings = []\n",
    "    for point in range(limit):\n",
    "        accelvec = np.array([az[point], ay[point], ax[point]])\n",
    "        magvec   = np.array([mz[point], my[point], mx[point]])\n",
    "\n",
    "        proj = getproj(magvec, accelvec)\n",
    "        bearings.append(getbearing(accelvec, magvec))\n",
    "        # length = math.sqrt(proj[0]**2 + proj[1]**2)\n",
    "        length =3\n",
    "        plt.arrow(current[0], current[1], proj[0]/length, proj[1]/length)\n",
    "        current += proj\n",
    "    print(bearings)\n",
    "    plt.title(f\"trace {trace}\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_390906/179091411.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  m /= np.linalg.norm(m)\n",
      "/tmp/ipykernel_390906/179091411.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  m /= np.linalg.norm(m)\n",
      "/tmp/ipykernel_390906/179091411.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  m /= np.linalg.norm(m)\n",
      "/tmp/ipykernel_390906/179091411.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  m /= np.linalg.norm(m)\n",
      "/tmp/ipykernel_390906/179091411.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  m /= np.linalg.norm(m)\n",
      "/tmp/ipykernel_390906/179091411.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  m /= np.linalg.norm(m)\n",
      "/tmp/ipykernel_390906/179091411.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  m /= np.linalg.norm(m)\n",
      "/tmp/ipykernel_390906/179091411.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  m /= np.linalg.norm(m)\n",
      "/tmp/ipykernel_390906/179091411.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  m /= np.linalg.norm(m)\n",
      "/tmp/ipykernel_390906/179091411.py:205: RuntimeWarning: invalid value encountered in divide\n",
      "  m /= np.linalg.norm(m)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "except 133\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avgdist2d_phone</th>\n",
       "      <th>avgdist3d_phone</th>\n",
       "      <th>dist1_phone</th>\n",
       "      <th>dist2_phone</th>\n",
       "      <th>dist3_phone</th>\n",
       "      <th>dist4_phone</th>\n",
       "      <th>dist5_phone</th>\n",
       "      <th>north_seg0_phone</th>\n",
       "      <th>east_seg0_phone</th>\n",
       "      <th>south_seg0_phone</th>\n",
       "      <th>...</th>\n",
       "      <th>south_seg2_phone</th>\n",
       "      <th>west_seg2_phone</th>\n",
       "      <th>north_seg3_phone</th>\n",
       "      <th>east_seg3_phone</th>\n",
       "      <th>south_seg3_phone</th>\n",
       "      <th>west_seg3_phone</th>\n",
       "      <th>north_seg4_phone</th>\n",
       "      <th>east_seg4_phone</th>\n",
       "      <th>south_seg4_phone</th>\n",
       "      <th>west_seg4_phone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>701.262034</td>\n",
       "      <td>701.914399</td>\n",
       "      <td>714.744140</td>\n",
       "      <td>198.662799</td>\n",
       "      <td>180.951272</td>\n",
       "      <td>117.861469</td>\n",
       "      <td>60.025861</td>\n",
       "      <td>2.0</td>\n",
       "      <td>343.0</td>\n",
       "      <td>10187.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8521.0</td>\n",
       "      <td>3171.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2931.0</td>\n",
       "      <td>8761.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9545.0</td>\n",
       "      <td>2147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>546.100524</td>\n",
       "      <td>639.582683</td>\n",
       "      <td>279.686353</td>\n",
       "      <td>176.365972</td>\n",
       "      <td>304.562859</td>\n",
       "      <td>351.965020</td>\n",
       "      <td>137.860149</td>\n",
       "      <td>4048.0</td>\n",
       "      <td>5848.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>6238.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10313.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10313.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>273.543447</td>\n",
       "      <td>295.314831</td>\n",
       "      <td>30.013414</td>\n",
       "      <td>46.503873</td>\n",
       "      <td>129.985201</td>\n",
       "      <td>281.760226</td>\n",
       "      <td>152.275170</td>\n",
       "      <td>6937.0</td>\n",
       "      <td>1405.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5867.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1026.0</td>\n",
       "      <td>7978.0</td>\n",
       "      <td>2533.0</td>\n",
       "      <td>346.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>980.0</td>\n",
       "      <td>9782.0</td>\n",
       "      <td>929.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227.103638</td>\n",
       "      <td>261.311774</td>\n",
       "      <td>131.317905</td>\n",
       "      <td>17.261247</td>\n",
       "      <td>40.955429</td>\n",
       "      <td>111.597296</td>\n",
       "      <td>87.701581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10390.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10390.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10390.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>122.890822</td>\n",
       "      <td>395.853094</td>\n",
       "      <td>123.932715</td>\n",
       "      <td>172.087942</td>\n",
       "      <td>70.076674</td>\n",
       "      <td>369.222708</td>\n",
       "      <td>401.084197</td>\n",
       "      <td>51.0</td>\n",
       "      <td>623.0</td>\n",
       "      <td>6417.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12385.0</td>\n",
       "      <td>183.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12205.0</td>\n",
       "      <td>355.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12033.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>262.714781</td>\n",
       "      <td>857.006496</td>\n",
       "      <td>100.557999</td>\n",
       "      <td>514.759911</td>\n",
       "      <td>223.413368</td>\n",
       "      <td>51.560612</td>\n",
       "      <td>35.946617</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5359.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6510.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6510.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>392</th>\n",
       "      <td>72.041355</td>\n",
       "      <td>351.148629</td>\n",
       "      <td>24.321658</td>\n",
       "      <td>118.623628</td>\n",
       "      <td>70.291726</td>\n",
       "      <td>117.637710</td>\n",
       "      <td>88.201234</td>\n",
       "      <td>2930.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12355.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12305.0</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>313.503377</td>\n",
       "      <td>452.199550</td>\n",
       "      <td>155.971067</td>\n",
       "      <td>192.170330</td>\n",
       "      <td>96.291299</td>\n",
       "      <td>171.615609</td>\n",
       "      <td>241.675099</td>\n",
       "      <td>2364.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>2215.0</td>\n",
       "      <td>12738.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3372.0</td>\n",
       "      <td>11581.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>341.469218</td>\n",
       "      <td>346.729092</td>\n",
       "      <td>53.490086</td>\n",
       "      <td>65.357879</td>\n",
       "      <td>15.527700</td>\n",
       "      <td>130.874747</td>\n",
       "      <td>232.507608</td>\n",
       "      <td>6981.0</td>\n",
       "      <td>2033.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7351.0</td>\n",
       "      <td>1328.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7793.0</td>\n",
       "      <td>3936.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>531.994082</td>\n",
       "      <td>575.494084</td>\n",
       "      <td>150.341735</td>\n",
       "      <td>291.853718</td>\n",
       "      <td>308.674904</td>\n",
       "      <td>353.580172</td>\n",
       "      <td>98.470724</td>\n",
       "      <td>11857.0</td>\n",
       "      <td>808.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>12716.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12716.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>396 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     avgdist2d_phone  avgdist3d_phone  dist1_phone  dist2_phone  dist3_phone  \\\n",
       "0         701.262034       701.914399   714.744140   198.662799   180.951272   \n",
       "1         546.100524       639.582683   279.686353   176.365972   304.562859   \n",
       "2         273.543447       295.314831    30.013414    46.503873   129.985201   \n",
       "3         227.103638       261.311774   131.317905    17.261247    40.955429   \n",
       "4         122.890822       395.853094   123.932715   172.087942    70.076674   \n",
       "..               ...              ...          ...          ...          ...   \n",
       "391       262.714781       857.006496   100.557999   514.759911   223.413368   \n",
       "392        72.041355       351.148629    24.321658   118.623628    70.291726   \n",
       "393       313.503377       452.199550   155.971067   192.170330    96.291299   \n",
       "394       341.469218       346.729092    53.490086    65.357879    15.527700   \n",
       "395       531.994082       575.494084   150.341735   291.853718   308.674904   \n",
       "\n",
       "     dist4_phone  dist5_phone  north_seg0_phone  east_seg0_phone  \\\n",
       "0     117.861469    60.025861               2.0            343.0   \n",
       "1     351.965020   137.860149            4048.0           5848.0   \n",
       "2     281.760226   152.275170            6937.0           1405.0   \n",
       "3     111.597296    87.701581               0.0              0.0   \n",
       "4     369.222708   401.084197              51.0            623.0   \n",
       "..           ...          ...               ...              ...   \n",
       "391    51.560612    35.946617             100.0              0.0   \n",
       "392   117.637710    88.201234            2930.0             27.0   \n",
       "393   171.615609   241.675099            2364.0             46.0   \n",
       "394   130.874747   232.507608            6981.0           2033.0   \n",
       "395   353.580172    98.470724           11857.0            808.0   \n",
       "\n",
       "     south_seg0_phone  ...  south_seg2_phone  west_seg2_phone  \\\n",
       "0             10187.0  ...            8521.0           3171.0   \n",
       "1                20.0  ...            1380.0           6238.0   \n",
       "2                97.0  ...            5867.0              0.0   \n",
       "3             10390.0  ...           10390.0              0.0   \n",
       "4              6417.0  ...               0.0          12385.0   \n",
       "..                ...  ...               ...              ...   \n",
       "391            5359.0  ...            6510.0              0.0   \n",
       "392             563.0  ...               0.0          12355.0   \n",
       "393               0.0  ...               0.0             44.0   \n",
       "394              38.0  ...               0.0           7351.0   \n",
       "395              51.0  ...               0.0            177.0   \n",
       "\n",
       "     north_seg3_phone  east_seg3_phone  south_seg3_phone  west_seg3_phone  \\\n",
       "0                 0.0              0.0            2931.0           8761.0   \n",
       "1                 0.0              0.0               0.0          10313.0   \n",
       "2              1026.0           7978.0            2533.0            346.0   \n",
       "3                 0.0              0.0           10390.0              0.0   \n",
       "4               183.0              0.0               0.0          12205.0   \n",
       "..                ...              ...               ...              ...   \n",
       "391               0.0              0.0            6510.0              0.0   \n",
       "392              50.0              0.0               0.0          12305.0   \n",
       "393            2215.0          12738.0               0.0              0.0   \n",
       "394            1328.0              0.0               0.0           7793.0   \n",
       "395           12716.0              0.0               0.0              0.0   \n",
       "\n",
       "     north_seg4_phone  east_seg4_phone  south_seg4_phone  west_seg4_phone  \n",
       "0                 0.0              0.0            9545.0           2147.0  \n",
       "1                 0.0              0.0               0.0          10313.0  \n",
       "2               192.0            980.0            9782.0            929.0  \n",
       "3                 0.0              0.0           10390.0              0.0  \n",
       "4               355.0              0.0               0.0          12033.0  \n",
       "..                ...              ...               ...              ...  \n",
       "391               0.0              0.0            6510.0              0.0  \n",
       "392            1575.0              0.0               0.0          10780.0  \n",
       "393               0.0           3372.0           11581.0              0.0  \n",
       "394            3936.0              0.0               0.0           5185.0  \n",
       "395           12716.0              0.0               0.0              0.0  \n",
       "\n",
       "[396 rows x 27 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#classify the number of bearings per direction based on the trace number\n",
    "def classify_bearings(source = \"phone\", numtrace=0):\n",
    "    FEATURES = ['avgdist2d', 'avgdist3d', \"dist1\", \"dist2\", \"dist3\", \"dist4\", \"dist5\"]\n",
    "    for idx, feature in enumerate(FEATURES):\n",
    "        FEATURES[idx] = FEATURES[idx] + f'_{source}' \n",
    "\n",
    "    avgdist2d=0; avgdist3d=0;\n",
    "    try: \n",
    "        x, y, z = madgwick_headings(numtrace, source=source)\n",
    "        # if source == \"phone\":\n",
    "        #     x = window_average(x,50)\n",
    "        #     y = window_average(y,50)\n",
    "        #     z = window_average(z,50)\n",
    "\n",
    "        # else:\n",
    "        #     x = window_average(x,5)\n",
    "        #     y = window_average(y,5)\n",
    "        #     z = window_average(z,5) \n",
    "             \n",
    "        avgdist2d=math.sqrt((x[-1]+x[0])**2 + (y[-1]+y[0])**2 )\n",
    "        avgdist3d=math.sqrt((x[-1]+x[0])**2 + (y[-1]+y[0])**2 + (z[-1]+z[0])**2)\n",
    "\n",
    "        seglen = int(len(x)/5)\n",
    "        dist1 = math.sqrt((x[seglen-1]   - x[0]       )**2   +   (y[seglen-1]   - y[0]       )**2)\n",
    "        dist2 = math.sqrt((x[seglen*2-1] - x[seglen]  )**2   +   (y[seglen*2-1] - y[seglen]  )**2)\n",
    "        dist3 = math.sqrt((x[seglen*3-1] - x[seglen*2])**2   +   (y[seglen*3-1] - y[seglen*2])**2)\n",
    "        dist4 = math.sqrt((x[seglen*4-1] - x[seglen*3])**2   +   (y[seglen*4-1] - y[seglen*3])**2)\n",
    "        dist5 = math.sqrt((x[seglen*5-1] - x[seglen*4])**2   +   (y[seglen*5-1] - y[seglen*4])**2)\n",
    "    except:\n",
    "        print(f\"except {numtrace}\")\n",
    "        # DistanceFeatures = ['north', 'northeast', \"east\", 'southeast', 'south', 'southwest', 'west', 'northwest']\n",
    "        DistanceFeatures = ['north', \"east\", 'south',  'west']\n",
    "        for segment in range(5):\n",
    "            for idx, feature in enumerate(DistanceFeatures):\n",
    "                FEATURES.append(DistanceFeatures[idx] + f'_seg{segment}_{source}')\n",
    "        #7 common features + 8 per segment features * 5 segments = 47 zeros\n",
    "        df_features = pd.DataFrame(index = [FEATURES], data = np.zeros(7 + len(DistanceFeatures) * 5))\n",
    "        df_features = pd.DataFrame.transpose(df_features)\n",
    "        df_features.columns = df_features.columns.map(''.join)\n",
    "        return df_features \n",
    "\n",
    "\n",
    "    df_features = pd.DataFrame(index = [FEATURES], data = [avgdist2d,avgdist3d, dist1, dist2, dist3, dist4, dist5])\n",
    "    df_features = pd.DataFrame.transpose(df_features)\n",
    "    df_features.columns = df_features.columns.map(''.join)\n",
    "\n",
    "    #divide data into 5 parts and classify headings separately\n",
    "    # print(f\"total length {len(x)}\")\n",
    "    north = 0; northeast  = 0; east = 0; southeast = 0; south = 0; southwest = 0; west = 0; northwest = 0;\n",
    "    DistanceFeatures = ['north', \"east\", 'south',  'west']\n",
    "    for i in range(len(x)):\n",
    "        bearing = (math.atan2(x[segment*seglen + i], z[segment*seglen + i]) * 180.0 / math.pi ) + 180.0\n",
    "\n",
    "        if bearing <= 90:\n",
    "            north += 1\n",
    "        elif bearing <= 180:\n",
    "            east += 1\n",
    "        elif bearing <= 270:\n",
    "            south += 1\n",
    "        else:\n",
    "            west += 1\n",
    "\n",
    "        # seg_features = pd.DataFrame(index = [DistanceFeatures], data = [north, northeast, east, southeast, south, southwest, west, northwest])\n",
    "    seg_features = pd.DataFrame(index = [DistanceFeatures], data = [north, east,  south,  west])\n",
    "    seg_features = pd.DataFrame.transpose(seg_features)\n",
    "    seg_features.columns = seg_features.columns.map(''.join)\n",
    "    df_features = pd.concat([df_features, seg_features],axis=1)\n",
    "\n",
    "    return df_features\n",
    "\n",
    "\n",
    "#wrapper functions because to make using map easier\n",
    "def classify_bearings_watch(numtrace):\n",
    "    return classify_bearings(source = \"watch\", numtrace=numtrace)\n",
    "\n",
    "\n",
    "def classify_bearings_phone(numtrace):\n",
    "    return classify_bearings(source = \"phone\", numtrace=numtrace)\n",
    "\n",
    "def classify_all_watch_recordings():\n",
    "    nums = np.arange(0,len(data['ax']), 1)\n",
    "    with Pool() as p:\n",
    "        directions = p.map(classify_bearings_watch, nums)\n",
    "    directions = pd.concat(directions, ignore_index=True)    \n",
    "    \n",
    "    return directions\n",
    "\n",
    "def classify_all_phone_recordings():\n",
    "    nums = np.arange(0,len(data['phone_ax']), 1)\n",
    "    with Pool() as p:\n",
    "        directions = p.map(classify_bearings_phone, nums)\n",
    "    directions = pd.concat(directions, ignore_index=True)    \n",
    "    \n",
    "    return directions\n",
    "\n",
    "watch_bearing_directions = classify_all_watch_recordings()\n",
    "watch_bearing_directions.to_pickle(path='data/watch_bearing_directions.pkl.zst', compression={'method': 'zstd'})\n",
    "watch_bearing_directions\n",
    "\n",
    "phone_bearing_directions = classify_all_phone_recordings()\n",
    "phone_bearing_directions.to_pickle(path='data/phone_bearing_directions.pkl.zst', compression={'method': 'zstd'})\n",
    "phone_bearing_directions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(147, 200):\n",
    "    d = Recording(f\"data/train/train_trace_{i}.pkl\")\n",
    "    sos = signal.cheby2(1, 20, 0.5, 'lowpass', fs=12.5, output='sos')\n",
    "    alt = signal.sosfiltfilt(sos,d.data[\"altitude\"].values)\n",
    "    plt.plot(alt)\n",
    "    plt.title(f\"{i} {np.var(alt)}\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

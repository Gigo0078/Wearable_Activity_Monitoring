{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# You may change the mhealth_activity module but your algorithm must support the original version\n",
    "from mhealth_activity import Recording, Trace, Activity, WatchLocation, Path\n",
    "\n",
    "# For interactive plots, uncomment the following line\n",
    "# %matplotlib widget\n",
    "import os\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.fft import fft, fftfreq\n",
    "import scipy.stats as stats\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.signal import find_peaks\n",
    "from scipy.signal import peak_prominences\n",
    "from sklearn.metrics import mean_absolute_error,accuracy_score,precision_score,recall_score,confusion_matrix,classification_report,f1_score\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load feature extractor for accelerometer, gyroscope and magnetometer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_extraction_common(inp): \n",
    "    FEATURES = ['Median', 'Numneg', 'Numpos', 'Numabovmed', 'Mean', 'STD', 'MAD', 'Var', 'Min', 'Max', 'SMA', 'Energy', 'IQR', 'Entropy', 'Npeaks', 'avgprom', 'avgpeakdist', 'Sum_f', 'Max_f', 'NPeak_f', 'Avgprom_f','avgpeakdist_f', 'Mean_f', 'Skew_f', 'Kurtosis_f']\n",
    "\n",
    "    \n",
    "    print(FEATURES)\n",
    "    Median=[];Numneg=[];Numpos=[];Numabovmed=[];\n",
    "    Min=[];Max=[];Mean=[];Mad=[];Sma=[];Eng=[];Iqr=[];Entr=[];Std=[];Var=[];Kurt=[];Skew=[];Npeaks=[];Avgprom=[]\n",
    "    Min_d=[];Max_d=[];Mean_d=[];Mad_d=[];Sma_d=[];Eng_d=[];Iqr_d=[];Entr_d=[];Std_d=[];Var_d=[];\n",
    "    Max_f=[];NPeak_f=[];Avgprom_f=[];Mean_f=[];Skew_f=[];Kurtosis_f=[];Sum_f=[]; Avgpeakdist=[]; Avgpeakdist_f=[];\n",
    "    \n",
    "    #X = df.values\n",
    "    ## TIME DOMAIN ##\n",
    "    #list of lists of lists, ugly as fuck but it works \n",
    "    Median.append(np.median(inp))\n",
    "    Numneg.append(np.sum(np.array(inp) < 0, axis=0))\n",
    "    Numpos.append(np.sum(np.array(inp) > 0, axis=0))\n",
    "    Numabovmed.append(np.sum(np.array(inp) > np.median(inp), axis=0))\n",
    "\n",
    "    Mean.append(np.mean(inp))\n",
    "    Std.append(np.std(inp))\n",
    "    #median absolute deviation\n",
    "    Mad.append(stats.median_abs_deviation(inp, scale=1))\n",
    "    Var.append(np.var(inp))\n",
    "    Min.append(np.min(inp))\n",
    "    Max.append(np.max(inp))\n",
    "    #Signal Magnitude Area\n",
    "    Sma.append(np.sum(inp))\n",
    "    #energy measure\n",
    "    Eng.append(np.sum(inp**2)/len(inp))\n",
    "    Iqr.append(stats.iqr(inp))\n",
    "    Entr.append(stats.entropy(inp))\n",
    "\n",
    "    npeaks, _ = find_peaks(inp, distance=5)\n",
    "    Npeaks.append(len(npeaks))\n",
    "    prom = peak_prominences(inp, npeaks)\n",
    "    Avgprom.append(np.mean(prom))\n",
    "\n",
    "    Apeakdist = 0\n",
    "    for i in range(len(npeaks)-1):\n",
    "        Apeakdist += abs(npeaks[i] - npeaks[i+1])\n",
    "    Avgpeakdist.append(Apeakdist/(len(npeaks)-1))\n",
    "\n",
    "    ## FREQ DOMAIN ##\n",
    "    ft = np.abs(fft(inp))\n",
    "    Sum_f.append(np.sum(ft))\n",
    "    Max_f.append(np.max(ft))\n",
    "\n",
    "    npeaks, _ = find_peaks(ft, distance=5)\n",
    "    NPeak_f.append(len(npeaks))\n",
    "    prom = peak_prominences(ft, npeaks)\n",
    "    Avgprom_f.append(np.mean(prom))\n",
    "\n",
    "    Apeakdist = 0\n",
    "    for i in range(len(npeaks)-1):\n",
    "        Apeakdist += abs(npeaks[i] - npeaks[i+1])\n",
    "    Avgpeakdist_f.append(Apeakdist/(len(npeaks)-1))\n",
    "\n",
    "    Mean_f.append(np.mean(ft))\n",
    "    Skew_f.append(stats.skew(ft))\n",
    "    Kurtosis_f.append(stats.kurtosis(ft))\n",
    "\n",
    "    #derivative\n",
    "    # f = np.gradient(inp)\n",
    "    # Mean_d.append(np.mean(inp))\n",
    "    # Std_d.append(np.std(recording[0]))\n",
    "    # #median absolute deviation\n",
    "    # Mad_d.append(stats.median_abs_deviation(recording[0], scale=1))\n",
    "    # Var_d.append(np.var(recording[0]))\n",
    "    # Min_d.append(np.min(recording[0]))\n",
    "    # Max_d.append(np.max(recording[0]))\n",
    "    # #Signal Magnitude Area\n",
    "    # Sma_d.append(np.sum(recording[0]))\n",
    "    # #energy measure\n",
    "    # Eng_d.append(np.sum(recording[0]**2)/len(recording[0]))\n",
    "    # Iqr_d.append(stats.iqr(recording[0]))\n",
    "    # Entr_d.append(stats.entropy(recording[0]))\n",
    "\n",
    "    #Create dataframe from features\n",
    "    return np.array([Median, Numneg, Numpos, Numabovmed, Mean,Std, Mad, Var, Min, Max, Sma, Eng, Iqr, Entr, Npeaks, Avgprom, Avgpeakdist, Sum_f, Max_f, NPeak_f, Avgprom_f, Avgpeakdist_f, Mean_f, Skew_f, Kurtosis_f]).reshape(-1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(396, 1)\n",
      "(396, 1)\n",
      "(396, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' #data = pd.read_pickle(\\'doruks_data/pickled_and_sorted_training_data.pkl.zst\\')\\n\\npos_labels  = []\\npath_labels = []\\nfor label in data[\"labels\"]:\\n    path_labels.extend([label[\"path_idx\"]])\\n    pos_labels.extend([label[\"watch_loc\"]]) '"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load pickled training 3d norm accelerometer data\n",
    "file = open('doruks_data/accel_mag_train.pkl', 'rb')\n",
    "pickled = pickle.load(file)\n",
    "accel_mag_train =  pd.DataFrame(((x,) for x in pickled), columns=['accel'])\n",
    "print(accel_mag_train.shape)\n",
    "file.close()\n",
    "\n",
    "file = open('doruks_data/magneto_mag_train.pkl', 'rb')\n",
    "pickled = pickle.load(file)\n",
    "magneto_mag_train =  pd.DataFrame(((x,) for x in pickled), columns=['magneto'])\n",
    "print(magneto_mag_train.shape)\n",
    "file.close()\n",
    "\n",
    "file = open('doruks_data/gyro_mag_train.pkl', 'rb')\n",
    "pickled = pickle.load(file)\n",
    "gyro_mag_train =  pd.DataFrame(((x,) for x in pickled), columns=['gyro'])\n",
    "print(gyro_mag_train.shape)\n",
    "file.close()\n",
    "\"\"\" #data = pd.read_pickle('doruks_data/pickled_and_sorted_training_data.pkl.zst')\n",
    "\n",
    "pos_labels  = []\n",
    "path_labels = []\n",
    "for label in data[\"labels\"]:\n",
    "    path_labels.extend([label[\"path_idx\"]])\n",
    "    pos_labels.extend([label[\"watch_loc\"]]) \"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('doruks_data/accel_gyro_magneto_timestamps.pkl', 'rb')\n",
    "\n",
    "\n",
    "timestamps = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n",
      "Difference:  0.0\n"
     ]
    }
   ],
   "source": [
    "# Seemingly, even though accel/gyro_time and magneto_time is different, the total recording time remains the same\n",
    "\n",
    "for i in range(0, timestamps.shape[0]):\n",
    "\n",
    "    print(\"Difference: \", timestamps[\"gyro_time\"][i][-1] - timestamps[\"magneto_time\"][i][-1])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_one = pd.read_pickle('unique_activity_ONE.pkl')\n",
    "unique_two = pd.read_pickle('unique_activity_TWO.pkl')\n",
    "unique_three = pd.read_pickle('unique_activity_THREE.pkl')\n",
    "\n",
    "unique_all = pd.concat([unique_one, unique_two, unique_three])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_indices = unique_all.index\n",
    "gyro_mag_train_unique = gyro_mag_train.loc[unique_indices]\n",
    "magneto_mag_train_unique = magneto_mag_train.loc[unique_indices]\n",
    "accel_mag_train_unique = accel_mag_train.loc[unique_indices]\n",
    "\n",
    "timestamps_unique = timestamps.loc[unique_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_all = pd.concat([unique_all, timestamps_unique, gyro_mag_train_unique, magneto_mag_train_unique, accel_mag_train_unique], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path_idx</th>\n",
       "      <th>activities</th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>speed</th>\n",
       "      <th>altitude</th>\n",
       "      <th>step_count</th>\n",
       "      <th>phone_steps</th>\n",
       "      <th>accel_time</th>\n",
       "      <th>gyro_time</th>\n",
       "      <th>magneto_time</th>\n",
       "      <th>gyro</th>\n",
       "      <th>magneto</th>\n",
       "      <th>accel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Trace(title='longitude', total_time=584.87, sa...</td>\n",
       "      <td>Trace(title='latitude', total_time=584.87, sam...</td>\n",
       "      <td>Trace(title='speed', total_time=584.87, sample...</td>\n",
       "      <td>Trace(title='altitude', total_time=584.87, sam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trace(title='phone_steps', total_time=584.87, ...</td>\n",
       "      <td>[0.0, 0.004992479791038916, 0.0099849595820778...</td>\n",
       "      <td>[0.0, 0.004992479791038916, 0.0099849595820778...</td>\n",
       "      <td>[0.0, 0.07988990575058053, 0.15977981150116105...</td>\n",
       "      <td>[53.384678630069224, 55.44401057024837, 54.294...</td>\n",
       "      <td>[221.89445350659278, 221.10276820131642, 221.3...</td>\n",
       "      <td>[0.9480597873558152, 0.8834795162112591, 0.826...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Trace(title='longitude', total_time=519.63, sa...</td>\n",
       "      <td>Trace(title='latitude', total_time=519.63, sam...</td>\n",
       "      <td>Trace(title='speed', total_time=519.63, sample...</td>\n",
       "      <td>Trace(title='altitude', total_time=519.63, sam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.0, 0.004998807130282537, 0.0099976142605650...</td>\n",
       "      <td>[0.0, 0.004998807130282537, 0.0099976142605650...</td>\n",
       "      <td>[0.0, 0.07999245689655173, 0.15998491379310345...</td>\n",
       "      <td>[2.1428685815022215, 2.3109384227933973, 2.486...</td>\n",
       "      <td>[248.5280522182176, 248.5280522182176, 248.528...</td>\n",
       "      <td>[0.9713710479087602, 0.9788491672371056, 0.979...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Trace(title='longitude', total_time=625.44, sa...</td>\n",
       "      <td>Trace(title='latitude', total_time=625.44, sam...</td>\n",
       "      <td>Trace(title='speed', total_time=625.44, sample...</td>\n",
       "      <td>Trace(title='altitude', total_time=625.44, sam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.0, 0.005001351405381632, 0.0100027028107632...</td>\n",
       "      <td>[0.0, 0.005001351405381632, 0.0100027028107632...</td>\n",
       "      <td>[0.0, 0.08003122200895713, 0.16006244401791425...</td>\n",
       "      <td>[3.500952797321439, 3.553201645342359, 3.49266...</td>\n",
       "      <td>[271.8695491537745, 271.8695491537745, 269.464...</td>\n",
       "      <td>[0.9858525450565528, 0.9902738944131763, 0.984...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Trace(title='longitude', total_time=499.81, sa...</td>\n",
       "      <td>Trace(title='latitude', total_time=499.81, sam...</td>\n",
       "      <td>Trace(title='speed', total_time=499.81, sample...</td>\n",
       "      <td>Trace(title='altitude', total_time=499.81, sam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trace(title='phone_steps', total_time=499.81, ...</td>\n",
       "      <td>[0.0, 0.005002932844859514, 0.0100058656897190...</td>\n",
       "      <td>[0.0, 0.005002932844859514, 0.0100058656897190...</td>\n",
       "      <td>[0.0, 0.08005894601954189, 0.16011789203908378...</td>\n",
       "      <td>[1.546642179982124, 1.4506286076538246, 1.6252...</td>\n",
       "      <td>[68.80874601448878, 68.80874601448878, 68.8087...</td>\n",
       "      <td>[1.0085702753031478, 1.0100548807662528, 1.008...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>Trace(title='longitude', total_time=473.97, sa...</td>\n",
       "      <td>Trace(title='latitude', total_time=473.97, sam...</td>\n",
       "      <td>Trace(title='speed', total_time=473.97, sample...</td>\n",
       "      <td>Trace(title='altitude', total_time=473.97, sam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trace(title='phone_steps', total_time=473.97, ...</td>\n",
       "      <td>[0.0, 0.00500227965931758, 0.01000455931863516...</td>\n",
       "      <td>[0.0, 0.00500227965931758, 0.01000455931863516...</td>\n",
       "      <td>[0.0, 0.08004914710352981, 0.16009829420705962...</td>\n",
       "      <td>[13.978758128803513, 11.405993305218088, 7.896...</td>\n",
       "      <td>[61.56632930124062, 62.093556897044365, 62.093...</td>\n",
       "      <td>[0.9529625801153142, 0.9204687610859984, 0.940...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>4</td>\n",
       "      <td>[2]</td>\n",
       "      <td>Trace(title='longitude', total_time=237.11, sa...</td>\n",
       "      <td>Trace(title='latitude', total_time=237.11, sam...</td>\n",
       "      <td>Trace(title='speed', total_time=237.11, sample...</td>\n",
       "      <td>Trace(title='altitude', total_time=237.11, sam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trace(title='phone_steps', total_time=237.11, ...</td>\n",
       "      <td>[0.0, 0.00500162423270825, 0.0100032484654165,...</td>\n",
       "      <td>[0.0, 0.00500162423270825, 0.0100032484654165,...</td>\n",
       "      <td>[0.0, 0.08005131667792033, 0.16010263335584066...</td>\n",
       "      <td>[57.52947564292359, 53.113549940974494, 48.797...</td>\n",
       "      <td>[179.98295915558447, 179.98295915558447, 179.9...</td>\n",
       "      <td>[1.1580717066912989, 1.1404327596370545, 1.127...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>1</td>\n",
       "      <td>[2]</td>\n",
       "      <td>Trace(title='longitude', total_time=321.26, sa...</td>\n",
       "      <td>Trace(title='latitude', total_time=321.26, sam...</td>\n",
       "      <td>Trace(title='speed', total_time=321.26, sample...</td>\n",
       "      <td>Trace(title='altitude', total_time=321.26, sam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trace(title='phone_steps', total_time=321.26, ...</td>\n",
       "      <td>[0.0, 0.005000965145783714, 0.0100019302915674...</td>\n",
       "      <td>[0.0, 0.005000965145783714, 0.0100019302915674...</td>\n",
       "      <td>[0.0, 0.08003413054309916, 0.16006826108619832...</td>\n",
       "      <td>[7.029947849072784, 6.943235275511577, 7.10389...</td>\n",
       "      <td>[184.6015820688411, 184.6015820688411, 184.601...</td>\n",
       "      <td>[1.0403482040369971, 1.0409539581985816, 1.041...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>379</th>\n",
       "      <td>2</td>\n",
       "      <td>[2]</td>\n",
       "      <td>Trace(title='longitude', total_time=278.21, sa...</td>\n",
       "      <td>Trace(title='latitude', total_time=278.21, sam...</td>\n",
       "      <td>Trace(title='speed', total_time=278.21, sample...</td>\n",
       "      <td>Trace(title='altitude', total_time=278.21, sam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trace(title='phone_steps', total_time=278.21, ...</td>\n",
       "      <td>[0.0, 0.005000916755046647, 0.0100018335100932...</td>\n",
       "      <td>[0.0, 0.005000916755046647, 0.0100018335100932...</td>\n",
       "      <td>[0.0, 0.08003624856156502, 0.16007249712313004...</td>\n",
       "      <td>[5.855300599343808, 5.383044731988208, 5.00855...</td>\n",
       "      <td>[179.33851951368842, 179.33851951368842, 179.3...</td>\n",
       "      <td>[0.9916801356888864, 0.9891451651933957, 0.993...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>3</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>Trace(title='longitude', total_time=464.79, sa...</td>\n",
       "      <td>Trace(title='latitude', total_time=464.79, sam...</td>\n",
       "      <td>Trace(title='speed', total_time=464.79, sample...</td>\n",
       "      <td>Trace(title='altitude', total_time=464.79, sam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trace(title='phone_steps', total_time=464.79, ...</td>\n",
       "      <td>[0.0, 0.005004242078403083, 0.0100084841568061...</td>\n",
       "      <td>[0.0, 0.005004242078403083, 0.0100084841568061...</td>\n",
       "      <td>[0.0, 0.08008080634045486, 0.16016161268090973...</td>\n",
       "      <td>[32.98797039249145, 31.148705374649655, 28.903...</td>\n",
       "      <td>[157.39305172536064, 158.76545395559904, 156.9...</td>\n",
       "      <td>[1.1274485432963524, 1.146372515080797, 1.1592...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>2</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>Trace(title='longitude', total_time=287.91, sa...</td>\n",
       "      <td>Trace(title='latitude', total_time=287.91, sam...</td>\n",
       "      <td>Trace(title='speed', total_time=287.91, sample...</td>\n",
       "      <td>Trace(title='altitude', total_time=287.91, sam...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>[0.0, 0.005160545607714505, 0.0103210912154290...</td>\n",
       "      <td>[0.0, 0.005160545607714505, 0.0103210912154290...</td>\n",
       "      <td>[0.0, 0.08259093516924841, 0.16518187033849682...</td>\n",
       "      <td>[46.220352990475845, 48.50249654035864, 52.515...</td>\n",
       "      <td>[61.2000778664403, 61.2000778664403, 61.200077...</td>\n",
       "      <td>[1.0018811843729554, 0.9861525614680781, 1.036...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     path_idx activities                                          longitude  \\\n",
       "0           2        [1]  Trace(title='longitude', total_time=584.87, sa...   \n",
       "3           2        [1]  Trace(title='longitude', total_time=519.63, sa...   \n",
       "4           1        [1]  Trace(title='longitude', total_time=625.44, sa...   \n",
       "5           1        [1]  Trace(title='longitude', total_time=499.81, sa...   \n",
       "6           3        [1]  Trace(title='longitude', total_time=473.97, sa...   \n",
       "..        ...        ...                                                ...   \n",
       "189         4        [2]  Trace(title='longitude', total_time=237.11, sa...   \n",
       "320         1        [2]  Trace(title='longitude', total_time=321.26, sa...   \n",
       "379         2        [2]  Trace(title='longitude', total_time=278.21, sa...   \n",
       "150         3     [2, 3]  Trace(title='longitude', total_time=464.79, sa...   \n",
       "219         2     [2, 3]  Trace(title='longitude', total_time=287.91, sa...   \n",
       "\n",
       "                                              latitude  \\\n",
       "0    Trace(title='latitude', total_time=584.87, sam...   \n",
       "3    Trace(title='latitude', total_time=519.63, sam...   \n",
       "4    Trace(title='latitude', total_time=625.44, sam...   \n",
       "5    Trace(title='latitude', total_time=499.81, sam...   \n",
       "6    Trace(title='latitude', total_time=473.97, sam...   \n",
       "..                                                 ...   \n",
       "189  Trace(title='latitude', total_time=237.11, sam...   \n",
       "320  Trace(title='latitude', total_time=321.26, sam...   \n",
       "379  Trace(title='latitude', total_time=278.21, sam...   \n",
       "150  Trace(title='latitude', total_time=464.79, sam...   \n",
       "219  Trace(title='latitude', total_time=287.91, sam...   \n",
       "\n",
       "                                                 speed  \\\n",
       "0    Trace(title='speed', total_time=584.87, sample...   \n",
       "3    Trace(title='speed', total_time=519.63, sample...   \n",
       "4    Trace(title='speed', total_time=625.44, sample...   \n",
       "5    Trace(title='speed', total_time=499.81, sample...   \n",
       "6    Trace(title='speed', total_time=473.97, sample...   \n",
       "..                                                 ...   \n",
       "189  Trace(title='speed', total_time=237.11, sample...   \n",
       "320  Trace(title='speed', total_time=321.26, sample...   \n",
       "379  Trace(title='speed', total_time=278.21, sample...   \n",
       "150  Trace(title='speed', total_time=464.79, sample...   \n",
       "219  Trace(title='speed', total_time=287.91, sample...   \n",
       "\n",
       "                                              altitude  step_count  \\\n",
       "0    Trace(title='altitude', total_time=584.87, sam...         NaN   \n",
       "3    Trace(title='altitude', total_time=519.63, sam...         NaN   \n",
       "4    Trace(title='altitude', total_time=625.44, sam...         NaN   \n",
       "5    Trace(title='altitude', total_time=499.81, sam...         NaN   \n",
       "6    Trace(title='altitude', total_time=473.97, sam...         NaN   \n",
       "..                                                 ...         ...   \n",
       "189  Trace(title='altitude', total_time=237.11, sam...         NaN   \n",
       "320  Trace(title='altitude', total_time=321.26, sam...         NaN   \n",
       "379  Trace(title='altitude', total_time=278.21, sam...         NaN   \n",
       "150  Trace(title='altitude', total_time=464.79, sam...         NaN   \n",
       "219  Trace(title='altitude', total_time=287.91, sam...         NaN   \n",
       "\n",
       "                                           phone_steps  \\\n",
       "0    Trace(title='phone_steps', total_time=584.87, ...   \n",
       "3                                                 None   \n",
       "4                                                 None   \n",
       "5    Trace(title='phone_steps', total_time=499.81, ...   \n",
       "6    Trace(title='phone_steps', total_time=473.97, ...   \n",
       "..                                                 ...   \n",
       "189  Trace(title='phone_steps', total_time=237.11, ...   \n",
       "320  Trace(title='phone_steps', total_time=321.26, ...   \n",
       "379  Trace(title='phone_steps', total_time=278.21, ...   \n",
       "150  Trace(title='phone_steps', total_time=464.79, ...   \n",
       "219                                               None   \n",
       "\n",
       "                                            accel_time  \\\n",
       "0    [0.0, 0.004992479791038916, 0.0099849595820778...   \n",
       "3    [0.0, 0.004998807130282537, 0.0099976142605650...   \n",
       "4    [0.0, 0.005001351405381632, 0.0100027028107632...   \n",
       "5    [0.0, 0.005002932844859514, 0.0100058656897190...   \n",
       "6    [0.0, 0.00500227965931758, 0.01000455931863516...   \n",
       "..                                                 ...   \n",
       "189  [0.0, 0.00500162423270825, 0.0100032484654165,...   \n",
       "320  [0.0, 0.005000965145783714, 0.0100019302915674...   \n",
       "379  [0.0, 0.005000916755046647, 0.0100018335100932...   \n",
       "150  [0.0, 0.005004242078403083, 0.0100084841568061...   \n",
       "219  [0.0, 0.005160545607714505, 0.0103210912154290...   \n",
       "\n",
       "                                             gyro_time  \\\n",
       "0    [0.0, 0.004992479791038916, 0.0099849595820778...   \n",
       "3    [0.0, 0.004998807130282537, 0.0099976142605650...   \n",
       "4    [0.0, 0.005001351405381632, 0.0100027028107632...   \n",
       "5    [0.0, 0.005002932844859514, 0.0100058656897190...   \n",
       "6    [0.0, 0.00500227965931758, 0.01000455931863516...   \n",
       "..                                                 ...   \n",
       "189  [0.0, 0.00500162423270825, 0.0100032484654165,...   \n",
       "320  [0.0, 0.005000965145783714, 0.0100019302915674...   \n",
       "379  [0.0, 0.005000916755046647, 0.0100018335100932...   \n",
       "150  [0.0, 0.005004242078403083, 0.0100084841568061...   \n",
       "219  [0.0, 0.005160545607714505, 0.0103210912154290...   \n",
       "\n",
       "                                          magneto_time  \\\n",
       "0    [0.0, 0.07988990575058053, 0.15977981150116105...   \n",
       "3    [0.0, 0.07999245689655173, 0.15998491379310345...   \n",
       "4    [0.0, 0.08003122200895713, 0.16006244401791425...   \n",
       "5    [0.0, 0.08005894601954189, 0.16011789203908378...   \n",
       "6    [0.0, 0.08004914710352981, 0.16009829420705962...   \n",
       "..                                                 ...   \n",
       "189  [0.0, 0.08005131667792033, 0.16010263335584066...   \n",
       "320  [0.0, 0.08003413054309916, 0.16006826108619832...   \n",
       "379  [0.0, 0.08003624856156502, 0.16007249712313004...   \n",
       "150  [0.0, 0.08008080634045486, 0.16016161268090973...   \n",
       "219  [0.0, 0.08259093516924841, 0.16518187033849682...   \n",
       "\n",
       "                                                  gyro  \\\n",
       "0    [53.384678630069224, 55.44401057024837, 54.294...   \n",
       "3    [2.1428685815022215, 2.3109384227933973, 2.486...   \n",
       "4    [3.500952797321439, 3.553201645342359, 3.49266...   \n",
       "5    [1.546642179982124, 1.4506286076538246, 1.6252...   \n",
       "6    [13.978758128803513, 11.405993305218088, 7.896...   \n",
       "..                                                 ...   \n",
       "189  [57.52947564292359, 53.113549940974494, 48.797...   \n",
       "320  [7.029947849072784, 6.943235275511577, 7.10389...   \n",
       "379  [5.855300599343808, 5.383044731988208, 5.00855...   \n",
       "150  [32.98797039249145, 31.148705374649655, 28.903...   \n",
       "219  [46.220352990475845, 48.50249654035864, 52.515...   \n",
       "\n",
       "                                               magneto  \\\n",
       "0    [221.89445350659278, 221.10276820131642, 221.3...   \n",
       "3    [248.5280522182176, 248.5280522182176, 248.528...   \n",
       "4    [271.8695491537745, 271.8695491537745, 269.464...   \n",
       "5    [68.80874601448878, 68.80874601448878, 68.8087...   \n",
       "6    [61.56632930124062, 62.093556897044365, 62.093...   \n",
       "..                                                 ...   \n",
       "189  [179.98295915558447, 179.98295915558447, 179.9...   \n",
       "320  [184.6015820688411, 184.6015820688411, 184.601...   \n",
       "379  [179.33851951368842, 179.33851951368842, 179.3...   \n",
       "150  [157.39305172536064, 158.76545395559904, 156.9...   \n",
       "219  [61.2000778664403, 61.2000778664403, 61.200077...   \n",
       "\n",
       "                                                 accel  \n",
       "0    [0.9480597873558152, 0.8834795162112591, 0.826...  \n",
       "3    [0.9713710479087602, 0.9788491672371056, 0.979...  \n",
       "4    [0.9858525450565528, 0.9902738944131763, 0.984...  \n",
       "5    [1.0085702753031478, 1.0100548807662528, 1.008...  \n",
       "6    [0.9529625801153142, 0.9204687610859984, 0.940...  \n",
       "..                                                 ...  \n",
       "189  [1.1580717066912989, 1.1404327596370545, 1.127...  \n",
       "320  [1.0403482040369971, 1.0409539581985816, 1.041...  \n",
       "379  [0.9916801356888864, 0.9891451651933957, 0.993...  \n",
       "150  [1.1274485432963524, 1.146372515080797, 1.1592...  \n",
       "219  [1.0018811843729554, 0.9861525614680781, 1.036...  \n",
       "\n",
       "[225 rows x 14 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' index = unique_indices\\n\\nfeatures_of_interest = np.array([\"gyro\", \"magneto\", \"accel\"])\\n\\n\\n\\nextracted_data_dictionary = {}\\n\\nfor sample_index, sample in unique_all.iterrows():\\n\\n    print(sample_index)\\n    feature_dictionary = {}\\n\\n    for feature_name in features_of_interest:\\n\\n        sample = unique_all.loc[sample_index][feature_name]\\n\\n\\n        print(\"Feature Name:\", feature_name)\\n        print(\" Time           Value\")\\n\\n        # Initialize a dictionary to store steps for each second\\n        values_per_second = {}\\n\\n\\n        if sample is not None:\\n\\n            # Iterate over the timestamps and values\\n            for t, x in zip(sample.timestamps, sample.values):\\n                # Get the second part of the timestamp as the key\\n                #if int(t) % 10 == 0 AND #no other 10er in dict:  \\n                 #   print(\"10er:\")\\n\\n                second = int(t) #put in if statement for other intervals of pooling\\n                #print(\"second:\", second, \"real: \", t)\\n                # If the second is not in the dictionary, initialize it with an empty list\\n                if second not in values_per_second:\\n                    values_per_second[second] = np.array([])\\n                # Add the steps to the list for the current second\\n                values_per_second[second] = np.append(values_per_second[second], x)\\n\\n            seconds_array = np.array([])\\n            averages_array = np.array([])\\n\\n            # Calculate the average steps for each second\\n\\n            \\n            for second, values in values_per_second.items():\\n                average_values = features_extraction_common(values) #np.average(values) #sum(values) / len(values)\\n                #print(f\"{second}s \\t{average_values:.5f} steps\")\\n\\n                seconds_array = np.append(seconds_array, second)\\n                averages_array = np.append(averages_array, average_values)\\n                \\n\\n            #das pooled alles in eine sekunde jeweils, eine überlegung wert\\n            \\n            feature_dictionary[\"seconds\"] = seconds_array\\n            feature_dictionary[feature_name]  = averages_array\\n\\n        else:\\n            feature_dictionary[feature_name]  = np.array([])            \\n\\n    #print(feature_dictionary)\\n\\n    extracted_data_dictionary[sample_index] = feature_dictionary '"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" index = unique_indices\n",
    "\n",
    "features_of_interest = np.array([\"gyro\", \"magneto\", \"accel\"])\n",
    "\n",
    "\n",
    "\n",
    "extracted_data_dictionary = {}\n",
    "\n",
    "for sample_index, sample in unique_all.iterrows():\n",
    "\n",
    "    print(sample_index)\n",
    "    feature_dictionary = {}\n",
    "\n",
    "    for feature_name in features_of_interest:\n",
    "\n",
    "        sample = unique_all.loc[sample_index][feature_name]\n",
    "\n",
    "\n",
    "        print(\"Feature Name:\", feature_name)\n",
    "        print(\" Time           Value\")\n",
    "\n",
    "        # Initialize a dictionary to store steps for each second\n",
    "        values_per_second = {}\n",
    "\n",
    "\n",
    "        if sample is not None:\n",
    "\n",
    "            # Iterate over the timestamps and values\n",
    "            for t, x in zip(sample.timestamps, sample.values):\n",
    "                # Get the second part of the timestamp as the key\n",
    "                #if int(t) % 10 == 0 AND #no other 10er in dict:  \n",
    "                 #   print(\"10er:\")\n",
    "\n",
    "                second = int(t) #put in if statement for other intervals of pooling\n",
    "                #print(\"second:\", second, \"real: \", t)\n",
    "                # If the second is not in the dictionary, initialize it with an empty list\n",
    "                if second not in values_per_second:\n",
    "                    values_per_second[second] = np.array([])\n",
    "                # Add the steps to the list for the current second\n",
    "                values_per_second[second] = np.append(values_per_second[second], x)\n",
    "\n",
    "            seconds_array = np.array([])\n",
    "            averages_array = np.array([])\n",
    "\n",
    "            # Calculate the average steps for each second\n",
    "\n",
    "            \n",
    "            for second, values in values_per_second.items():\n",
    "                average_values = features_extraction_common(values) #np.average(values) #sum(values) / len(values)\n",
    "                #print(f\"{second}s \\t{average_values:.5f} steps\")\n",
    "\n",
    "                seconds_array = np.append(seconds_array, second)\n",
    "                averages_array = np.append(averages_array, average_values)\n",
    "                \n",
    "\n",
    "            #das pooled alles in eine sekunde jeweils, eine überlegung wert\n",
    "            \n",
    "            feature_dictionary[\"seconds\"] = seconds_array\n",
    "            feature_dictionary[feature_name]  = averages_array\n",
    "\n",
    "        else:\n",
    "            feature_dictionary[feature_name]  = np.array([])            \n",
    "\n",
    "    #print(feature_dictionary)\n",
    "\n",
    "    extracted_data_dictionary[sample_index] = feature_dictionary \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 4.99247979e-03, 9.98495958e-03, ...,\n",
       "       5.84864015e+02, 5.84869008e+02, 5.84874000e+02])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_all.loc[0][\"gyro_time\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 4.99247979e-03, 9.98495958e-03, ...,\n",
       "       5.84864015e+02, 5.84869008e+02, 5.84874000e+02])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_all[\"gyro_time\"][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_all.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without Pooling but with 10s Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample_index:  0\n",
      "Progress:  0.0 %\n",
      "Feature Name: gyro gyro_time\n",
      "Chunk: 0\n",
      "['Median', 'Numneg', 'Numpos', 'Numabovmed', 'Mean', 'STD', 'MAD', 'Var', 'Min', 'Max', 'SMA', 'Energy', 'IQR', 'Entropy', 'Npeaks', 'avgprom', 'avgpeakdist', 'Sum_f', 'Max_f', 'NPeak_f', 'Avgprom_f', 'avgpeakdist_f', 'Mean_f', 'Skew_f', 'Kurtosis_f']\n",
      "Feature Name: magneto magneto_time\n",
      "Chunk: 0\n",
      "['Median', 'Numneg', 'Numpos', 'Numabovmed', 'Mean', 'STD', 'MAD', 'Var', 'Min', 'Max', 'SMA', 'Energy', 'IQR', 'Entropy', 'Npeaks', 'avgprom', 'avgpeakdist', 'Sum_f', 'Max_f', 'NPeak_f', 'Avgprom_f', 'avgpeakdist_f', 'Mean_f', 'Skew_f', 'Kurtosis_f']\n",
      "Feature Name: accel accel_time\n",
      "Chunk: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 62\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;66;03m# Add the timestamps and values to the list for the current interval\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     new_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[t], [x]])\n\u001b[1;32m---> 62\u001b[0m     values_per_interval[last_second] \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues_per_interval\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlast_second\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_value\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# Calculate the average steps for each second\u001b[39;00m\n\u001b[0;32m     67\u001b[0m intervals_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "index = unique_indices\n",
    "\n",
    "features_of_interest = np.array([\"gyro\", \"magneto\", \"accel\"])\n",
    "\n",
    "chunk_size = 10\n",
    "\n",
    "extracted_data_dictionary = {}\n",
    "\n",
    "for sample_index, sample in unique_all.iterrows():\n",
    "\n",
    "    print(\"Sample_index: \", sample_index)\n",
    "    feature_dictionary = {}\n",
    "\n",
    "    print(\"Progress: \", sample_index/unique_all.shape[0], \"%\")\n",
    "\n",
    "    #print(\"Sample: \", sample)\n",
    "\n",
    "    for feature_name in features_of_interest:\n",
    "\n",
    "        sample_values = unique_all.loc[sample_index][feature_name]\n",
    "\n",
    "        #print(feature_name)\n",
    "\n",
    "        time_name = f'{feature_name}_time'\n",
    "\n",
    "        #print(time_name)\n",
    "        #time_column = unique_all[sample_index].filter(regex=f'{feature_name}.*_time$').columns\n",
    "\n",
    "\n",
    "        sample_timestamps = unique_all[time_name][sample_index]\n",
    "\n",
    "        #print(\"sample: \", sample)\n",
    "\n",
    "        print(\"Feature Name:\", feature_name, time_name)\n",
    "        #print(\" Time           Value\")\n",
    "\n",
    "        # Initialize a dictionary to store steps for each second\n",
    "        values_per_interval = {}\n",
    "\n",
    "        if sample is not None:\n",
    "\n",
    "            # Iterate over the timestamps and values\n",
    "            for t, x in zip(sample_timestamps, sample_values):\n",
    "                # Get the second part of the timestamp as the key\n",
    "\n",
    "                second = int(t) #put in if statement for other intervals of pooling\n",
    "\n",
    "                if second % chunk_size == 0 & second not in values_per_interval:\n",
    "                    values_per_interval[second] = np.array([[], []])\n",
    "\n",
    "                    #update the second\n",
    "                    last_second = second\n",
    "\n",
    "                    print(\"Chunk:\", last_second)                \n",
    "\n",
    "\n",
    "                # Add the timestamps and values to the list for the current interval\n",
    "                \n",
    "                print(\"Timestamp:\", t)\n",
    "                print(\"Value:\", x)\n",
    "\n",
    "                new_value = np.array([[t], [x]])\n",
    "\n",
    "\n",
    "\n",
    "                values_per_interval[last_second] = np.concatenate((values_per_interval[last_second], new_value), axis = 1)\n",
    "\n",
    "            # Calculate the average steps for each second\n",
    "\n",
    "            \n",
    "            intervals_array = np.array([])\n",
    "            embeddings_array = np.array([])\n",
    "\n",
    "            for interval, values in values_per_interval.items():\n",
    "                average_values = features_extraction_common(values[1]) #np.average(values) #sum(values) / len(values)\n",
    "                #print(f\"{second}s \\t{average_values:.5f} steps\")\n",
    "\n",
    "                print(average_values)\n",
    "\n",
    "                intervals_array = np.append(intervals_array, interval)\n",
    "                embeddings_array = np.append(embeddings_array, average_values)\n",
    "                \n",
    "\n",
    "            #das pooled alles in eine sekunde jeweils, eine überlegung wert\n",
    "            \n",
    "            feature_dictionary[\"intervals\"] = intervals_array\n",
    "            feature_dictionary[feature_name]  = embeddings_array\n",
    "\n",
    "        else:\n",
    "            feature_dictionary[feature_name]  = np.array([])            \n",
    "\n",
    "    #print(feature_dictionary)\n",
    "\n",
    "    extracted_data_dictionary[sample_index] = feature_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mhealth",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
